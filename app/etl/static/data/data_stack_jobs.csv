application_url_or_email,category,company_logo_url,company_name,company_slug,company_twitter,description,id,location,location_type,position,published_at,slug,status,tags,type
https://jobs.lever.co/boulevard/155cb811-c2d1-4759-8c03-9dd11068df45,product,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/yifxlruwe2.webp,Boulevard,boulevard,,"As the Senior Product Analyst you will be the foundational team member for our Product Analytics team and create a robust self-service product analytics program from the ground up. You will work across our Product Operations, Analytics Engineering, and Engineering organization to understand the product data gaps and develop a plan to instrument the necessary tracking to power analytics and KPI’s. You will support the design, development, and administration of advanced analytics dashboards for reporting on our product health and performance. You will play a key role starting from requirements gathering, to delivery of an analytics solution, and continuous support of a self service dash-boarding and reporting.You will work with product managers, engineers, and our analytics engineering team, to ensure our product organization has access to the data they need to answer critical questions. If you’re interested in building something from the ground up, having a high sense of ownership, and learning with a growth mindset, and have a passion for data informed decision making, this is the role for you.What you'll do here:Product Event Tracking: Work across Analytics Engineering and Product to define and own product event tracking schema and select and implement a reporting tool such as Amplitude / Mixpanel.Product KPIs: Work closely with product to define and track product metrics and KPIs related to our North Star Metric and its input metrics.Product Dashboards: Support the design and development of product dashboards within an event tracking and reporting toolProduct Strategy / Roadmap: Provide analysis and/ market studies to support strategic initiatives related to product strategy and roadmapProduct A/B Testing: Create a system and visibility for future A/B testing of new features within the product analytics reporting tool, so success criteria for A/B testing can be quickly identified and understood.What you'll need to thrive:Strong Proficiency in an event reporting tool such as Amplitude / MixpanelExperience working with BI or Data engineersStrong Intuition for data and basic statistical conceptsEffective communicator who can successfully operate in a cross-functional role (Product / Analytics Engineering / Eng)Ability to communicate technical concepts to both technical and non-technical audiences through visualizations and studiesStrong intuition for product and user journeys and common SaaS KPIs",21948,United States,remote,Sr. Product Analyst,2022-05-04T16:13:28Z,yifxlruwe2-sr-product-analyst,approved,"['Amplitude', 'Mixpanel', 'SQL']",fulltime
hr@bitquery.io,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ixumzawhqq.webp,Bitquery,bitquery,Bitquery_io,"We have a distributed team, we are looking for programmers to further develop and support a data collection and processing system.Responsibilities:Building scalable infrastructureEffective data storageData quality control, monitoring, and ensuring data qualityDatabase administrationMessage queue administrationUnderstanding blockchain data (blocks, transfers, transactions, smart contracts, etc.)Adding data quality checker/alert/metrics to monitoring systemsRequirements:Knowledge of database technologiesHight SQL language skillProgramming skill (Ruby or Python or Java or Golang)Experience to work with dataThe desire to understand a variety of systems and projects3 years IT experienceStack: Ubuntu, Ansible, Jenkins, Clickhouse, Mysql, Kafka, Ruby, Python, Go, Java, Docker, Grafana, PrometheusKeywords: Unix, Database, DBA, SQL, Go, Python, Blockchain",20251,Worldwide,remote,Data Engineer / Data Ops,2022-03-21T12:18:22Z,ixumzawhqq-data-engineer-data-ops,approved,"['Airflow', 'Clickhouse', 'Apache Spark']",fulltime
https://jobs.lever.co/corestream/0fc8cc4f-306d-41ce-9a6f-5cb638bd27e0?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/o6okkm0d0f.webp,Corestream,corestream,CorestreamInc,"We’re looking for a data engineer with analytics experience to join a small data team and spearhead development on our cloud data lakehouse. The ideal candidate will be adept at working cross-functionally to elicit design requirements from business and technology teams, building robust data pipelines, curating meaningful datasets, and provisioning data for end-users, integrations, and other services.Key ResponsibilitiesWork with business teams to understand current and future data needs and provide mechanisms for constructing and storing datasets to support those requirements.Work with the R&amp;D teams to influence the design and implementation of new data models.Provide expertise in data movement and storage best practices in support of downstream reporting, analytics, and data science initiatives.Help design and optimize the business’ database and table schemas for existing applications and future product development.Design, implement, and optimize robust ELT pipelines.Populate a cloud data lakehouse utilized by data analysts, data scientists, and BI developers.Skills and Expertise4+ Years designing data models, building ETL pipelines, and wrangling data to solve business problems.2+ Years developing in Spark, with Databricks experience strongly preferred.Working experience within the Azure ecosystem.Advanced SQL experience working with relational databases.Experience building data pipelines, architectures, and datasets, with preference for Delta Lake multi-hop architecture development experience.Knowledge of database and data warehouse design best practices for read/write performance.Development experience with either Python or Scala.Demonstrated understanding of common BI patterns and tabular modeling, with preference for Microsoft Power BI experience.Corestream is a fast-growing, cutting-edge financial and benefits technology company. We are an industry leader in the delivery of Voluntary Benefits; our proprietary software is the engine for large, Fortune-500 companies to easily and cost-effectively offer unlimited Voluntary Benefits to its employees through payroll deduction. We have a driven, flexible, and fun team and offer competitive compensation and benefit packages. Although we are over ten years old, we still have a “start-up” culture and when we are in the office we have a casual dress code, weekly yoga, free snacks and beverages, and Friday lunches are on the house. We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",20240,Worldwide,remote,Data Engineer,2022-03-21T12:20:00Z,o6okkm0d0f-data-engineer,approved,"['Azure', 'Data pipelines', 'ETL', 'Power BI']",fulltime
https://apply.workable.com/j/9FE469A6B8/apply?ref=datastackjobs.com&utm_source=datastackjobs.com,machinelearning,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/spxkdouo5t.webp,Wavicle Data Solutions,wavicle-data-solutions,WavicleDataLLC,"Wavicle Data Solutions designs and delivers data and analytics solutions to reduce time, cost, and risk of companies’ data projects, improving the quality of their analytics and decisions now and into the future. As a privately-held consulting service organization with popular, name brand clients across multiple industries, Wavicle offers exciting opportunities for data scientists, solutions architects, developers, and consultants to jump right in and contribute to meaningful, innovative solutions.Our 300+ local, nearshore and offshore consultants, data architects, cloud engineers, and developers build cost-effective, right-fit solutions leveraging our team’s deep business acumen and knowledge of cutting-edge data and analytics technology and frameworks.At Wavicle, you’ll find a challenging and rewarding work environment where we enjoy working as a team to exceed client expectations. Employees appreciate being part of something meaningful at Wavicle. Wavicle has been recognized by industry leaders as follows:Chicago Tribune’s Top WorkplacesInc 500 Fastest Growing Private Companies in the USCrain’s Fast 50 fastest growing companies in the Chicago areaTalend Expert Partner recognitionMicrosoft Gold Data Platform competencyWatch here to learn <a href=""https://vimeo.com/654661550"">Why Wavicle As a ML Engineer you will be responsible for the end-to-end a development of machine learning solutions that solve some of our client's most complex business problems.What You Will Get To Do:Identify scalable ML solutions to solve business problems that addresses client need.Understanding on ML pipeline (feature engineering, scoring, signal processing).Understand Data Engineering and its mechanism, whether its real time or batch.Work with Data Scientists on how models are being built and used against different data inputs.Provide a platform for Data Scientist to access data and processes to allow them to fine tune the models.Build a system that can provide capabilities for Data Scientists to be contributors.Leverage cloud compute to build solutions.Understand Data science needs and translate them into workable solutions.Mentor and guide other ML engineers, scientists and senior leaders. Be a continuous learner and invest in the learning and development of ML engineers.Requirements5+ years of data &amp; analytics professional work experience.Prior experience working as a management/strategic consultant is highly desirable.3+ years of developing and deploying machine learning systems into a production environment.Experience working with big data tools (i.e. Hadoop, Spark, Kafka, etc.) to extract data.Familiarity with ML modeling frameworks (i.e. Tensorflow, Keras, Pytorch).Expertise with key cloud services (VM, Storage, etc...) - AWS, Azure or GCP.Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala , etc.Experience working with distributed systems, service oriented architectures and designing APIs.Expert knowledge of SQL.Strong written and verbal communication skills.Excellent analytical and problem solving skills.Familiar with project management methodologies.Bachelor or Master's degree in Computer Science, Statistics, Mathematics, Analytics or related degree.Hybrid work schedule (onsite/remote).Ability to travel to client locations up to 25% (Canadian and U.S. based customers).Must reside in the Quebec providence; Montreal preferred. Wavicle's Canadian office is located in Montreal.Equal Opportunity Employer Wavicle is an Equal Opportunity Employer and committed to creating an inclusive environment for all employees. We welcome and encourage diversity in the workplace regardless of race, color, religion, national origin, gender, pregnancy, sexual orientation, gender identity, age, physical or mental disability, genetic information or veteran status.BenefitsHealth Care Plan (Medical, Dental &amp; Vision)Life Insurance (Basic, Voluntary &amp; AD&amp;D)Unlimited Paid Time Off (Vacation, Sick &amp; Public Holidays)Short Term &amp; Long Term DisabilityTraining &amp; DevelopmentFlexible Work ScheduleBonus ProgramWellness Program",19439,Canada,remote,Senior ML Engineer,2022-03-06T12:26:22Z,spxkdouo5t-senior-ml-engineer,approved,"['AWS', 'Azure', 'Big Data', 'Consulting']",fulltime
https://boards.greenhouse.io/innovaccer/jobs/5954305002?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/okmf74i1ul.webp,Innovaccer,innovaccer,innovaccer,"Your RoleWe are looking for a Staff Data Engineer to join the Customer Innovation team, who will be responsible for acquiring, transforming, and integrating customer data onto our Data Activation Platform from customers’ clinical, claims, and other data sources. You will work closely with customers to build data and analytics solutions to support their business needs, and be the engine that powers the partnership that we build with them by delivering high-fidelity data assets.In this role, you will work closely with our Product Managers, Data Scientists, and Software Engineers to build the solution architecture that will support customer objectives. You'll work with some of the brightest minds in the industry, work with one of the richest healthcare data sets in the world, use cutting-edge technology, and see your efforts affect products and people on a regular basis. The ideal candidate is someone that Has healthcare experience and is passionate about helping heal people,Loves working with data, Has an obsessive focus on data quality,Is comfortable with ambiguity and making decisions based on available data and reasonable assumptions,Has strong data interrogation and analysis skills,Defaults to written communication and delivers clean documentation, and,Enjoys working with customers and problem solving for them.A Day in the Life▶ Enabling customers for success Define the end-to-end solution architecture for projects by mapping customers’ business and technical requirements against the suite of Innovaccer products and solutions. Measure and communicate impact to our customers.Enabling customers on how to activate data themselves using SQL, BI tools, or APIs to solve for questions they have at speed.Identify risks to customer success and communicate to leadership.▶ Playing with data and delivering insightsDesign, implement, and document data integration pipelines.Automate and orchestrate data flows.Build and unit testing of data ingestion pipelines.Building actionable dashboards and reports for customers.Take part in software engineering lifecycle activities including sprint planning, backlog grooming, code reviews etc.Analyze data and present data quality reports and insights to internal and external audiences. ▶ Finally, shaping the healthcare data platform for customer needsCrafting data models visible to the customersCreating analytical views that drive new insights customers need.What You Need8+ years of experience in a Data Engineering role, Graduate degree in Computer Science, Statistics, Informatics, Information Systems or another quantitative field. Experience working with relational databases like Snowflake, Redshift or Postgres. Familiarity with NoSQL databases like MongoDB and ElasticSearch will be an added advantage.Proficiency in SQL programmingProficiency in at least one programming language (like Python, R, Scala) and experience writing code to handle data manipulation, scheduling, event-based triggering and automation tasksExperience working with AWS including services like EC2, EMR, RDS, Redshift, S3 and moreUS Healthcare Data experience preferably in Value-Based Care and strong healthcare data background - clinical, claims, FHIR, HL7, X12, CCDA etc.Data Analytics and Visualization (using tools like PowerBI)The ability to engage with both the business and technical teams of a client - to document and explain technical problems or concepts in a clear and concise wayAbility to work in a fast-paced and agile environment.Easily adapt and learn new things whether it’s a new library, framework, process, or a visual design concept.Passion for being the technology ambassador and coaching engineering excellence to junior engineers.Experience supporting customer incidents to resolution Preferred SkillsMulti Cloud experienceFamiliarity with Agile methodologies",19429,USA,remote,Staff Data Engineer,2022-03-06T12:24:39Z,okmf74i1ul-staff-data-engineer,approved,"['AWS', 'Data Analytics', 'EC2', 'Engineering']",fulltime
https://angel.co/company/ydata/jobs/1541372-marketing-manager,salesmarketing,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/p1azjgcujr.webp,YData.ai,ydata-ai,YData_ai,"We're looking for a Marketing Manager who will help us shape our team, drive the company to the next level, and have the most direct influence on our success.Your ProfileExperience working in small startups with limited resourcesStrong communication skills to internal and external audiencesCreativity is something you leverage to get to talk with someoneExperience or interest to work with Sales, Marketing, and Analytics toolsWillingness to communicate and share your knowledge with other team membersSince our team is currently being developed from scratch, we need pragmatic peopleYour ResponsibilitiesCreate a marketing strategy for YData's product, building out differentiated technical content and demonstration scenarios that enable thought leadershipLead efforts to market to technical practitioners by deeply understanding their needs and use casesCreate messaging and user experiences that drive engagement, product usage, and retentionCreate content to support marketing campaigns, website pages, and in-product experiences for YData usersDevelop and test product positioning and messaging informed by user research, market and competitive insights, and product understandingCollaborate with Product, Marketing, and Data Science teams to track product awareness, adoption, and engagementYou will be part of a self-organized teamOur Perks – More than just a jobHave an impact. With innovation and smart technology, we are changing the way organizations use and share data.Trust-based working. We don't punch the clock – organize your own schedule. We trust in what you do!Improve yourself. You can have fun at work at the same time you learn and improve yourself. We only hire the best and make them even better.Push boundaries. Everyone is equally important and works together on uncharted challenges alongside inspiring colleagues from all over the world.Feel at home. Literally! We are remote work enthusiasts!Want to write the history of artificial intelligence with us? Submit your application. We're excited to hear from you!",18891,"Europe, Africa, North America, South America, Central America",remote,Marketing Manager,2022-03-06T12:27:55Z,p1azjgcujr-marketing-manager,approved,"['Sales', 'Marketing', 'Analytics', 'Digital Marketing']",fulltime
https://angel.co/company/ydata/jobs/1452245-data-science-advocate,datascience,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ojswkhzzy6.webp,YData.ai,ydata-ai,YData_ai,"We're looking for a Data Science Advocate who will help us shape the way data scientists understand the preparation step, including privacy, explainability, and causality of their datasets.Your ResponsibilitiesYou will be the owner of the documentationYou will create processes for content creation &amp; deliveryYou will write blog posts, social media posts, white papers, and other materialsYou take initiative to write about tools, frameworks, processes, or AI in generalYou are curious about how things work and write about itYour ProfileExperience writing for a technical audience (data scientists, developers, programmers, system architects, or similar)Data Science / AI knowledge and/or willingness to learnInterested in being part of a promising startupPassionate about learning new tools and keeping yourself up-to-dateWillingness to communicate and share your knowledge with othersFluent in EnglishOur Perks – More than just a jobHave an impact. With innovation and smart technology, we are changing the way organizations use and share dataTrust-based working. We don't punch the clock – organize your own schedule. We trust in what you do!Push boundaries. Everyone is equally important and works together on uncharted challenges alongside inspiring colleagues from all over the world.Want to write the history of data science and artificial intelligence with us? Apply now!",18890,"Europe, Africa, North America, South America, Central America",remote,Data Science Advocate,2022-03-06T12:27:48Z,ojswkhzzy6-data-science-advocate,approved,"['AI', 'ML', 'Data Quality', 'Copywriting']",fulltime
https://angel.co/company/ydata/jobs/1453984-senior-data-scientist-product,datascience,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/w45xlizshh.webp,YData.ai,ydata-ai,YData_ai,"We're looking for a Senior Data Scientist (Product) who will help us shape our team, drive the company to the next level, and have the most direct influence on our success.Your ResponsibilitiesYou'll be working with the newest data science Python library for data qualityYou will be part of a self-organized, cross-functional team while working on defining metrics, reports and helping to improve current models' functionalities at scale.Since our team is still growing, we need pragmatic scientistsYou take responsibility for the whole product your team deliversYou are curious and figure out how things work and how they should work for your productYou bring your core expertise but are open to getting your hands dirty with data architecture and data engineeringYou have a problem-solving attitudeYour ProfileML/DL models knowledge and statisticsExperience working with PythonInterested in data explainability and causalityInterested in creating the best tools for data scientists to use on their daily tasksInterested in working together with the FoundersPassionate about learning new tools and keeping yourself up-to-dateWillingness to communicate and share your knowledge with other team membersWillingness to work in agile processesFluent in EnglishOur Perks – More than just a jobHave an impact. With innovation and smart technology, we are changing the way organizations use and share data Trust-based working. We don't punch the clock – organize your own schedule. We trust in what you do! Feel at home. Literally! We are remote work enthusiasts! Feel it’s your own company. Check our stock options plan. We want to have you onboard and be part of YData.Want to write the history of data science and artificial intelligence with us? Submit your application today. We're excited to hear from you!",18889,"Europe, Africa, North America, South America, Central America",remote,Senior Data Scientist (Product),2022-03-06T12:27:43Z,w45xlizshh-senior-data-scientist-product,approved,"['Python', 'Statistics', 'SDK', 'Data Quality']",fulltime
https://angel.co/company/ydata/jobs/1280007-senior-data-engineer,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/q4cjm1n6fm.webp,YData.ai,ydata-ai,YData_ai,"We are currently looking for a Senior Data Engineer to join our team. Our product has built-in data pipelines that require scale to cope with high volumes of data. You will be working on a highly motivated team that is responsible for productizing ML solutions.Your TasksDevelop highly scalable integrations with different data-sourcesDesign and scale research pipelinesDrive decisions on data processingAbility to define your prioritiesOwnership and accountability for your tasksYour ProfileStrong algorithmic thinking and programming skills (Python)Experience with distributed data processing (Spark, Dask, etc.)Good understanding of Data Science workflows/pipelines (Data Cleaning and Data Processing)Understanding of tools such as Kubernetes, Airflow or Kubeflow is a plusPassionate about learning new tools and keeping yourself up-to-dateWillingness to communicate and share your knowledge with other team membersWillingness to work in agile processesFluent in EnglishOur Perks – More than just a jobHave an impact. With innovation and smart technology, we are changing the way organizations use and share data Trust-based working. We don't punch the clock – organize your own schedule. We trust in what you do! Improve yourself. You can have fun at work at the same time you learn and improve yourself. We only hire the best and make them even better. Push boundaries. Everyone is equally important and works together on uncharted challenges alongside inspiring colleagues from all over the world. Feel at home. Literally! We are remote work enthusiasts! Feel it’s your own company. Check our stock options plan. We want to have you onboard and be part of YData.Want to write the history of data science and artificial intelligence with us? Submit your application now. We're excited to hear from you!",18888,"Europe, Africa, North America, South America, Central America",remote,Senior Data Engineer,2022-03-06T12:27:36Z,q4cjm1n6fm-senior-data-engineer,approved,"['Python', 'Spark', 'Dask', 'Kubernetes']",fulltime
https://angel.co/company/ydata/jobs/683530-mlops-back-end-engineer,softwareengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/vc3ynqb6l9.webp,YData.ai,ydata-ai,YData_ai,"We're looking for an MLOps / Back-End Engineer who will help us shape our team, drive the company to the next level, and have the most direct influence on our success.Your ProfileExperience or interest to work with Go and/or Python languagesExperience with infrastructure technologies (Kubernetes and Docker)Experience developing distributed systems and microservice architecturesUnit, integration, and end-to-end tests are an essential part of your coding stylePassionate about learning new tools and keeping yourself up-to-dateWillingness to communicate and share your knowledge with other team membersWillingness to work in agile processes, like Scrum or KanbanFluent in EnglishYour ResponsibilitiesYou will be part of a self-organized, cross-functional team building a data platformSince our team is currently being developed from scratch, we need pragmatic engineersYou are not only our 'code', you take responsibility for the whole product your team deliversYou are curious and figure out how things work and how they should work for your productYou bring your core expertise but are open to getting your hands dirty with back-end, DevOps, QA, and customer successYou have a problem-solving attitudeOur Perks – More than just a jobHave an impact. With innovation and smart technology, we are changing the way organizations use and share data.Trust-based working. We don't punch the clock – organize your own schedule. We trust in what you do!Improve yourself. We only hire the best and make them even better.Feel at home. Literally! We are remote work enthusiasts!Feel it’s your own company. Besides salary, we offer stock options because we want you to be part of YData.Want to write the history of artificial intelligence with us? Submit your application now. We're excited to hear from you!",18887,"Europe, Africa, North America, South America, Central America",remote,MLOps / Back-End Engineer,2022-03-06T12:27:30Z,vc3ynqb6l9-mlops-back-end-engineer,approved,"['Go', 'Python', 'Kubernetes', 'Docker']",fulltime
https://angel.co/company/ydata/jobs/918696-cloud-infrastructure-engineer,softwareengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ni0frws4gc.webp,YData.ai,ydata-ai,YData_ai,"We're looking for a Cloud Infrastructure Engineer who will help us shape our team, drive the company to the next level, and have the most direct influence on our success.Your ProfileExperience with infrastructure technologies (Terraform, Cloud Formation, Kubernetes, Kustomize, and Docker)Experience with cloud providers (AWS, Azure, GCP)Interested in working together with the FoundersPassionate about learning new tools and keeping yourself up-to-dateWillingness to communicate and share your knowledge with other team membersWillingness to work in agile processes, like Scrum or KanbanFluent in EnglishYour ResponsibilitiesYou will be part of a self-organized, cross-functional team building a software platformSince our team is currently being developed from scratch, we need pragmatic engineersYou are not only our 'code', you take responsibility for the whole product your team deliversYou are curious and figure out how things work and how they should work for your productYou bring your core expertise but are open to getting your hands dirty with different cloud infrastructure, on-prem or virtualized, DevOps, QA, and software architectureYou have a problem-solving attitudeOur Perks – More than just a jobHave an impact. With innovation and smart technology, we are changing the way organizations use and share data.Trust-based working. We don't punch the clock – organize your own schedule. We trust in what you do!Feel at home. Literally! We are remote work enthusiasts!Want to write the history of artificial intelligence with us? Send us your application. We're excited to hear from you!",18886,"Europe, Africa, North America, South America, Central America",remote,Cloud infrastructure Engineer,2022-03-06T12:27:20Z,ni0frws4gc-cloud-infrastructure-engineer,approved,"['Terraform', 'Kubernetes', 'Kustomize', 'Docker']",fulltime
https://boards.greenhouse.io/faire/jobs/5893190002?ref=datastackjobs.com&utm_source=datastackjobs.com,machinelearning,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/edyq9egblg.webp,Faire Wholesale,faire-wholesale,faire_wholesale,"About FaireFaire is an online wholesale marketplace built on the belief that the future is local — there are over 2 million independent retailers in North America and Europe doing more than $2 trillion in revenue. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town — we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants.By supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We’re looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours.Job DescriptionAt Faire we build elegant and efficient products to deliver superior customer experiences and enhance marketplace efficiency at the same time. From the mobile checkout process, to personalized search ranking, to the intelligent underwriting engine that determines credit limits for retailers --- we are constantly iterating and innovating our product offering to create more value for the ecosystem.You will be working closely with other data scientists, engineers, and product managers to drive projects that derive value from our unique, rich, and rapidly growing data on two sided marketplace. You will lead projects that enable software driven machine learning deployment to improve Faire’s core metrics.What you will be doing:Leverage machine learning to optimize Faire’s two-sided marketplace dynamicsDesign, build and scale Real-Time and Batch processing pipelines to compute features, perform inference, and make decisionsImprove Faire’s credit portfolio by evaluating creditworthiness of retailers on Faire’s platform; use predictive modeling to dynamically assign credit limits that minimize default risk and maximize growth.What it takes:An advanced degree (MS or PhD) in a relevant discipline such as Computer Science, Machine Learning, or another similar field.3+ years of experience in software engineering or building and deploying machine learning models with large datasetsStrong coding skills in Python/Java/Scala or equivalentSolid understanding of engineering and infrastructure best practices, general software development principles with a machine learning software development life-cycle orientationResourcefulness and proactiveness: track record for executing independent projects and leading complex, multi-functional projects with several dependencies.Strong communication skills and the ability to work with others in a closely collaborative team environment.Prior experience solving data problems in two-sided marketplaces is a big plus.Why you’ll love working at FaireWe are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process.We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners.We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy.We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality.Faire was founded in 2017 by a team of early product and engineering leads from Square. We’re backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our<a href=""https://blog.faire.com/""> blog.Faire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.",17712,North America,remote,Senior Machine Learning Engineer,2022-02-08T21:19:53Z,edyq9egblg-senior-machine-learning-engineer,approved,"['Engineering', 'Java', 'Machine Learning', 'Python']",fulltime
https://boards.greenhouse.io/faire/jobs/5893238002?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/0pv3qxqcrp.webp,Faire Wholesale,faire-wholesale,faire_wholesale,"About FaireFaire is an online wholesale marketplace built on the belief that the future is local — there are over 2 million independent retailers in North America and Europe doing more than $2 trillion in revenue. At Faire, we're using the power of tech, data, and machine learning to connect this thriving community of entrepreneurs across the globe. Picture your favorite boutique in town — we help them discover the best products from around the world to sell in their stores. With the right tools and insights, we believe that we can level the playing field so that small businesses everywhere can compete with these big box and e-commerce giants.By supporting the growth of independent businesses, Faire is driving positive economic impact in local communities, globally. We’re looking for smart, resourceful and passionate people to join us as we power the shop local movement. If you believe in community, come join ours.Job DescriptionThe Data Engineering team is the backbone of all data-related processes and enables the Data Science team to develop and deploy a wide variety of algorithms and models that power the marketplace. Our infrastructure is used by the whole company for analytics, reporting, forecasting and research. We care about having a reliable infrastructure with quality data and building machine learning models that help our customers thrive. As a Senior Data Engineer you’ll be responsible for developing and automating large scale, high-performance data storage and processing systems.Our team already includes experienced Data Scientists and Engineers from Airbnb, Facebook, Quora, Square, Uber, Pinterest, and Stitch Fix. Faire will soon be known as a top destination for data science and machine learning, and you will help take us there!What you will be doing: Develop our machine learning infrastructure to help us scale for where we’re going over the next several yearsManage our data infrastructure and ETL platformWhat it takes:3+ years experience in a Data Engineering role with an emphasis on managing data warehousesStrong skills in Python, Git, Docker, SQL, Airflow, ETL pipelinesFamiliarity with Snowflake or BigQueryA passion for programming and solving problems with codeA bachelor's degree in Computer Science/Software Engineering or equivalent industry experienceA love for technology, and an insatiable curiosity for new tools to tackle real problems Faire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.Why you’ll love working at FaireWe are entrepreneurs: Faire is being built for entrepreneurs, by entrepreneurs. We believe entrepreneurship is a calling and our mission is to empower entrepreneurs to chase their dreams. Every member of our team is an owner of the business and taking part in the founding process.We are using technology and data to level the playing field: We are leveraging the power of product innovation and machine learning to connect brands and boutiques from all over the world, building a growing community of more than 350,000 small business owners.We build products our customers love: Everything we do is ultimately in the service of helping our customers grow their business because our goal is to grow the pie - not steal a piece from it. Running a small business is hard work, but using Faire makes it easy.We are curious and resourceful: Inquisitive by default, we explore every possibility, test every assumption, and develop creative solutions to the challenges at hand. We lead with curiosity and data in our decision making, and reason from a first principles mentality.Faire was founded in 2017 by a team of early product and engineering leads from Square. We’re backed by some of the top investors in retail and tech including: Y Combinator, Lightspeed Venture Partners, Forerunner Ventures, Khosla Ventures, Sequoia Capital, Founders Fund, and DST Global. We have headquarters in San Francisco and Kitchener-Waterloo, and a global employee presence across offices in Salt Lake City, Atlanta, Toronto, London, New York, LA, and Sao Paulo. To learn more about Faire and our customers, you can read more on our<a href=""https://blog.faire.com/""> blog.Faire provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity or gender expression.",17707,North America,remote,Senior Data Engineer,2022-02-08T21:17:59Z,0pv3qxqcrp-senior-data-engineer,approved,"['Airflow', 'BigQuery', 'Engineering', 'ETL']",fulltime
https://nostosgenomics.recruitee.com/o/data-engineer?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/mbxbnw261d.webp,Nostos Genomics,nostos-genomics,nostosgenomics,"We are a venture-backed health tech startup supported by leading investors and scientists on a mission to improve the lives of the 400 million people around the world who suffer from genetic diseases. The platform we have developed uses artificial intelligence and synthetic biology to decipher how changes in the DNA of humans lead to disease. Through this platform, we enable genetic testing labs to provide clear and fast diagnoses to more patients.For this, we've gathered one of the best teams of experts in genetic data, machine learning, and business development. Our people aren't just part of a team, they're part of something bigger. As a community of creative thinkers and doers, we're paving the way for a new generation of genetic healthcare. Our people are what make us great. So, finding the best people is everything to us. Your roleWe are looking for a Data Engineer to lead the improvement of our data infrastructure and take ownership of our data management. You will be responsible for setting up a data lakehouse infrastructure integrating ETL processes and workflows for different scientific and business applications.You will be embedded in our Artificial Intelligence team and work closely together with our Computational Genomics, Software and Product teams, creating innovative solutions to handle large datasets with applications in data science pipelines and machine learning analytics. The ability to think strategically and work collaboratively with hands-on mentality are expected from this role.We foster a flexible work environment and encourage applications from candidates that are either based in Berlin or would work remotely with a willingness to travel to Berlin occasionally.  RequirementsEssentialDegree in a quantitative subject such as computer science, engineering, physics, mathematics or a related disciplineCompetent Python experience (2+ years of experience)Experience with software engineering best practices, such as version control (e.g. Git) and test-driven developmentComfortable working with relational databases such as PostgresAble to write complex SQL queries (e.g. using efficient joins, aggregations and window functions)Experience handling large volumes of data within computational workflowsExperience using workflow orchestration tools such as Apache AirflowExperience with AWS services such as S3, Athena, RDS and DMSExperience building end to end data lakehouse style pipelines in AWSExposure to the 'PyData stack' (e.g. Pandas, NumPy, SciKit-Learn, MatPlotLib and/or Seaborn)Ability to take ownership and responsibility as well as find pragmatic solutions to potentially complex problemsSkills in verbal and written communicationHighly motivated and able to work in a fast-paced, multidisciplinary and collaborative environmentWillingness to learn and openness to feedbackNice-to-haveInterest in data science and machine learningHands-on experience using Docker and KubernetesKnowledge on how to manage data and compute services on AWS using infrastructure-as-code (e.g. AWS CloudFormation templates and/or Terraform)Start-up experienceWhat we value in our teamOur team reflects the interdisciplinary collaboration required to solve this big challenge – ranging from software and data science to genetics and healthcare. We are a proudly diverse, international group of creative problem-solvers and humble learners that care about having a positive impact on society and are also aware of the trust placed in us. This is why we value transparency and kindness, taking ownership and encouraging your personal growth:Develop your personal skills and knowledge with resources like books and courses to learn continuouslyDynamic and flexible work environment that you can design (incl. remote work options)Participate in our success with equity optionsPossibility to grow with the company and influence our directionRegular social activities: participate only if you feel like itAdditionally, we offer good coffee, a selection of healthy snacks and company-subsidized public transport in our Berlin-based officesWe see diversity as a core feature of our team and we encourage you to apply especially if you are from an underrepresented group.",17690,Worldwide,remote,Data Engineer,2022-02-08T21:08:50Z,mbxbnw261d-data-engineer,approved,"['Airflow', 'AWS', 'Engineering', 'ETL']",fulltime
https://boards.greenhouse.io/angi/jobs/5892336002?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/vm5kgrooo4.webp,Angi,angi,angi_home,"Angi® is the home for everything home. From repairs and renovations to products and financing, Angi is transforming every touch point in home services. With over 25 years of experience and a network of nearly 250,000 pros, we have helped more than 150 million people with their home needs. Our products and technology help our customers love where they live while helping small businesses grow and thrive. We believe the home is the most important place on earth and we are at the beginning of our ambitious journey to redefine how people care for their homes - join us! The Team and Role Angi is looking for a Data Engineer to play a key role on the Data Engineering team. The successful candidate will develop and maintain strong relationships with teammates while ensuring delivery of high quality Engineering solutions. The ideal candidate will have outstanding communication skills, proven data infrastructure design and implementation capabilities, strong business acumen, and an innate drive to deliver results. He/she will be a self-starter, comfortable with ambiguity and will enjoy working in a fast-paced dynamic environment. As a Data Engineer, you will be responsible for:Establishing and instilling innovative practices, patterns, and toolkits to deliver enterprise-grade data assets.Interact closely with stakeholders to determine analytics needs and translate those into efficient and scalable data processesPartnering with passionate counterparts to deliver awesomeness and continuously evaluate the best way to deliver short-term and long-term solutions The folks in this role are usually successful when they have experience in:Extensive hands on experience in developing reusable data integration and streaming platforms using Python or another comparable languageBroad knowledge of data infrastructure ecosystemExperience with modern cloud database platforms, such as Snowflake or RedshiftStrong Analytical and SQL skills with demonstrated strength in data modeling, ELT development, and data warehousingExperience with GitLab, CI/CD workflows, AWS services, containerization (Docker), Grafana, and orchestration toolsProven track record of sharing outcomes through written communication, including an ability to effectively communicate with both business and technical teams Compensation &amp; Benefits:The salary band for this position ranges from 70k-170k, commensurate with experience and performance. Compensation may vary based on factors such as cost of living.This position will be eligible for a competitive year end performance bonus &amp; equity package.Full medical, dental, vision package to fit your needsFlexible vacation policy: work hard and take time when you need itPet discount plans &amp; retirement plan with company match (401K)The rare opportunity to work with sharp, motivated teammates solving some of the most unique challenges and changing the world",17683,Worldwide,remote,Data Engineer,2022-02-08T21:07:37Z,vm5kgrooo4-data-engineer,approved,"['AWS', 'Data Warehousing', 'Engineering', 'GitLab']",fulltime
https://jobs.lever.co/mattermost/3a85123c-b46d-4ab8-a97e-7049885d3649?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/qofsrtw71b.webp,Mattermost,mattermost,Mattermost,"Mattermost is an open source platform for secure collaboration across the entire software development lifecycle. Hundreds of thousands of developers around the globe trust Mattermost to increase their productivity by bringing together team communication, task and project management, and workflow orchestration into a unified platform for agile software development. Founded in 2016, Mattermost’s open source platform powers over 800,000 workspaces worldwide with the support of over 4,000 contributors from across the developer community. The company serves over 800 customers, including European Parliament, NASA, Nasdaq, Samsung, SAP, United States Air Force and Wealthfront, and is backed by world-class investors including Battery Ventures, Redpoint, S28 Capital, YC Continuity. To learn more, visit <a href=""http://www.mattermost.com"">www.mattermost.com.We value high impact work, ownership, self-awareness and being focused on customer success. If these values match who you are, we hope you'll learn more about <a href=""https://handbook.mattermost.com/company/about-mattermost"">working at Mattermost and apply!Mattermost is a data-driven organization, and we are looking for a best-in-class Data Analytics Engineer to operate, maintain and enhance our internal self-service data warehouse. You will be responsible for managing our Snowflake data warehouse, building and maintaining ETL and data ingestion processes, and providing assistance to other teams within the company who input data into the warehouse and carry out analytics with the data it holds.Responsibilities:Design, deploy, own and maintain best-in-class data infrastructure (Snowflake, Airflow, dbt, EKS, etc.)Manage the development and operation of high-volume data pipelines to enable the business to make data-driven decisions.Partner with the Analytics team to build data models that are actionable for the businessDrive strategic and architectural decisions around the evolution of our data warehouse and pipelines.Write complex SQL queries and ETL pipelines.Collaborate with Product and Engineering teams to ensure that new products and features are instrumented to capture product usage data/telemetryProvide assistance to other teams within the company supplying data to the warehouse or consuming it for analytics.Design schemas and guide usage of the data warehouse to maintain it as a high quality source of insights.Required Background/Skills:3+ years experience as a Data Engineer3+ years experience using PythonStrong SQL SkillsExperience building and managing a data lake in an enterprise settingExperience applying Software Engineering best practices to Data Analytics, including CI/CD, version control, infrastructure as code, etc.Experience in Schema Design, Data Modelling and Metadata managementComfortable working with a variety of different tools and scripting languages and flexible in your choice of key technologies in the data analytics stack.Ability to work independently in a small, globally-distributed remote team.Strong written and verbal communication skills and a proven ability to work with engineers, data analysts and non-technical stakeholders across all departments of an organization.Nice to haves:Experience developing software and scripts in Go and Javascript.Experience with Snowflake, Apache Airflow, dbt and Rudderstack.Experience with data visualisation tools such as Looker.Experience working in open source communities.Mattermost is a remote-first company with staff living and working across the globe. We are currently hiring staff in these countries/regions:Australia - Brazil - Canada - Chile - Colombia - Finland - Georgia - Germany - Greece - India - Ireland - Mauritius - Mexico - Pakistan - Philippines - Poland - Portugal - South Africa - Spain - Turkey - Uganda - United Kingdom - United StatesWe are constantly working towards adding more countries/regions to this list, but first we need to make sure we are compliant with local laws and regulations, which takes time. Mattermost is made up of people from a wide variety of backgrounds and lifestyles. We embrace diversity and invite applications from people from all walks of life. We don't discriminate against staff or applicants based on gender identity or expression, sexual orientation, race, religion, age, national origin, citizenship, disability, pregnancy status, veteran status, or any other differences. Also, if you have a disability, please let us know if there's any way we can make the interview process better for you; we're happy to accommodate!",17676,Worldwide,remote,Data Engineer,2022-02-08T21:06:05Z,qofsrtw71b-data-engineer,approved,"['Airflow', 'Data Analytics', 'Data pipelines', 'Engineering']",fulltime
https://glide.recruitee.com/o/data-engineer?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/gfbanjlu0r.webp,Glide,glide,glidedotcom,"About UsGlide’s mission is to make the process of buying and selling homes faster, simpler, and safer for real estate agents and their clients. We serve an industry larger than any other, streamlining the most important financial transaction of a consumer’s lifetime.Our platform is used by more than 50,000 real estate agents on over $100B worth of home sale transactions each year. Agents choose Glide because we focus on making their lives simpler, helping them deliver outstanding customer service, stay compliant and grow their businesses.Our culture is based on moving fast, putting customer needs first and supporting one another to accomplish incredible results. We operate as an independent subsidiary of Compass (NYSE: COMP), allowing us to combine the agility of a startup with the resources of a public company.Join Glide because you want to do your best work, to collaborate with amazing people and to make a lasting impact at a pivotal moment in people’s lives.About this RoleAs a Data Engineer at Glide you will support and build data pipelines that enable stakeholders to do their jobs effectively and answer their own questions. You will be working hands on with the latest modern data stack, making sure the models are correct and on time.At Glide You WillSupport the management of our data lake/warehouse infrastructureWrite and Maintain dbt models, with proper documentation and testingTranslate complex business requirements and raw data into transformed tables to support analysis across all areas of the businessDevising architectural solutions that are performant, scalable, well-tested, and maintainableEfficiently handle vast amounts of data from multiple sources and destinations, including relational databases as well as external systemsRequirementsWhat We Look For2+ years of experience working in data engineering.Proven experience in Business IntelligenceStrong skills in Python and SQLExpert in data modelling, extra points if you know your way around dbtExperience with AWS Ecosystem (Redshift, S3, EMR, ECS)Experience using orchestration tools like AirflowExperience in distributed systems (Spark, Hudi, Hadoop, Hive)Deep interest in learning about and keeping up with quickly evolving industry trends around the modern data stack and data best practicesWhat we offerAbove the average salary (base salary in USD, paid in Pesos with a highly competitive exchange rate)Health insurance stipend. We will cover the health insurance for you and your family via a stipend.15 working days of paid vacationsTraining Budget. We like to be updated and encourge you to learn new things.Great equipment. Each employee gets a brand new Macbook.",17352,Worldwide,remote,Data Engineer,2022-02-04T18:55:27Z,gfbanjlu0r-data-engineer,approved,"['Airflow', 'AWS', 'Business Intelligence', 'Data pipelines']",fulltime
https://jobs.lever.co/opendoor/7b08b7df-f2d4-4251-8dd1-36f9b230dedc?ref=datastackjobs.com&utm_source=datastackjobs.com,machinelearning,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/vhafue1wpc.webp,Opendoor,opendoor,Opendoor,"About Opendoor:  Founded in 2014, Opendoor’s mission is to empower everyone with the freedom to move. We believe the traditional real estate process is broken and our goal is simple: build a digital, end-to-end customer experience that makes buying and selling a home simple, certain and fast. We have assembled a dedicated team with diverse backgrounds to support more than 100,000 homes bought and sold with us and the customers who have selected Opendoor as a trusted partner in handling one of their largest financial transactions. But the work is far from over as we continue to grow in new markets. Transforming the real estate industry takes tenacity and dedication. It takes problem solvers and builders. It takes a tight knit community of teammates doing the best work of their lives, pushing one another to transform a complicated process into a simple one.  So where do you fit in? Whether you’re passionate about real estate, people, numbers, words, code, or strategy -- we have a place for you. Real estate is broken. Come help us fix it.About the Role: We are looking for an Engineer with an expertise in Machine Learning or Data Science to join our Pricing Team. In this role, you will use your experience to develop a deep understanding of our AI-driven pricing strategy at Opendoor, and to drive the implementation of our algorithms and experiments while adhering to engineering best practices and keeping an eye towards quality as we scale. You will design and develop platforms, services, and tools to tackle a variety of challenges related to price optimization, inventory management, forecasting, workflow automation, and more. You will collaborate closely with Data Scientists and Analysts on our pricing team to influence our pricing strategy at Opendoor and deliver highly scalable services and products that enable delightful customer experiences. We are looking for engineers with proven ability to deliver results, a passion to learn, and expertise in service oriented architectures, distributed systems, algorithms, analytics, databases, and front-end technologies. In this role, you will be responsible for:Working with product, engineers, and data scientists to contribute to all phases of software development including ideation, prototyping, design, and production.Building products and services from scratch, as well as evolving existing systems using Spark, AWS, Databricks, and python.Developing tools to support the unique challenges of pricing homes at Opendoor, such as custom human data labeling tools or a workflow orchestrator.Applying your technical and quantitative expertise to guide the team in making intelligent, scalable, and pragmatic design decisions.Influencing the technology and architectural roadmap of the engineering teams.Playing an active role in hiring and mentoring other engineers.Building deep domain expertise in pricing and real estate.We’re looking for teammates who have:BS or higher degree in Computer Science, Engineering, or a related technical field.Quantitative experience, either via previous job experience or a degree in Mathematics, Statistics, or a related field, or continuing studies, such as online courses and certifications.Proven ability to design and build production-quality software systems.Excellent programming skills in Python.Experience developing models in a deep learning framework such as pytorch or tensorflow, or with SparkML or SageMaker.Experience in different phases of the ML project lifecycle, including experimentation, EDA, model training, model deployment (batch and/or real time ), AB testing, and monitoring model quality in production over time.Proven ability to use data and metrics to drive decisions.History of independently leading cross-functional projects and prioritizing work based on business impact.Ability to understand the needs of stakeholders, define business requirements, and architect systems that will scale and extend to accommodate them over time.Expertise breaking down complex problems, documenting solutions, and sequencing work to make iterative improvements.A sense of ownership and a passion for delighting customers through innovation and creative solutions to complex problems.Excellent communication skills and high attention to detail.Nice To Have:Experience in Go/Java/C++ is a plus.Experience working closely to support data science or analytics teams is a plusExperience in web development (e.g. React, API design, Rails, Postgres) is a plus.Prior experience with data processing technology (e.g. Spark, Hadoop, SQL) and workflow management tools (e.g. Airflow, dbt) is a plus.Experience with a cloud computing platform such as AWS or GPC is a plus.More About Us: Want to learn more about us and how we are revolutionizing the home buying and selling process? Learn more <a href=""https://www.opendoor.com/w/about"">about us on our website, check out our profile on <a href=""https://www.themuse.com/profiles/opendoor"">The Muse to learn more about our culture from our team members, or read our <a href=""https://www.opendoor.com/w/blog"">blog posts to hear about the work we are doing.We Offer the Following Benefits and Perks:Full medical, dental, and vision with optional 85% coverage for dependentsFlexible vacation policyGenerous parental leavePaid time off to volunteerPlease note that these benefits and perks are available only to Full Time team members and do not apply to contract roles.Opendoor Values Openness:Our team celebrates our diverse backgrounds. We believe that being open about who we are and what we do allows us to be better. Individuals seeking employment at Opendoor are considered without regards to race, color, religion, national origin, age, sex, marital status, ancestry, physical or mental disability, veteran status, sexual orientation, gender identity or other protected status under all applicable laws, regulations, and ordinances. For California residents: for more information about the categories of personal information that we collect for recruiting purposes, please see our personnel <a href=""https://www.opendoor.com/w/ccpa-personnel-privacy-policy"">Privacy Policy.",17330,Worldwide,remote,Sr Machine Learning Platform Engineer,2022-02-04T18:42:22Z,vhafue1wpc-sr-machine-learning-platform-engineer,approved,"['Airflow', 'AWS', 'Deep Learning', 'Distributed Systems']",fulltime
https://boards.greenhouse.io/doma/jobs/3834841?ref=datastackjobs.com&utm_source=datastackjobs.com,datascience,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/akmffrpcy4.webp,Doma,doma,DomaHQtweets,"Build the solution that transforms the real estate industry! Want to infuse a $34B sector of the insurance and real estate industry with predictive analytics and a tech-forward customer experience? Yearning for a startup culture within a profitable nationwide company? Join Doma and send an entirely new type of real estate model into the wild. About Us Doma and its family of brands - States Title, North American Title Company (NATC) and North American Title Insurance Company (NATIC) - offer solutions for lenders, real estate professionals, title agents, and homeowners that make closings vastly more simple and efficient, reducing cost and increasing customer satisfaction. Our Values Customer Obsessed – We always put our customers first. Solution Driven – We solve problems that other people are afraid to. People leaders – We grow all of our people into leaders. One Team – We believe inclusion and teamwork produce the best results. Direct with Respect – We communicate with honesty and respect to our colleagues, customers, and partners. What You’ll DoShape the technical direction of the data science function for our line of businessDevelop and deploy predictive models and analytical solutions; establish best practicesGrow into our go-to-expert in pricing, risk, and forecastingResearch new data sources, vetting for efficacy and applicabilityArchitect and build a platform for our algorithmic engines to run at scaleWork with business and engineering partners to influence product direction and business strategyWhat You’ll NeedAdvanced degree (Masters or PhD) in Mathematics, Statistics, Economics, Data Science or another quantitative field, or actuarial training (ACAS/FCAS/ASA/SOA) preferred6+ years of hands-on experience utilizing data science (AI/ML) to develop models and deploy solutions to solve complex business problemsStrong experience in SQL and programming in PythonStrong organizational, interpersonal, and communication skills (both written and verbal)A bias towards solving problems from a customer-centric lens and an intuitive sense for how the work aligns closely with business objectivesBonus: Experience or interest in pricing and risk modelsBonus: Experience with big data technologies such as Spark, AWS Athena, Redshift, Looker, Tableau, or others.Bonus: Experience with Azure, Airflow, and containerization (Docker)We want the work you do here to be the best work of your life.  We believe the most valuable investment we can make - and the greatest boost we can give to your career - is to build an outstanding team of colleagues who are passionate about our mission. We currently offer the following benefits and will continually evolve them with the goal of efficiently attracting, retaining, and leveraging the very highest quality talent. Our passionate, capable team will always be our #1 benefit We are proud of the team we have built so far, and we are excited about the team we have yet to add Learn something new every day Get more done than you would anywhere else Competitive salaries Top-of-the-line computer equipment Multiple Medical, Dental, and Vision Benefits options to allow you to customize to your and your Family’s needs Paid Time Off  Health &amp; Dependent Care Flexible Spending Accounts (FSA) Short Term &amp; Long Term Disability Commuter Flexible Spending Account (i.e. Transit or Parking) Supplemental Life and AD&amp;D Insurance Auto &amp; Home Insurance Group Life Insurance Pet Insurance We believe in Equal Opportunity We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. ",17327,USA,remote,Founding Staff Data Scientist,2022-02-04T18:37:51Z,akmffrpcy4-founding-staff-data-scientist,approved,"['Airflow', 'AWS', 'Azure', 'Big Data']",fulltime
https://boards.greenhouse.io/janetechnologies/jobs/5876997002?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/swcngss38o.webp,Jane Technologies,jane-technologies,,"Jane Technologies, Inc. is an MIT-founded technology company in the cannabis industry, and we are growing extremely quickly. Our technology digitizes dispensary inventories and creates virtual menus to allow users to explore, purchase, and review products. Our secret sauce is a clean product catalogue with rich content, which we use to map inventory across thousands of stores to a single product. For this reason, we have some of the cleanest transactional, browsing, and product data in the industry. And we’re looking for a passionate, personable, creative, and entrepreneurial Data Analyst to join the team. The Data Engineer is responsible for developing and maintaining data pipelines, storage, and integrations. Their duties include coordinating with data scientists and software engineers to create unique data infrastructure, running tests on their designs, monitoring data quality, and updating systems to accommodate changes in company needs.Culture is the single most important component of Jane’s success to date. A successful candidate will thrive in our environment of mutual support, relentless pursuit of excellence, creativity, and complete lack of ego. We believe in the cannabis industry's ability to bring well-being, health, and love into this world, and it is our mission to bring confidence to the online cannabis shopping experience. To learn more about who we are, our culture, and whether this is the right place for you, read our Key Values profile:<a href=""https://www.keyvalues.com/jane""> https://www.keyvalues.com/jane. Check out our product at:<a href=""https://www.iheartjane.com/""> https://www.iheartjane.com/.Responsibilities:Build data pipelines (ETL) on complex datasets to assist analyses done by data scientists, analysts, and machine learning engineers.Identifying, designing, and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes.Implementing tooling for monitoring and maintaining data pipelines.Working with stakeholders including data, design, product and executive teams and assisting them with data-related technical issues.Minimum qualifications:1+ years experience in a Data Engineer related roleSQL (PostgreSQL preferred, but any variation will suffice)PythonExperience retrieving data from API endpointsAWS (S3, IAM, and other related tools)Effective communication/presentationNice to haves:Salesforce APILookerSnowflakeFeature store for ML jobsAWS Jobs/AirflowJane Technologies is proud to be an equal opportunity employer, and committed to providing employment opportunities regardless of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex, gender, gender identity, gender expression, pregnancy, childbirth and breastfeeding, age, sexual orientation, military or veteran status, or any other protected classification, in accordance with applicable federal, state, and local laws. EOE, including disability/vets.",17227,Worldwide,remote,Senior Data Engineer,2022-02-03T17:11:41Z,swcngss38o-senior-data-engineer,approved,"['Airflow', 'AWS', 'Classification', 'Data pipelines']",fulltime
https://apply.workable.com/j/17EDDC4009/apply?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/1ljwy3gxbl.webp,BrainPOP,brainpop,brainpop,"BrainPOP is an online K-12 educational solution that makes rigorous learning experiences accessible and engaging for all. Proven to raise academic achievement, BrainPOP has been a trusted resource to more than six million educators, and engages the hearts and challenges the minds of over 300 million learners worldwide. BrainPOP provides endless opportunities for kids to take agency over their learning through playful, knowledge-building content and learner-driven projects, preparing them for success in the classroom and beyond. We are seeking a Senior Data Engineer to join our growing team. In this role, you will focus on building new data pipelines and refactoring existing ones that ingest and transform data from a wide array of sources. You will be part of a team responsible for delivering reliable, accurate and timely data to our stakeholders. The data that you provide will be consumed by data scientists, machine learning experts, executives, stakeholders across the company and our most important stakeholders: the districts, schools and teachers that rely on BrainPOP. You will be working collaboratively alongside other passionate Data Engineers, Data Analysts, and Software Engineers to support and maintain our data infrastructure.In this role, you will:Identify and implement improvements to our data ecosystem based on industry best practices.Build, refactor and maintain data pipelines that ingest data from multiple sources.Transform and model datasets for myriad business use cases.Build and support the tools we use for monitoring data hygiene and the health of our pipelines.Support data discovery, certification and governance initiatives in partnership with our Data Science peersOn your resume:4+ years experience working in a modern data engineering environment, including workflow orchestration, pipeline monitoring, warehouse health, etc.3+ years of experience modeling data in a warehouse setting.Demonstrated mastery of SQL and fluency in one or more programming languages, python strongly preferred.Excellent understanding of data structures and algorithms.Familiarity with analytics and data science.About our ideal candidate:Passionate about improving education.Self-starting and interested in building a modern, best-in-class data platform.Experience working in our data stack: AWS, Airflow, Snowflake, dbt, Looker, DockerExcellent organizational skills.BS, BA, MS, MA, or PhD in Information Science, Computer Science, Mathematics, or a related technical field.5+ years of work experience in data-centric roles.Familiarity with data science concepts and statistics.Experience using CDC, Kinesis or other streaming technologies.Experience administering Airflow and/or Snowflake.Experience with data discovery tools such as Amundsen.Life at BrainPOPOur commitment to supporting and empowering teachers and students is reflected in our dedication to enhancing the lives of our employees—in and out of the office.Our team is made up of educators, data scientists, published authors, engineers, artists, bakers, film buffs, cyclists, dual-citizens, and so much more. We value Diversity &amp; Inclusion, collaboration and learning from multiple perspectives, and encourage people to bring their most authentic selves to work.Besides offering a comprehensive benefits package and putting an emphasis on work-life balance, we make it a point to integrate fun and play into the workplace.We offer:Corporate Donation MatchingMedical, Dental, Vision and Paid Life Insurance401K with a company matchFriends &amp; Family BrainPOP SubscriptionLearning &amp; Development StipendWellness Activities (ClassPass Membership)Annual Performance Bonus &amp; Equity Appreciation PlanCompany Events (happy hours, volunteering opportunities, trivia nights and monthly Town Halls)What we do today directly impacts how teachers teach, and students learn. We continue to be inspired because we can see the difference we’re making and we’re proud to be a creative, collaborative, always-teaching and always-learning community.BrainPOP is a hybrid work environment, allowing employees to self-select where they work–whether fully remote in approved states or in-office in our New York headquarters.We are able to employ remotely out of the following approved hiring states:CaliforniaPennsylvaniaTexasFloridaGeorgiaOregonNorth CarolinaNew York (we have our HQ office in this state but candidates may choose to work fully remote in NY if so desired)New JerseyConnecticutMassachusettsWe believe that a diverse organization is a more effective organization. BrainPOP is an Equal Opportunity/Affirmative Action Employer. ",17226,United States,remote,Senior Data Engineer,2022-02-03T17:10:21Z,1ljwy3gxbl-senior-data-engineer,approved,"['Airflow', 'AWS', 'Data pipelines', 'Engineering']",fulltime
https://boards.greenhouse.io/samsara/jobs/3320963?gh_jid=3320963&ref=datastackjobs.com&utm_source=datastackjobs.com,softwareengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/fchbtuibaq.webp,Samsara,samsara,Samsara,"Who We AreSamsara is the pioneer of the Connected Operations Cloud, which allows businesses and organizations that depend on physical operations to harness IoT (Internet of Things) data to develop actionable business insights and improve their operations. Samsara operates in North America and Europe and serves more than 20,000 customers across a wide range of industries including transportation, wholesale and retail trade, construction, field services, logistics, utilities and energy, government, healthcare and education, manufacturing and food and beverage. Learn more about Samsara's mission to increase the efficiency, safety, and sustainability of the operations that power the global economy at <a href=""http://www.samsara.com"">www.samsara.com.About the role:The Senior Data Engineer will be a core technical contributor to Samsara’s data engineering team with deep expertise in creating and manipulating large, complex datasets that feed central data warehouses for Samsara’s data science, product, and engineering teams. The Data Engineer will be responsible for standing up and maintaining data pipelines, building computed tables and database structures, identifying data integrity issues, and data management at Samsara. The Data Engineer will also work closely with Samsara data analysts, data scientists, and ML Engineers to help prep data for models and dashboards. In this role, you will: Build highly reliable computed tables (including unstructured data like video and audio) combining and transforming data across multiple sources, including Samsara sensor data, customer metadata, and financial dataUse Python to access, manipulate, and join external datasets to internal data (e.g., via REST APIs, Pyspark, SparkSQL)Ensure very large databases and compute clusters operate optimally and enable Data Science, ML, and software engineering teamsImplement and maintain database structures and governanceDevelop / maintain data management at Samsara (including scalable systems to document metadata)Work closely with stakeholders across the company from product engineers, data scientists, customer support, finance, and more, to build data pipelines that solve business needsAssist our machine learning and data science team by building robust data annotation, training, and inference pipelinesChampion, role model, and embed Samsara’s cultural principles (Focus on Customer Success, Build for the Long Term, Adopt a Growth Mindset, Be Inclusive, Win as a Team) as we scale globally and across new officesMinimum requirements for this role:BA / MS degree in Computer Science, Statistics, or related disciplineExperience in data engineering focused on ML / data science and ML operationsExperience with standing up ETL pipelines to handle massive volumes of dataExperience working with Hadoop or Spark-based data platformsExperience processing and manipulating data very large data, preferably in Python (e.g., with PySpark)Strong proficiency in SQL, Python, and working with REST APIsKnowledge of software engineering fundamentals; high level of comfort reading and understanding full-stack / backend development code (e.g., our Go code base)Familiarity managing code via GitHub or other code versioning tool4+ years experience as a data engineer or data-focused Software EngineerAn ideal candidate also has:Some experience with data visualization, preferably in TableauExperience with distributed machine learningSome experience with time series based dataAt Samsara, we welcome all. All sizes, colors, cultures, sexes, beliefs, religions, ages, people. We depend on the unique approaches of our team members to help us solve complex problems. We are committed to increasing diversity across our team and ensuring that Samsara is a place where people from all backgrounds can make an impact.AccommodationsSamsara is an inclusive work environment, and we are committed to ensuring equal opportunity in employment for qualified persons with disabilities. Please email <a href=""mailto:accessibleinterviewing@samsara.com"">accessibleinterviewing@samsara.com or <a href=""https://form.asana.com/?k=dcecpJYeVpOJt1RCCU7Hdg&amp;d=182866037607514"">click here if you require any reasonable accommodations throughout the recruiting process.US Only: Please note that Samsara’s COVID-19 vaccination policy requires all team members who will be meeting in person for business or working from one of our offices to be fully vaccinated against COVID-19. People who cannot be vaccinated for qualifying medical conditions, sincerely held religious beliefs, and other legally protected categories, may request an accommodation. BenefitsWorking at Samsara has its perks: for all global full-time employees, we provide private medical and dental insurance, growth and development opportunities, regular virtual team and company events, and other location-based perks. Review all of Samsara's current benefit offerings at <a href=""https://www.rewards.samsara.com/"">rewards.samsara.com.Flexible WorkAt Samsara, we have adopted a flexible way of working, enabling teams and individuals to do their best work. We value in person collaboration and know a change of scenery and quiet space to work is welcomed from time to time. Our offices remain open for those who prefer to collaborate or work in-office. We also offer a co-working support program for employees who are not located near a Samsara office. For more information about our Flexible Work model, please see our blog post <a href=""https://www.samsara.com/blog/the-future-of-work-at-samsara/"">here.",16924,USA,remote,Senior Data Engineer,2022-01-31T19:12:16Z,fchbtuibaq-senior-data-engineer,approved,"['Data pipelines', 'Engineering', 'ETL', 'Finance']",fulltime
https://boards.greenhouse.io/samsara/jobs/3853047?gh_jid=3853047&ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/tcqcxesng3.webp,Samsara,samsara,Samsara,"Who We AreSamsara is the pioneer of the Connected Operations Cloud, which allows businesses and organizations that depend on physical operations to harness IoT (Internet of Things) data to develop actionable business insights and improve their operations. Samsara operates in North America and Europe and serves more than 20,000 customers across a wide range of industries including transportation, wholesale and retail trade, construction, field services, logistics, utilities and energy, government, healthcare and education, manufacturing and food and beverage. Learn more about Samsara's mission to increase the efficiency, safety, and sustainability of the operations that power the global economy at <a href=""http://www.samsara.com"">www.samsara.com.About the role:Data and Analytics is a critical team within Marketing. Our mission is to enable revenue performance by providing marketing and sales teams with the insights, tools, infrastructure and consultation to make data driven decisions. We are a scrappy and growing team that loves all things data! The team will be composed of data engineers, analytics managers and data scientists. We are passionate about leveraging world class data and analytics to deliver a great customer experience.  Our team promotes an agile, collaborative, supportive environment where diverse thinking, innovative design, and experimentation is welcomed and encouraged.In this role, you will: Develop and maintain databases, datasets, pipelines and Samsara’s Customer Data Platform (CDP) to enable advanced segmentation, targeting, automation and analyticsWork with data from a variety of sources including but not limited to: CRM data, Product data, Marketing data, Order flow data, Support ticket volume dataManage critical data pipelines to enable our growth initiatives and advanced analyticsFacilitate data integration and transformation requirements for moving data between applications; ensuring interoperability of applications with data mart and CDP environmentsDevelop and improve the current data architecture, data quality, monitoring and data availabilityWrite data transformations in SQL/Python to generate data products consumed by customer systems and Analytics, Marketing Operations, Sales Operations teamsChampion, role model, and embed Samsara’s cultural principles (Focus on Customer Success, Build for the Long Term, Adopt a Growth Mindset, Be Inclusive, Win as a Team) as we scale globally and across new officesMinimum requirements for the role:2+ years of working experience in a growth, software or data engineering roleStrong SQL and proficient Python knowledge with hands-on data modeling experience Exposure to data warehouse technical architectures, infrastructure components, ETL/ ELT and reporting/analytic toolsHands-on experience working with modern data technologies stack such as Data Bricks, Google Big Query, Redshift, RDS, Snowflake or similar solutions Comfort in working with business customers to gather requirements and gain a deep understanding of varied datasetsSelf-starter, motivated, responsible, innovative and technology-driven individual who performs well both independently and as a team memberA proactive problem solver and have good communication as well as project management skills to relay your findings and solutions across technical and non technical audiencesAn ideal candidate also has:Familiarity with customer, marketing and/or web data Knowledge of Marketo, Salesforce.com and Google AnalyticsExperience working with CDPs such as Segment, Blueshift, Lytics or Adobe Real-time CDPExperience with data visualization tools and packages (e.g. Looker, Domo, Tableau, MixPanel)Familiarity with Marketing Technologies (MarTech stacks)Experience coding with Scala, R or PandasAt Samsara, we welcome all. All sizes, colors, cultures, sexes, beliefs, religions, ages, people. We depend on the unique approaches of our team members to help us solve complex problems. We are committed to increasing diversity across our team and ensuring that Samsara is a place where people from all backgrounds can make an impact.AccommodationsSamsara is an inclusive work environment, and we are committed to ensuring equal opportunity in employment for qualified persons with disabilities. Please email <a href=""mailto:accessibleinterviewing@samsara.com"">accessibleinterviewing@samsara.com or <a href=""https://form.asana.com/?k=dcecpJYeVpOJt1RCCU7Hdg&amp;d=182866037607514"">click here if you require any reasonable accommodations throughout the recruiting process.US Only: Please note that Samsara’s COVID-19 vaccination policy requires all team members who will be meeting in person for business or working from one of our offices to be fully vaccinated against COVID-19. People who cannot be vaccinated for qualifying medical conditions, sincerely held religious beliefs, and other legally protected categories, may request an accommodation. BenefitsWorking at Samsara has its perks: for all global full-time employees, we provide private medical and dental insurance, growth and development opportunities, regular virtual team and company events, and other location-based perks. Review all of Samsara's current benefit offerings at <a href=""https://www.rewards.samsara.com/"">rewards.samsara.com.Flexible WorkAt Samsara, we have adopted a flexible way of working, enabling teams and individuals to do their best work. We value in person collaboration and know a change of scenery and quiet space to work is welcomed from time to time. Our offices remain open for those who prefer to collaborate or work in-office. We also offer a co-working support program for employees who are not located near a Samsara office. For more information about our Flexible Work model, please see our blog post <a href=""https://www.samsara.com/blog/the-future-of-work-at-samsara/"">here.",16923,USA,remote,Marketing Data Engineer,2022-01-31T19:13:54Z,tcqcxesng3-marketing-data-engineer,approved,"['Data pipelines', 'Engineering', 'ETL', 'Healthcare']",fulltime
https://boards.greenhouse.io/everfi/jobs/3352873?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/v9ixdf791s.webp,EVERFI,everfi,EVERFI,"EVERFI is an international technology company driving social impact through education to address the most challenging issues affecting society ranging from financial wellness to mental health to workplace conduct and other critical topics. Founded in 2008, EVERFI’s Impact-as-a-Service TM solution and digital educational content have reached more than 41 million learners globally. In 2020, the company was recognized as one of the World’s Most Innovative Companies by Fast Company and was featured on Fortune Magazine’s Impact 20 List. The company was also named to the 2021 GSV EdTech 150, a list of the most transformative growth companies in digital learning. Some of America’s leading CEOs and venture capital firms are EVERFI investors including Amazon founder and CEO Jeff Bezos, Google Chairman Eric Schmidt, Twitter founder Evan Williams, as well as Advance, Rethink Education, Rethink Impact, The Rise Fund, and TPG Growth. To learn more about EVERFI and how you can #answerthecall please visit<a href=""http://everfi.com/""> everfi.com or follow us on<a href=""https://c212.net/c/link/?t=0&amp;l=en&amp;o=2348374-1&amp;h=3982107549&amp;u=https%3A%2F%2Fwww.facebook.com%2Feverfi%2F&amp;a=Facebook""> Facebook,<a href=""https://c212.net/c/link/?t=0&amp;l=en&amp;o=2348374-1&amp;h=335111280&amp;u=https%3A%2F%2Fwww.instagram.com%2Feverfi%2F&amp;a=Instagram""> Instagram,<a href=""https://c212.net/c/link/?t=0&amp;l=en&amp;o=2348374-1&amp;h=1526369965&amp;u=https%3A%2F%2Fwww.linkedin.com%2Fcompany%2Feverfi%2F&amp;a=LinkedIn""> LinkedIn, or<a href=""https://c212.net/c/link/?t=0&amp;l=en&amp;o=2348374-1&amp;h=443747734&amp;u=https%3A%2F%2Ftwitter.com%2FEVERFI&amp;a=Twitter""> Twitter @EVERFI.The Senior Data Engineer will design, develop, monitor and maintain a robust and scalable data platform used by other data analyst and engineering teams to deliver powerful insights to both internal and external stakeholders. This role will create abstractions to speed the platform’s adoption and build reliable pipelines to support growing data processing and analytics needs. Ideally this person will be a self-starter, detail and quality oriented, and excited about the prospects of having a big impact with data at EVERFI. Responsibilities Design, build and maintain data infrastructure that powers both batch and realtime processing of billions of records a day.Improve the data quality and reliability of data pipelines through monitoring, validation and failure detectionDesign, build and maintain a central data cataloging system to ease integration and discovery of datasetsDevelop data pipelines that provide fast, optimized, and robust end-to-end solutionsAutomate manual processes and create a platform in favor of self-service data consumptionDeploy and configure components to production environments.Participate in on-call schedule to provide emergency incident supportMentor and train teammates on design and operation of data platformStay current with industry trends, making recommendations as needed to help the company excel Other job-related duties as assignedSkills, Experience and QualificationsBachelor’s Degree in Computer Science or Engineering a plus3+ years of relevant industry experience in Data Engineering working with large scale data driven systemsExperience designing data schemas and fine-tuning queries around large, complex data setsExtensive experience working with big data frameworks, like Hive, Spark, Presto and AirflowExperience with data streaming systems such as Apache KafkaDeep understanding of SQL and data warehouse systems, especially Redshift and SnowflakeExpertise in object-oriented and/or functional programming languages (Python preferred)Strong overall programming skills, able to write modular, maintainable codeunderstanding of DevOps principles such as automating of CI/CD pipelines and Infrastructure as codeUnderstanding of polyglot data persistence (relational, key/value, document, column)Excellent problem-solving skills and the ability to proactively solve issuesExcellent communication and organizational skills and proven ability to complete tasks and meet deadlinesAbility to be flexible with working in tandem with a team of engineers or alone, as requiredWork-life, Culture, &amp; Perks:Competitive base salary and bonus potential401k program and equity planComprehensive health care and excellent parental leave benefitsFlexible PTO and generous holiday scheduleCasual work environmentAnnual company-wide retreatOpportunity to work with talented people who have fun in the workplaceCompany Values:We’re looking for future team members who are energized and inspired by our values, as well as people who bring new backgrounds, perspectives, and experiences. At EVERFI, our eight core values are an active part of everything we do:Relationships FirstDemand ExcellenceEmbrace Diversity of Thought &amp; Drive ChangeAct Like an OwnerAlways Show UpShare the CreditRequire Honest &amp; PositivityAlways Ask: “Did I Matter Today?” EVERFI appreciates your interest in our company as a place of employment. It is EVERFI policy to provide equal opportunity for employment to all qualified employees and applicants, regardless of race, religion, religious affiliation, ancestry, citizenship status, marital status, familial status, sexual orientation, gender identity, color, creed, national origin, sex, age, disability, or veteran status or any other characteristic protected by local, state or federal law. This policy applies to all areas of employment including recruitment, placement, training, transfer, promotion, termination, pay, and other forms of compensation and benefits. EVERFI will provide reasonable accommodations to qualified individuals with disabilities.",16920,USA,remote,Senior Data Engineer,2022-01-31T19:11:01Z,v9ixdf791s-senior-data-engineer,approved,"['Airflow', 'Big Data', 'Data pipelines', 'Engineering']",fulltime
https://jobs.lever.co/aquicore/0ba29491-1790-426c-9aaf-7a5580dc7c9c?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/nbocqtriis.webp,Aquicore,aquicore,Aquicore,"Who We AreAquicore was founded in 2013 in the early hours of the morning on the belief that smarter and more connected buildings will have a global impact in curbing our climate challenges and make buildings technologically ready for the next century. We create global impact by bettering the built environment every day. Our next generation of software which facilitates smarter building operations is used by the largest real estate owners and operators around the world. We are changing the industry from the ground up and we’re looking for the right people to achieve our mission!We’re amped by the work we do and driven to constantly propel our values and culture. While awards aren’t the goal, we are humbled to be recognized as one of the coolest places to work by organizations such as DC Inno. Our people come first and it’s the combination of our culture and our mission that has been our greatest differentiator. We take our core values as a company seriously and aspire to level-up our Aquicorians in their careers and professional growth.Our ChallengeWe are looking for a Data Engineer to help usher in the next generation of the Aquicore platform, working on a robust and scalable data platform and data pipelines that deliver truly unique products to market. Aquicore believes that seamless access to vast amounts of data is critical to improving the status-quo of Enterprise software. A successful Data Engineer will leverage their expertise at building data pipelines, integrating with data warehouses, and maintaining ETL products to allow Aquicore to deliver high-quality products to market much faster. We will challenge you to:Focus on solutions, share ideas, and solve problems rather than just write codeCreate design documents and construct formal documentation for cross-team educationIdentify patterns across large datasets, and translate them into heuristicsBring to life the platform that allows our customers to collect millions of data points from live sensors in commercial buildings, and utilize the information in helpful ways.The Impact You’ll HaveAs a Data Engineer, you will work as part of our Data team alongside Software Engineers and Data Scientists to create high quality deliverables that improve our ability to deliver business value to customers. You will design, construct, and maintain robust data pipelines that help power Aquicore's internal business operations, and customer platform. To do this, you will work with modern ETL/ELT systems that automate the data flow and transformation of datasets from multiple sources. You will unify structured and unstructured data from across dozens of sources. You will debug and optimize the performance of data pipelines and queries. You will have a key role in illuminating insights and products that make a difference in our world.The skills we are looking for…Highly responsive and able to work in a virtual environment Individual contributor who works well on an agile teamSelf-starter with the drive, determination, and ability to take ownership of assigned tasksEnjoys technology, cutting-edge software, and thrives in a small team environmentExperience designing, implementing, and maintaining ETL systemsDemonstrable experience with data pipelines in Airflow, Matillion, DBT, or similarStrong software development chops to deliver unit-tested and scalable code in PythonStrong SQL knowledge and experience working with relational databases, query authoring (SQL), as well as a working familiarity with a variety of databasesExperience in database performance tuningFamiliarity with data warehousing, modeling, and dashboarding - Redshift and Snowflake preferredExperience with AWS, especially Redshift and S3Familiarity using team collaboration tools - we use GitHub, JIRA, and ConfluenceUnderstanding of data architecture, modeling, and infrastructure concepts and patternsFamiliarity with data visualizations tools (e.g. Tableau, Looker)Experience with the complete SDLC and CI/CD proceduresAbility to give and receive constructive feedback while in code reviews and coaching sessionsEngaged and interested in continuous improvement &amp; continuous developmentMust-have attributes include hustle, grit, determination, courage, entrepreneurial ambition, and a deep desire to winWithin 1 Month you will…Complete our training &amp; certification program designed to get you up to speed with our business and our customers. You’ll learn about our business, product, vision, and team, and gain an understanding about how your role fits into the AQ family.Speak fluently about our customer segments and the businesses that buy and sell real estate who use our product.Understand the fundamentals about real estate, how buildings work, and why the real estate industry buys and sells iconic skyscrapers across the cities of the USParticipate in weekly team meetings, and get up to speed with our development processDevelop familiarity with our current deployed data modelsDevelop familiarity with our current data pipelines, ETL/ELT processes &amp; patterns, codebases, and software applicationsDevelop familiarity with our Data Engineering frameworks and tools (Databricks, Airflow, DBT, and Snowflake)Establish a regular cadence of reporting your weekly accomplishments and challenges to your managerWithin 3 Months you will…Design, launch, and measure the impact of an improvement to an existing feature.You’ll understand the current state of the functionality and the unmet need; explore ways to iterate and build on what is there; and converge on the best solution given what you’ve learned Report on the outcomes of one of your launches to the engineering &amp; product teams.You will discuss how well goals and hypotheses were met, and what learnings to use in the next iteration.Within 6 Months you will…Launch a feature from start to end as the primary engineering owner.You will execute the architecture and partner with engineering &amp; product leadership to ensure that the right MVP is built and launched.Proactively identify and unblock knowledge sharing and communication challenges to unlock a scalable data engineering organizationEducate, mentor and train team members across the engineering teams on data engineering methodology and philosophyWithin 12 Months you will…Form strong opinions about our Roadmap and what we should be building based on your technical knowledgeBecome a critical voice and contributor to strategic discussions across ProductIs this role not a perfect fit?Sign up to stay in touch. We have new positions regularly and we’d love to reach out to you first when it opens up!We are committed to equal opportunities and creating an inclusive environment for all our employees. We welcome applicants regardless of ethnic origin, national origin, gender, race, religious beliefs, disability, sexual orientation or age. Aquicore is an EEOC.",16467,USA,remote,Data Engineer,2022-01-26T15:51:20Z,nbocqtriis-data-engineer,approved,"['Airflow', 'AWS', 'Data pipelines', 'Data Warehousing']",fulltime
https://boards.greenhouse.io/flocksafety/jobs/5858180002?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/2ol4g0m97m.webp,Flock Safety,flock-safety,Flock_Safety,"Eliminate Crime. Build Community. Flock Safety provides a public safety operating system that empowers private communities and law enforcement to work together to eliminate crime. We are committed to protecting human privacy and mitigating bias in policing with the development of best-in-class technology rooted in ethical design, which unites civilians and public servants in pursuit of a safer, more equitable society. Our Safety-as-a-Service approach includes affordable devices powered by LTE and solar that can be installed anywhere. Our technology detects and captures objective details, decodes evidence in real-time and delivers investigative leads into the hands of those who matter. While safety is a serious business, we are a supportive team that is optimizing the remote experience to create strong and fun relationships even when we are physically apart. Our flock of hard-working employees thrive in a positive and inclusive environment, where a bias towards action is rewarded. Flock Safety is headquartered in Atlanta and operates nationwide. We are well funded by Meritech Capital, Initialized Capital, YCombinator, Matrix Partners, BedRock Capital, and Founders Fund - and we're scaling quickly.About the opportunityAs a Data Engineer, you will lead the design and implementation of data solutions to enable our internal and external-facing engineering teams effectively leverage its data, better automate its processes, and monitor and react to its models’ outputs.Some challenges you’ll tackleConnecting and aggregating various data sources into data warehousesCreating pipelines and data stores for specific use casesEvidence Search and Advanced SearchMachine Learning Active LearningMachine Learning Quality MonitoringAggregating Company Operational MetricsAbout YouExperience with Data Storage (e.g. RDBMS, RedShift, Druid, Elastic, HDFS, Hudi, InfluxDB, Cassandra, Neo4j)Stream Processing (e.g. Kinesis, Kafka, Storm, Flink, Spark)Task Schedulers (e.g. Airflow, Prefect, Luigi)Monitoring (e.g. Grafana, Prometheus)Experience is Data Engineering AWS servicesBasic git knowledgeAble to take on complex problems, learn quickly, iterate, and persist towards a good solutionEffectively communicate, at the level of your audience, and seek to understand and be understoodWhy join the Flock? When you join the Flock, you are joining a diverse team of passionate, ambitious, intelligent people that put the team over self. We offer competitive salary, benefits, and the opportunity to grow your career at a fast-paced, high growth start up. We genuinely care about the well-being of our employees both in and out of the office and understand the importance of work/life balance. We’d love for you to join us in the fight to eliminate non-violent crime, one neighborhood at a time.",16453,Worldwide,remote,Data Engineer,2022-01-26T15:52:17Z,2ol4g0m97m-data-engineer,approved,"['Airflow', 'AWS', 'Cassandra', 'Engineering']",fulltime
https://boards.greenhouse.io/paddle/jobs/5816986002?gh_jid=5816986002&ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ky7mcc3xto.webp,Paddle,paddle,PaddleHQ,"What do we do?As the SaaS space expands, there’s more potential than ever for growing software companies.  Having a great product is only part of the journey. B2B SaaS companies today face endless competition, live or die by customer acquisition costs, have to earn customer loyalty every day, need to operate across borders, and must navigate increasingly complex regulations. Our all-in-one platform is purpose-built for modern SaaS execution and already powers growth for over 2000 software companies, globally. Our Revenue Delivery Platform integrates checkout, payment, and subscription management, making it easy for businesses to activate new business models, enter new markets, turn on new offerings, and renew subscriptions without friction and we handle compliance globally, so our Sellers always operate with full integrity.  The role:  Reporting into the Data Engineering Team Lead, you will be responsible for the delivery of technical solutions to implement Paddle’s data systems. You will collaborate with the wider engineering team and support analysts decentralized across the organization.What you'll do: Leverage your experience and skills to establish the best architecture.Work closely with decentralized analysts (Commercial, Finance, etc.) to identify requirements and develop the necessary data solutions to deliver against those requirements.Build, maintain and run efficient data pipelines.Apply data transformation logic including advanced aggregations and data wrangling techniques.Practise DevOps, you’re responsible for getting your code to production and maintaining it.Explore and use the right tools for the job, backing your choices constructively.Help design a stable platform to support phenomenal growth.We'd love to hear from you if you are: You are a skilled Data or Software Engineer with significant proven experience working in a fast paced growing company and with a passion for Data.Solid development background with Python.Good experience working with IaC tools (we use Terraform).Experienced leading data engineering projects in a high velocity product driven environmentYou champion designing and building systems to handle high traffic at scale in a cloud-based environment in AWS. Experience with Jenkins, Kibana, Grafana &amp; Prometheus highly desirable.Good understanding of data modelling. Experience with Redshift and/or Snowflake is a plus.Experience with batch processing frameworks, preferably familiarity with DBT, Apache Airflow, or similar a plus.Experience with Fivetran, Matillion, Stitch, or similar (we use Fivetran) a plus.Experience with message brokers and stream processing technologies e.g. KinesisFamiliarity with BI tools such as Looker, Tableau, Sisense or similarStrong attention to detail to highlight and address data quality issuesWhy you’ll love working at PaddleWe are a diverse team of 200 and growing people. We care deeply about enabling a great culture which is inclusive no matter your background. We celebrate our diverse group of talented employees and we pride ourselves on our transparent, collaborative, friendly and respectful culture. We live and breathe our values, which are:Exceptional TogetherSolve for the CustomerExecute with impactBetter than YesterdayWe offer a full suite of benefits, including attractive salaries, stock options, pension plans, private healthcare, a health &amp; wellbeing platform and coaching sessions. We are a ‘digital-first’ company, which means you can work remotely or from our amazing office if you prefer, or even a bit of both! We offer all team members unlimited holidays. We love our casual dress code, annual company retreats and much more. We truly invest in learning and will help you with your personal development, from constant exposure to new challenges, an annual learning stipend to regular internal and external training.Our MissionOur mission is to help software companies succeed — enabling them to focus on creating products the world loves. Hundreds of companies rely on our e-commerce platform to sell their software products globally, as well as our powerful analytics and marketing tools to understand and grow their businesses.Our vision is to become the platform that all software companies use to run and grow their business. We aim to replace a fragmented ecosystem of specialised tools with a unified platform that removes the complex burden that comes with running a software business, whilst also providing unparalleled insight to help them grow faster.Deloitte Fast 50 named us amongst the fastest growing software companies in the UK four years running, and we’ve raised over $93m in funding from incredible investors such as FTV Capital, Kindred, Notion, and 83North.Equal opportunitiesWe believe in having diverse teams in which everyone can be their authentic self is key to our success. We encourage people from underrepresented backgrounds to apply and we don't discriminate based on race, colour, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, marital status, disability or age. ​Our office is wheelchair friendly and we are a family-friendly employer​.",16450,London or Remote,flexible,Staff Data Engineer,2022-01-26T15:53:47Z,ky7mcc3xto-staff-data-engineer,approved,"['Airflow', 'AWS', 'Data pipelines', 'Engineering']",fulltime
https://boards.greenhouse.io/jasper/jobs/5855655002?ref=datastackjobs.com&utm_source=datastackjobs.com,softwareengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ioxpumdpes.webp,Jasper,jasper,jasperhealthinc,"<a href=""https://www.hellojasper.com/"">Jasper Health is a fast-paced company with a noble mission to provide a digital experience to improve the lives of cancer patients and their caregivers throughout their treatment and remission journeys. The company announced its <a href=""https://www.businesswire.com/news/home/20210512005663/en/Jasper-Health-Launches-Comprehensive-Support-Platform-for-Individuals-With-Cancer-and-Their-Caregivers"">official launch and was covered by high impact media outlets including <a href=""https://www.usatoday.com/story/tech/2021/05/12/cancer-care-website-managing-chemo-side-effects-caregivers/5037814001/"">USA Today, and <a href=""https://hitconsultant.net/2021/05/12/jasper-health-cancer-care-platform-launch/#.YKQk0JNKg3g"">HIT Consultant. A few months later, Jasper announced its first large-scale client with <a href=""https://www.prnewswire.com/news-releases/employer-direct-healthcare-and-jasper-health-to-partner-on-groundbreaking-oncology-solution-301376300.html"">Employer Direct Healthcare which covers over 2MM lives across hundreds of employers. Jasper Health is funded and supported by <a href=""https://redesignhealth.com/"">Redesign Health, with a recent round of funding led by <a href=""https://www.7wireventures.com/"">7wire Ventures, known for such digital health stand outs as Livongo, which merged in an $18.5 billion transaction with Teladoc late last year.We are currently focused on the 100M+ patients living with cancer, as well as their loved ones who provide care and support throughout treatment and recovery. 38% of people will be diagnosed with cancer in their lifetime, yet no one plans for it. Of those, 65% don’t know what to expect, leading them to feel overwhelmed and out of control—ultimately affecting both their quality of care and quality of life. What We’re BuildingIn late 2020 we launched our first product, the Jasper Smart Planner which enables patients to organize their care and track daily symptoms and side effects. This year, we followed these initial features with medication tracking, biometric tracking (including a Fitbit integration), a tailored content library, and we recently launched Recommendations—providing patients with personalized suggestions for clinical and care-based actions. We are seeing incredibly strong early traction with both consumers and the B2B marketplace, and Jasper recently passed 11,000 registered members. Reporting to the Chief Data Scientist, the Sr. Data Architect is responsible for the strategic direction and leadership for the overall data operations, which includes architecting and building the Jasper Data Warehouse, ETL processes and framework and the BI environment. This role is to effectively and efficiently manage the architecture of Jasper’s data operations to enable Jasper to deliver data driven experiences for our members. As the personalized data driven experiences increase, so too will the enrollment into and engagement with Jasper increase. This crucial role allows Jasper to fulfill the mission of helping and improving the lives of cancer patients and their loved ones. Role and ResponsibilitiesUnderstand the data needs of stakeholders across the businessResponsible for the design of scalable &amp; fault tolerant data applications on Cloud Platforms to store &amp; process terabytes of data from upstream sources with high availabilityPartner with information architects, platform architects, data scientists and product management on solution requirements to design solutionsWork with the quantitative teams to understand data requirementsDesign solutions that enable the efficient and reliable extraction of insight from all captured healthcare, device and behavior dataDesign processes that ingest, transform, enrich and store a combination of structured (healthcare data, EHR, PROs, Device etc.) and unstructured data (e.g. Notes, Radiology Images etc.), guaranteeing data quality and availabilityContinuously evaluate external data sources to make sure that we have the most accurate data available, backfilling historically when requiredParticipate in product design, implementation, and quality assuranceRecommend improvements to the process both in terms of data collection, data consumption and storageResolve high impact problems/projects through in-depth evaluation of complex business processes, system processes, enterprise standards &amp; proceduresEnforce data management standards and proceduresResponsible for design, testing oversight and production implementation using BigQuery, Pub/Sub, Data Catalog, DataFlow and GCPPartner with multiple teams to ensure appropriate data solutions to meet goals as well as identify and define necessary system and process enhancementsConduct personnel duties for direct reports (e.g. mentorship, performance evaluations or hiring)Oversee data engineering agile teams to deliver against sprint and program increment objectivesEngage in business partner engagement; management of relationship and inter-group planning among technology leadership/peers Core Competencies Must have prior experience as a Data Warehouse, BI and ETL Technical ArchitectStrong experience and deep understanding of ETL, data warehousing, data lake technologies and analytics conceptsExperience owning multiple mission critical applications on big data platformExperience with batch and real-time data pipelines in a DevOps environmentWilling to work in a fast-paced environment with globally located Agile teams working in different shiftsAbility to develop and maintain strong collaborative relationships at all levels across Business StakeholdersExcellent written and oral communication skillsAdept and presenting complex topics, influencing and executing with timely / actionable follow-through Qualifications and Education RequirementsProven track record of design of an analytical environmentMust have a bachelor's degree in Computer Science, Engineering, or a related field4+ years of experience in a related field or role Knowledge, Skills and Abilities RequiredPrior work experience in healthcareExperience working with payer claims dataExperience working with provider EHR dataExperience building environments for or working with data-driven statistical modelsExperience dealing with sensitive data in a highly regulated environmentDemonstrated implementation of complex and innovative solutionsArticles and publications in the field of data engineeringBe the captain of the team, lead by example, motivate, and work together as a team Benefits IncludesPaid Time Off (PTO)Health, Dental, &amp; Vision InsuranceFlexible Spending AccountsEmployee Assistance ProgramAnd more... Conditions of EmploymentYou must be authorized to work in the United StatesApplicants will be required to pass a background check as a condition of employment Equal Employment Opportunity PolicyJasper Health, Inc. provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state or local laws.This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.",16445,Worldwide,remote,Sr. Data Architect,2022-01-26T15:49:03Z,ioxpumdpes-sr-data-architect,approved,"['Big Data', 'BigQuery', 'Dataflow', 'Data pipelines']",fulltime
https://boards.greenhouse.io/glooko/jobs/3848717?ref=datastackjobs.com&utm_source=datastackjobs.com,softwareengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/mvu6rpdqac.webp,Glooko,glooko,diasend,"About the Role:Mentor a team of engineers to design and develop Data platform.Design and implement data platform architecture, data ingestion pipelines and data infrastructure.Collaborate with product management and data engineering leadership to understand the requirements and design new products or extensions to existing products.Provide technical oversight to the development process including code reviews and mentoring of the technical team.Collaborate with engineering, data scientist, cloud infrastructure and security teams to understand the requirements and develop highly scalable system design and architecture.Define goals and metrics for the team and establish a process for regular assessment and improvement.Communicate effectively the status, risks and mitigation strategies to the leadership team. About You:Bachelor or Master Degree in Computer Science, Math, or Engineering.10+ years of working experience in software development.5+ years experience in designing and developing REST APIs and/or web applications.Experience with development of large-scale distributed Web services Infrastructure and Microservices.Experience with real-time data processing systems (e.g. Spark,, Storm, Kafka, Flink).Experience with modern data platforms such as Snowflake, Spark, Hive, and Pig.Experience with a variety of data stores such as MongoDB, Cassandra, HBase, MySQL.Experience with AWS environment e.g., Amazon Kinesis, Lamdba, DynamoDB and Redshift.Experience with programming languages such as Java &amp; Python.Experience managing globally distributed teams.Experience building multi-tenant SaaS applicationsExperience with development of large-scale distributed Web services InfrastructureExperience with development of data InfrastructureExperience with containerization platforms (Docker) and container orchestration toolsExperience with Microservices Architectures, AWS and Lambda functionsHave demonstrated ability to mentor other software developers to maintain software quality and adopt right architectural principles.Have a deep understanding of functional and design patterns with a focus on performance, security and scalabilityHave experience and knowledge of Scrum and Agile tools. JIRA and Atlassian tools experience is a Plus. About Glooko:There are over 420 million people in the world with diabetes and Glooko helps those people, as well as their physicians and care team, manage the disease more easily and cost effectively. Glooko is the Unified Platform for Diabetes Management providing an FDA cleared, HIPAA compliant Web and Mobile (iOS and Android) application for people with diabetes and the clinicians who treat them. Glooko’s products seamlessly unifies data from over 200 of the leading blood glucose meters, insulin pumps, continuous glucose monitors, activity trackers, and biometric devices to deliver insights that improve personal and clinical decision support.Glooko’s mobile app and web dashboard enable patients to easily track and proactively manage all aspects of their diabetes care. Glooko’s Population Tracker and APIs offer diabetes-centric analytics and supply insightful reports, graphs and pattern-triggered notifications to patients, health systems, and payers. The Glooko platform also allows customers and third-party developers to create branded modules for Glooko users. The most recently created business unit is Glooko Research, which offers a clinical research platform for pharmaceutical companies, CROs, medical devices companies and other players within the industry.Launched in 2010, Glooko is funded and managed by visionary technologists and leaders in healthcare.Glooko's Perks and Benefits Include:Competitive salary based on experiencePre-IPO stock incentivesFull benefits: medical, dental, vision, and transportation incentives401(k) matching programHardware to get the job doneInternet/cell phone reimbursementAnnual reimbursement for our Employee Well-Being stipend which encourages employees to invest in any combination of fitness equipment/fitness activities or home office/ergonomics related itemsGenerous annual reimbursement for our Glooko Professional Development ProgramHave a meaningful impact on people’s lives Glooko provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, marital status, or disability. In addition to federal law requirements, Glooko complies with applicable state and local laws governing nondiscrimination in employment in every location in which the company has facilities. This policy applies to all terms and conditions of employment, including recruiting, hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training.Posted positions are not open to third party recruiters/agencies and unsolicited resume submissions will be considered free referrals.",16432,USA,remote,Software Architect (Data Engineering),2022-01-26T15:47:23Z,mvu6rpdqac-software-architect-data-engineering,approved,"['AWS', 'Cassandra', 'Engineering', 'Healthcare']",fulltime
https://boards.greenhouse.io/beat/jobs/3832985?gh_jid=3832985&ref=datastackjobs.com&utm_source=datastackjobs.com,machinelearning,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/6buhpdbybz.webp,Beat,beat,thebeatapp,"About usBeat is the fastest growing ride hailing app in Latin America and a part of the international FreeNow Group, the multi-service mobility joint venture backed by BMW Group and Daimler AG. One city at a time, we are on a mission to develop seamless mobility for a safe and sustainable urban life. We are proud to say we have launched Beat Tesla / Loonshot, the first and largest private all-electric vehicle service in Latin America. As an organization, we are committed to our drivers with ethical practices and a safe working environment. To our customers, we differentiate ourselves from other ride-hailing apps with our super user-friendly app and excellent customer service. Last but not least, our priority is to maintain a hyperlocal approach in everything we do, from product to operations to marketing.We are proud to see Beat leading the FreeNow group in growth in 2021 and we have ambitious plans for 2022. But we need you to help us get closer to our vision: ​​a connected Latin America where the only question is “Where Next?”We are currently operating in Mexico, Argentina, Chile, Colombia, Peru and Greece and are transporting over 24 million riders with the support of more than 700,000 drivers. Our global headquarters are in Athens - where BEAT started back in 2011. We also have offices in Amsterdam.Our employee base is spread out even wider. We mastered the hybrid workspace with our office and remote locations even before Covid-19. So if you are interested in joining us on our mission, whether based in one of the countries we operate or elsewhere in the world, we are happy to hear from you! About the roleWe’re looking for a Senior Machine Learning Engineer to join the Machine Learning team within the Matching Domain.The domain has all necessary crafts to allow us to achieve our goals autonomously and consists of a Product team (Product Managers, Data Analysts and Designers) and Engineering (Backend, Frontend, Data and ML). The domain has the following areas of responsibility:Dispatch, orchestrating the whole matching workflow between passenger and driversMatching, trying to find the optimal driver for a passengerMapping, providing map-related services to all domains in the companyOur teams work in a virtual office setup, with overlapping hours and a mixture of sync and async communication methods. You’ll be reporting to the ML team’s Engineering Manager.What’s the day to dayThe ML team is working across all projects within Matching Domain. We are responsible for intelligently matching drivers to users' ride requests using driver and passenger behaviour modelling. We also estimate the total duration of rides using ML models and we apply data-driven insights and heuristics to optimally configure the Matching’s flow parameters. We are concerned with the whole lifecycle of the development of a ML/DS product as our work starts with formalizing the business requirements and follows all appropriate steps until a well performing, ML-powered solution gets into BEAT’s production flow.Our marketplace team work on matching drivers with passengers, focusing on the best optimisation of this, so the main challenge is the balance of dynamic pricing to keep the drivers earnings optimised and the passengers fair lower. If you can help us solve these challenges, we want to hear from you! What you will do Work within a cross-functional team, highly skilled in data science, machine learning, software engineering and data engineering.Understand product requirements and formulate suitable ML-based POCs to satisfy them.Convert successful POCs to fully-fledged ML-based product features and put them in BEAT’s production flow in collaboration with Matching’s domain’s backend teams.  Evaluate ML features/models both offline and online through AB tests and online performance monitoring.Maintain and improve the performance of existing solutions. Take full ownership of your work, being able to lead and mentor junior to mid level teammates.Be part of BEAT’s ML Chapter, a community of ML engineers across the company, formed with the purpose of knowledge sharing across different teams. What you need to bring Master's degree in Computer Science or in a related STEM field. Higher degrees are highly appreciated.Solid understanding of methods, concepts, models, evaluation schemes across the whole DS/ML landscape, eg. supervised learning, unsupervised learning, data mining etc.Solid coding experience in Python.Solid experience in working the full software development lifecycle using the industry’s best practices. Knowledge of SQL and relational databases. What is useful to have:Hands-on experience with MLOPs frameworks such as Kubeflow, MLFlow, (Azure ML Studio) or Amazon Sagemaker.Hands-on experience with Apache Spark.Hands-on experience with Docker and Kubernetes.About the interview process at BEATDuring our interview process, we want to learn about you but also provide you with a good understanding of what it’s like to work at Beat. We will introduce you to several team members and stakeholders to make sure you can ask all your questions.Here is what you can expect:An initial conversation with a member of the Talent Acquisition teamAn introductory meeting with your potential future managerFor tech roles, there is a take home assignment that you will need to submit by the agreed deadlineThe last stage of the interview process will be meetings with the team and internal stakeholders.Throughout the process, our Candidate Experience team will be there to support you and ensure that you have a great time interviewing with us. What's in it for you:Competitive full-time salaryFlexible working hours, top Line toolsWorking in a hyper-growth environment, you will enjoy numerous learning and career development opportunities A great opportunity to grow and work with the most amazing people in the industryBeing part of an environment that offers challenging goals, autonomy and mentoring, which creates incredible opportunities, both for you and the company.As part of our dedication to the diversity of our workforce, Beat is committed to Equal Employment Opportunity without regard for race, colour, national origin, ethnicity, gender, disability, sexual orientation, gender identity, or religion.",16248,Worldwide,remote,Senior Machine Learning Engineer,2022-01-23T21:24:51Z,6buhpdbybz-senior-machine-learning-engineer,approved,"['Matching', 'Azure', 'Data Mining', 'Kubernetes']",fulltime
https://boards.greenhouse.io/appdirect/jobs/5844384002?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/koiidhcdzb.webp,AppDirect,appdirect,AppDirect,"About AppDirectBecome a digital, global citizen and enable the new generation of digital entrepreneurs around the world. AppDirect offers a subscription commerce platform to sell any product, through any channel, on any device - as a service. We power millions of subscriptions worldwide for organizations. We do this by our values-driven culture - one that enables you to Be Seen, Be Yourself, and Do Your Best Work.About YouAs a Data Engineering Team lead, you’re a highly technical, hands-on and experienced developer with the ability to manage and lead a small team. You will play a pivotal role in designing, architecting and overseeing the development of critical services while coaching and mentoring a group of developers. You are responsible for driving the vision and roadmap of the team while collaborating with other parts of the organization and cross-functioning teams.What You’ll Do and How You’ll Make an ImpactLead, support and mentor a team made up of Data Engineers. You will own performance management for your team (i.e. objectives setting, performance reviews and career development) as well as recruitment and overall team management.Technically coach engineers by reviewing technical designs and code as well as through technical talks .Partner with the Product Manager, Designer, and other Engineering Managers and Tech Leads to collaborate and build awesome reporting experience.Lead efforts enabling the team and our Cloud Data Pipelines to scaleCoach members of the team about industry-leading tools and techniquesModernize our Cloud Data Pipeline strategy to enable the business, engineers and customersCollaborate with our reporting team to build insightful dashboardsWork with Engineering and Architecture teams to develop new organizational standardsMigrate current batch ETL to new streaming data pipelinesImprove efficiency by enabling internal stakeholders with self-served data solutionsResearch solutions to complex problems and drive proof-of-conceptsAuthor and maintain knowledge base through high-quality documentationDeliver quality solutions/process through CICD and automationWhat You’ll NeedYou are a technical leader with a real passion for development and with a strong product sense.Experience with developing in modern programming language (e.g., Scala, Java, SQL, Python.Exposure to some of the following technologies: Apache Spark &amp; Flink, AWS &amp; Azure, Docker &amp; Kubernetes, CDCUnderstanding of Data Schemas (e.g. SQL, JSON, Avro, Protobuf)Experience automating, producing and consuming data in real time from event driven microservices using streaming platforms like KafkaProven experience building data pipelines and data solutions aligned to Business Architecture, operational and analytics use cases.Good knowledge and understanding of data structures and experience handling large data setsComfortable in code reviewing other engineers' code and driving/reviewing technical designs..Ability to self-manage, think critically, handle multiple tasks and/or projects and deliver solutions autonomouslyAbility to clearly communicate complex ideas to a technical and non-technical audience At AppDirect/AppSmart, we believe that innovation thrives in an environment that houses diversity of excellence, experience and thought. We respect each AppDirector as their own fingerprint; unique with no one alike. We foster an environment of inclusion without regard to race, religion, age, sexual orientation, or gender identity enabling AppDirectors to embrace their uniqueness to do their best work. As such, we strongly encourage applications from Indigenous peoples, racialized people, people with disabilities, people from gender and sexually diverse communities, and/or people with intersectional identities.",16237,Canada,remote,Data Engineering Team Lead,2022-01-23T21:23:00Z,koiidhcdzb-data-engineering-team-lead,approved,"['Avro', 'AWS', 'Azure', 'Data pipelines']",fulltime
https://boards.greenhouse.io/life360/jobs/5667321002?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/dbkesybeg4.webp,Life360,life360,Life360,"Life360 is a Remote First company, which means a remote work environment will be the primary experience for all employees. All positions, unless otherwise specified, can be performed remotely (within the US) regardless of any specified location above. About Life360Life360 is on a mission to bring families closer— and that starts with ensuring that loved ones are safe and secure. That’s why millions of families across 140 countries trust Life360 to keep them connected each day, and in life’s unpredictable moments.From real-time location sharing and notifications, to driving safety features like Crash Detection and Roadside Assistance, we create tools that remove uncertainty from modern life — so families can feel free, together.About the JobLife360 collects and processes several hundred billion location points, over a hundred billion user events, and billions of miles driven on a monthly basis. As a Senior Data Engineer, you will contribute to enhancing and maintaining our data processing and storage pipelines/workflows for external and internal data consumers. You will be a key member of our Data Partnerships team responsible for efficient and highly resilient, high-volume data pipelines. You should have a strong engineering and support background and, more importantly, a desire to take ownership of our data systems and drive to make them world-class. What You’ll DoDesign and develop resilient data processing pipelines using a variety of open-source technologies.Manage data from ingestion through transformation to delivery, in batch and near real-time. Coordinate onboarding of new data customers and support existing data customers. Actively monitor the health of the data pipelines and identify opportunities to add or improve automation in data handling. Support business customers as they look to answer data-oriented questions in support of business growth. Test, harden, and automate new and existing data workflows. Participate in rotational on-call support and provide ongoing maintenance of the data infrastructure. Be a key member of a fast-growing data team handling massive scale through sophisticated processing and automation. What We’re Looking ForMinimum 4+ years of experience developing and supporting high volume data systems. Extensive programming experience: Python/Java preferred. Experience in data modeling, writing optimized SQL, and system performance tuning. Knowledge and proficiency in the latest open-source data frameworks. Experience with AWS-based data-related services. Experience evaluating industry trends and technologies.Continuous learning to stay up to speed in the fast-moving big data world.Our BenefitsCompetitive pay and benefitsMedical, dental, vision, life and disability insurance plans (100% paid for employees)401(k) plan with company matching programEmployee Assistance Program (EAP) for mental wellness.Flexible PTO and 12 company wide days off throughout the yearLearning &amp; Development programsEquipment, tools, and reimbursement support for a productive remote environmentFree Life360 Platinum Membership for your preferred circleLife360 ValuesOur company’s mission driven culture is guided by our shared values to create a trusted work environment where you can bring your authentic self to work and make a positive difference Build A High Performing Team – Communicate Directly, Be a Good PersonMake Things Happen – Take Ownership, Think Long TermDeliver an Exceptional Experience – Users Come First, Quality &amp; CraftsmanshipOur Commitment to DiversityWe believe that different ideas, perspectives and backgrounds create a stronger and more creative work environment that delivers better results. Together, we continue to build an inclusive culture that encourages, supports, and celebrates the diverse voices of our employees. It fuels our innovation and connects us closer to our customers and the communities we serve. We strive to create a workplace that reflects the communities we serve and where everyone feels empowered to bring their authentic best selves to work.We are an equal opportunity employer and value diversity at Life360. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status or any legally protected status.  We encourage people of all backgrounds to apply. We believe that a diversity of perspectives and experiences create a foundation for the best ideas. Come join us in building something meaningful.____________________________________________________________________________Since the majority of our staff is located on the US West Coast, our primary working hours will be 9-4pm PST",16230,USA,remote,"Senior Data Engineer, Data Partnerships",2022-01-23T21:21:26Z,dbkesybeg4-senior-data-engineer-data-partnerships,approved,"['AWS', 'Big Data', 'Data pipelines', 'Engineering']",fulltime
https://boards.greenhouse.io/celonis/jobs/4798902003?ref=datastackjobs.com&utm_source=datastackjobs.com,softwareengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/xcveig27jo.webp,Celonis,celonis,Celonis,"Senior Software Engineer (Machine Learning)Welcome to Celonis, the global leading Process Mining software company and one of the world's fastest-growing SaaS firms. We believe that every company can unlock its full execution capacity and for that, we need you to join us as a Machine Learning Engineer.The Team:For our Applied Machine Learning Team we are looking for a Software Engineer with a Machine Learning focus, who will be part of a dynamic team that is responsible for the design and implementation of end-to end products for the currently existing and future ML pipelines/ products. The Role:Alongside each member of the team you will be responsible for design and implementation of end-to end products. Furthermore, you will increase the software development ability within the team and ensure sustainable product life-cycles. In this role you will also have the opportunity to get involved with complex code reviews and architectural discussion with high level platform architects.Requirements:Strong engineering background with very good hands-on-experience of Python and exposure to one or more programming language (Java preferred), as well as engineering best practices (logging, monitoring and alerting)Previous experience in working with and developing Machine Learning products (to include Infrastructure, Models and Pipelines)Industry experience creating and productionising Machine Learning algorithms at scaleWorking knowledge of DevOps (Kubernetes and Docker key) Highly experienced in writing efficient, readable and testable codeA true problem solver and excellent team playerMSc / Masters in a relevant Computer Science topicMust have excellent English skills, German is a plus What Celonis can offer you:The unique opportunity to work within a new category of technology, ExecutionManagementInvestment in your personal growth and skill development (clear career paths,internal mobility opportunities, mentorships, yearly development stipend)Great compensation and benefits packages (stock options, 401(K) matching,generous time off, parental leave, and more)Work from home support (mindfulness tools such as Headspace, monthlyremote working stipend, flexible working hours, virtual events and workshops)A global and growing team of Celonauts from diverse backgrounds to learnfrom and work withAn open-minded culture with innovative, autonomous teamsEmployee resource communities to help you feel connected, valued and seen (Women@Celonis, Parents@Celonis, Pride@Celonis, Resilience@Celonis, and more)A clear set of company values that guide everything we do: Live for CustomerValue, The Best Team Wins, We Own It, and Earth Is Our FutureAbout Us:Celonis believes that every company can unlock its full execution capacity. Powered by its market-leading process mining core, the Celonis Execution Management System provides a set of applications, and developer studio and platform capabilities for business executives and users to eliminate billions in corporate inefficiencies. Celonis has thousands of global customers and is headquartered in Munich, Germany and New York City, USA with 15 offices worldwide. Celonis is an equal opportunity employer. We celebrate diversity and are committed to creating an inclusive environment for all employees. <a href=""https://www.celonis.com/careers/diversity/"">Different makes us better. ",16223,Munich based OR remote in Germany,flexible,Senior Software Engineer (Machine Learning),2022-01-23T21:20:07Z,xcveig27jo-senior-software-engineer-machine-learning,approved,"['Engineering', 'Java', 'Kubernetes', 'Machine Learning']",fulltime
https://boards.greenhouse.io/appannie/jobs/3854035?gh_jid=3854035&ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/llojfrughh.webp,App Annie,app-annie,appannie,"Something about us...App Annie is the industry’s most trusted mobile data and analytics platform. Our mission is to help customers create winning mobile experiences and achieve excellence. We created the mobile app data market and are committed to delivering the industry’s most complete mobile performance offering. More than 1,300 enterprise clients and 1 million registered users across the globe and spanning all industries rely on App Annie as the standard to revolutionize their mobile business. We are a global company, headquartered in San Francisco but as a “remote” first company, we care about your results and not your location. Along with a market defining product, we take great pride in our culture and values and strive to embody them daily! We set a high bar for our success and have made Excellence as our standard, hold each other Accountable, continuously push Innovation and Win with Style.What can you tell your friends when they ask you what you do?As a Big Data Engineer, I’m a key contributor to the design, implementation and ongoing governance of App Annie’s data products. I’m responsible for expanding and optimizing our large-scale data ingestion flows and our data processing pipelines to create transparency and consistency across the entire Data Science system architecture. I work closely with Product Managers, Data Scientists, Data Analysts and other Big Data and Business Intelligence Engineers to develop and sustain the governance of our data products, including conceiving and building large-scale data integration solutions. I’m passionate about what I do and excited to do it in the context of an entrepreneurial start-­up with a phenomenal team.You will be responsible for and take pride in….As a Big Data Engineer, you will be an integral part of a team responsible for large-scale data processing pipelines across our Intelligence Product. You will also help to expand our product governance processes and support the Data Science team in building new product features. This includes:Ability to work with large, complex data sets that meet function and non-functional business requirementsWorking as engineer in building the infrastructure required for optimal extraction, transformation and loading of data from a wide variety of data sources using SQL, Apache Spark, AWS S3, Databricks, SnowflakeAbility to design and optimize queries, scripts and data tools to provide increased visibility into the Data Science system architectureThe ability to communicate well and clearly with teams and team members across multiple time zones and countries.Designing, building, and supporting large scale, fault-tolerant distributed systems that support App Annie’s data science and analytics teamsYou should recognize yourself in the following...You should be a strong tech lead with proven experience in distributed systems, and big data analysis.Bachelor’s degree in Computer Science / Engineering or equivalent experienceAt least 2-3 years in software development, with multiple examples of delivering innovative product ideasDeep understanding of hardware and computer organization, Linux operating system, computer network and compilers etc.Solid skills of big data related data structures and algorithmsProficient in data modeling and data warehouse design Experience in designing architecture is a big plusProficient programming experience in SQL Proficient programming experience in at least one mainstream language, like Python, Scala or Java Experienced in data processing such as ETLFlexible mindset and the ability to prototype and change direction rapidly as research evolvesStrong problem solving, analytical and troubleshooting skillsA seasoned engineer with big data ecosystem (Computation: Mapreduce, Spark/Flink, Presto/Hive/Redshift/Snowflake etc.; Storage: Postgresql, Elasticsearch, HDFS, Kafka etc.), experience AWS/Google Cloud/Microsoft Azure is a big plusAn excellent communicator with a knack for concisely explaining problems and solutions to multiple stakeholders, e.g. product managers, senior management, etc.A strong drive to continue learning and developingIndependently making decisions quickly based on your expertise Demonstrated ability to produce results as part of a highly distributed team that crosses cultural and country boundariesEnergy and creativity are key characteristics that describe you and the projects you are involved in. You make it happen. Boom!This is what we offer...We provide a $1,000 reimbursable WFH allowance to set you up for remote work success.Internet allowance for stable internet connection, so your video does not freeze on Zoom. Flexible working days. We love to meet, but if you need to get your kids to school-zoom, you need to leave early to get to your band rehearsal or gym classes, do your thing. Paid time off so you can recharge.Health and dental benefits.An international team of talented and engaged people from different cultural backgrounds and locations.Wellbeing allowance for any activity that matters to your wellbeing; (online) gym classes, fitness equipment, mindfulness apps or even childcare support!Unlimited access to our online learning platform Udemy to help you develop your skills.Virtual initiatives and events to keep you connected with your colleagues.Yes, I want this job!",16222,AMER Region,remote,Big Data Engineer,2022-01-23T21:18:43Z,llojfrughh-big-data-engineer,approved,"['AWS', 'Azure', 'Big Data', 'Business Intelligence']",fulltime
https://jobs.lever.co/treasure-data/7e24cb1f-21c8-410f-b2c1-71cbca76f49b?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/aszhdkcr50.webp,Treasure Data,treasure-data,treasuredata,"Treasure Data is seeking a Senior Data Engineer in the US time zone for the Data Engineering Team. Treasure Data began by offering data warehousing and processing services, since then, we’ve moved further up the value chain with our Customer Data Platform application (CDP), which is seeing a lot of traction with customers new and old. Moreover, CDP is the fastest-growing offering we have and is front and center in most major initiatives across the company. The ideal candidate will have the deep technical expertise and strong experience collaborating in a team-oriented environment. Together with the team, you will design, implement, enhance, and advance the data technologies that empower stakeholders to make data-informed decisions faster, with more insights in a timely manner as the Data team aims at “Zero untapped opportunity with data”. The Data team prepares data for various internal data stakeholders and dashboarding. Therefore, we are seeking a proven track record of success and a passion for developing data pipelines that are a central part of data engineering work. You should have knowledge of SQL. <u>Things you will do:</u> Analyzing and organizing raw data; Building data systems and pipelines; Evaluating business needs and objectives; Building reports and interpreting trends and patterns; Preparing data for prescriptive and predictive modeling; Building algorithms and prototypes; Keep up to date on novel technical concepts that we should adopt (and which ones we should ignore); Along with the rest of the team, own and operate the data services that you built;<u>What fun stuff are we doing? </u>Acquisition: Sourcing the data from different systems; Cleansing: Detecting and correcting data errors; Conversion: Converting data from one format to another; Inquiries: Quickly responding to data inquiries from stakeholders; Disambiguation: Interpreting data that has multiple meanings; Deduplication: Removing duplicate copies of data; Presenting: Using various BI tools to visualize data; Corporate Data Strategy: Driving the Corporate Data strategy initiatives;<u>Your background and skills include: </u>Experience building, expanding &amp; improving, and maintaining the data systems; Extensive experience on SQL and working with and maintaining Relational Databases in a production environment; Experience in writing Python code; Designing and building data pipelines with reliability and operations in mind;Strong sense of project ownership and responsibility;Familiar with cloud technologies (AWS) and development/deployment in cloud infrastructure; Strong communication skills with a remote team across time zones; A demonstrated initiative to stay abreast of technology advancements;<u>We would be thrilled if you: </u>Have previous experience working with data; Have contributed to a production level code; Have experience in developing a fully managed cloud service; Have experience with integrating BI tool; Have made open source contributions;Have experience with agile development; Are more importantly willing to take challenges for growth; <u>Who we are: </u>Treasure Data employees are enthusiastic, data-driven and customer-obsessed. Our actions reflect our values of honesty, reliability, openness and humility. Treasure Data moved to remote-based work in March 2020 and is committed to ensuring it remains agile to accommodate shifting preferences of its workforce. While we are not working shoulder-to-shoulder, we still work side-by-side, finding unique ways to connect and create together while also respecting each other’s life priorities outside of work. We offer competitive salary and benefits and named one of the 2021 Best Places to Work. Treasure Data is an equal opportunity employer dedicated to building an inclusive and diverse workforce. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.<u>What we do: </u>Treasure Data is the only enterprise Customer Data Platform (CDP) that harmonizes an organization’s data, insights, and engagement technology stacks to drive relevant, real-time customer experiences throughout the entire customer journey. Treasure Data helps brands give millions of customers and prospects the feeling that each is the one and only. With its ability to create true, unified views of each individual, Treasure Data CDP is central for enterprises who want to know who is ready to buy, plus when and how to drive them to convert. Flexible, tech-agnostic and infinitely scalable, Treasure Data provides fast time to value even in the most complex environments.Agencies and Recruiters: We cannot consider your candidate(s) without a contract in place. Any resumes received without having an active agreement will be considered gratis referrals to us. Thank you for your understanding and cooperation!",16011,North America,remote,Senior Data Engineer,2022-01-20T22:09:38Z,aszhdkcr50-senior-data-engineer,approved,"['AWS', 'Data pipelines', 'Data Warehousing', 'Engineering']",fulltime
https://boards.greenhouse.io/recur/jobs/4303469004?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/mnay3mmpla.webp,RECUR,recur,RecurForever,"RECUR needs a Senior Data Engineer to join our team full time. This is an exciting opportunity to join a fast-growing organization, where you will be designing and building data pipelines for analytics, forecasting and finance activities.What do we at RECUR believe makes a great engineering team? Here are our core beliefs:   It’s important to have team members that care about the team’s results more than their own individual achievementsIt’s important for leadership to be tolerant of making mistakesIt’s important that the team members help, teach, and mentor one anotherIt’s important not to place blame on individuals when things go bad but instead to evaluate as a team how we do it better the next timeIt’s important to be clear on what that mission is and minimize the distractions on the teams executing on that missionSmall teams execute better than big ones, empower small teams with ownership and minimize the dependencies between themIt’s important to encourage self-directed innovationWhat you will do at RECURCollaborate with a distributed team of developers and business stakeholders on a wide variety of data engineering, data integration and business intelligence projects.Explore, document and present new technologies and approaches to the team.Develop and maintain data pipelines and integrations using AWS cloud services and best-in-class tools from the modern data stack.Develop high quality and maintainable software.Test your code using modern automated testing frameworks and practices.“Own” your code throughout the full product life cycle, including production deployment and support, including participation in on-call rotations and critical issue escalations.What you will bring to RECURYou have 5+ years of experience developing data pipelines, data-integrations and/or other data-centric applications.You have advanced, extensive working SQL knowledge and practical experience with relational databases and concepts.You have familiarity with cloud-based databases such as Redshift or Snowflake.You have familiarity with ETL/ELT, BI and orchestration tools and frameworks like Fivetran, DBT, AWS Glue, Tableau, Superset, etc.You are comfortable with applying SDLC process concepts to data pipelines and infrastructure, such as source-control, automated testing, CICD, promotion through multiple environments, etc.You have a passion for leveraging the latest technologies and innovations while still following a rigorous software development life cycle.You learn quickly, are flexible, and do whatever it takes for the team to be successfulYou have an interest in blockchain, cryptocurrency, and NFTsYou are legally eligible to work in the United States or Canada.Benefits &amp; PerksCommitment to being a remote-first companyCompany sponsored Health, Dental and Vision Benefits401k with no waiting period for vesting3 weeks paid vacation and 10 paid company holidaysIndustry focused lunch and learnsCompany swagFlexibility to get the tooling you need to do your best work The chance to work with incredibly passionate people on a mission to shape an industry!",15986,North America,remote,Senior Data Engineer,2022-01-20T22:03:47Z,mnay3mmpla-senior-data-engineer,approved,"['AWS', 'Blockchain', 'Business Intelligence', 'Data pipelines']",fulltime
https://boards.greenhouse.io/beat/jobs/3832985?gh_jid=3832985&ref=datastackjobs.com&utm_source=datastackjobs.com,machinelearning,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/di5wu0xfxn.webp,Beat,beat,thebeatapp,"About usBeat is the fastest growing ride hailing app in Latin America and a part of the international FreeNow Group, the multi-service mobility joint venture backed by BMW Group and Daimler AG. One city at a time, we are on a mission to develop seamless mobility for a safe and sustainable urban life. We are proud to say we have launched Beat Tesla / Loonshot, the first and largest private all-electric vehicle service in Latin America. As an organization, we are committed to our drivers with ethical practices and a safe working environment. To our customers, we differentiate ourselves from other ride-hailing apps with our super user-friendly app and excellent customer service. Last but not least, our priority is to maintain a hyperlocal approach in everything we do, from product to operations to marketing. We are proud to see Beat leading the FreeNow group in growth in 2021 and we have ambitious plans for 2022. But we need you to help us get closer to our vision: ​​a connected Latin America where the only question is “Where Next?”We are currently operating in Mexico, Argentina, Chile, Colombia, Peru and Greece and are transporting over 24 million riders with the support of more than 700,000 drivers. Our global headquarters are in Athens - where BEAT started back in 2011. We also have offices in Amsterdam.Our employee base is spread out even wider. We mastered the hybrid workspace with our office and remote locations even before Covid-19. So if you are interested in joining us on our mission, whether based in one of the countries we operate or elsewhere in the world, we are happy to hear from you!About the roleWe’re looking for a Senior Machine Learning Engineer to join the Machine Learning team within the Matching Domain.The domain has all necessary crafts to allow us to achieve our goals autonomously and consists of a Product team (Product Managers, Data Analysts and Designers) and Engineering (Backend, Frontend, Data and ML). The domain has the following areas of responsibility:Dispatch, orchestrating the whole matching workflow between passenger and driversMatching, trying to find the optimal driver for a passengerMapping, providing map-related services to all domains in the companyOur teams work in a virtual office setup, with overlapping hours and a mixture of sync and async communication methods. You’ll be reporting to the ML team’s Engineering Manager.What’s the day to dayThe ML team is working across all projects within Matching Domain. We are responsible for intelligently matching drivers to users' ride requests using driver and passenger behaviour modelling. We also estimate the total duration of rides using ML models and we apply data-driven insights and heuristics to optimally configure the Matching’s flow parameters. We are concerned with the whole lifecycle of the development of a ML/DS product as our work starts with formalizing the business requirements and follows all appropriate steps until a well performing, ML-powered solution gets into BEAT’s production flow.Our marketplace team work on matching drivers with passengers, focusing on the best optimisation of this, so the main challenge is the balance of dynamic pricing to keep the drivers earnings optimised and the passengers fair lower. If you can help us solve these challenges, we want to hear from you! What you will do Work within a cross-functional team, highly skilled in data science, machine learning, software engineering and data engineering.Understand product requirements and formulate suitable ML-based POCs to satisfy them.Convert successful POCs to fully-fledged ML-based product features and put them in BEAT’s production flow in collaboration with Matching’s domain’s backend teams.  Evaluate ML features/models both offline and online through AB tests and online performance monitoring.Maintain and improve the performance of existing solutions. Take full ownership of your work, being able to lead and mentor junior to mid level teammates.Be part of BEAT’s ML Chapter, a community of ML engineers across the company, formed with the purpose of knowledge sharing across different teams. What you need to bring Master's degree in Computer Science or in a related STEM field. Higher degrees are highly appreciated.Solid understanding of methods, concepts, models, evaluation schemes across the whole DS/ML landscape, eg. supervised learning, unsupervised learning, data mining etc.Solid coding experience in Python.Solid experience in working the full software development lifecycle using the industry’s best practices. Knowledge of SQL and relational databases. What is useful to have:Hands-on experience with MLOPs frameworks such as Kubeflow, MLFlow, (Azure ML Studio) or Amazon Sagemaker.Hands-on experience with Apache Spark.Hands-on experience with Docker and Kubernetes.About the interview process at BEATDuring our interview process, we want to learn about you but also provide you with a good understanding of what it’s like to work at Beat. We will introduce you to several team members and stakeholders to make sure you can ask all your questions.Here is what you can expect:An initial conversation with a member of the Talent Acquisition teamAn introductory meeting with your potential future managerFor tech roles, there is a take home assignment that you will need to submit by the agreed deadlineThe last stage of the interview process will be meetings with the team and internal stakeholders.Throughout the process, our Candidate Experience team will be there to support you and ensure that you have a great time interviewing with us.What's in it for you:Competitive full-time salaryFlexible working hours, top Line toolsWorking in a hyper-growth environment, you will enjoy numerous learning and career development opportunities A great opportunity to grow and work with the most amazing people in the industryBeing part of an environment that offers challenging goals, autonomy and mentoring, which creates incredible opportunities, both for you and the company.As part of our dedication to the diversity of our workforce, Beat is committed to Equal Employment Opportunity without regard for race, colour, national origin, ethnicity, gender, disability, sexual orientation, gender identity, or religion.",15978,Worldwide,remote,Machine Learning Engineer,2022-01-20T22:02:03Z,di5wu0xfxn-machine-learning-engineer,approved,"['Azure', 'Data Mining', 'Engineering', 'Kubernetes']",fulltime
https://jobs.lever.co/sensortower/f0fdd10d-2fb1-435b-995b-6273c07c43fe?ref=datastackjobs.com&utm_source=datastackjobs.com,datascience,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/j3bdjnckkd.webp,Sensor Tower,sensor-tower,SensorTower,"Quick Intro to Sensor Tower<a href=""https://sensortower.com/"">Sensor Tower is a high-growth SaaS company that provides accurate, comprehensive, and customizable mobile market economy analytics to app developers, marketers, and industry analysts across gaming, travel &amp; hospitality, music, finance, broadcast entertainment. We serve a wide range of clients from early-stage mobile innovators to industry-leading Fortune 500 companies.As a high-integrity source of industry insight, Sensor Tower is regularly cited by the world’s leading news and finance publications, including the Wall Street Journal, The New York Times, Forbes, Fortune, Bloomberg, CNBC, The Washington Post, and Reuters.  Founded in 2013, Sensor Tower has grown from a $1M seed investment to being profitable and in 2020 we received a $42M growth investment from Riverwood Capital.Role Summary:Data Scientists at Sensor Tower are hybrid data scientists and software engineers. You would take data all the way from doing initial analysis to building data pipelines to final model implementation and monitoring. Data Scientists take full ownership of the back-end of the products they’re working on. We are looking for a hands-on thinker to help harvest new insights from our constantly growing foundation of quantitative information collected from the mobile app ecosystem. ResponsibilitiesPrototype machine learning models in Python or RubyWork with MongoDB and analyze query performance to ensure calculation efficiencyWrite tests for the implementation of machine learning modelsCollaborate with back-end engineers to understand the raw data being collectedCollaborate with front-end engineers to create data visualizations for both external and internal customersConduct ad-hoc data analysis based on requests from the Sales, CSM or Contents teamPresent results of various data analysisRequirementsMaster’s degree or above in mathematics, statistics, or computer science3+ years applied experience in business intelligence, data mining, analytics, or statistical modeling in technology or mobile industries OR 2+ years applied experience in data science in mobile market intelligenceAbility to write code that is ready for production (Python and Ruby preferred)Experience with adjusting data for biasSubstantial experience with databases, querying data, and data structure manipulationAbility to communicate effectively with technical developers and non-technical marketing business partnersAbility to produce rough timelines for deliveries plus solid understanding of steps necessary to complete a projectAbility to come up with a rough project structure from scratchAbility to critically analyse given data, ask probing questions, and perform own researchSubstantial knowledge of statistical modeling techniquesMastery of one or more statistical visualization or graphing toolkits such as Excel, Jupyter Notebooks, or Google SpreadsheetsWhat is it like working at Sensor Tower?  Sensor Tower’s flexible work environment allows employees to choose how much they want to work remotely or in an office. We offer flexible time off so employees can shape their time away from the office. Our model allows employees to live in greater connection with the people, traditions, places, and activities they love while contributing to their team! Sensor Tower provides fair and competitive compensation packages that honor the investment our team members make each day. To support health and wellbeing, we offer industry-standard benefits and additional perks that our employees love. This includes stipends for office and/or gym setup, home internet, and daily meal delivery. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, and veteran status. In support of the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records. If you have a disability or special need, please do not hesitate to let us know and we'll do our best to accommodate.Interested in learning more? Submit your info and let's get a conversation going!",15977,Europe,remote,Senior Data Scientist,2022-01-20T21:59:17Z,j3bdjnckkd-senior-data-scientist,approved,"['Business Intelligence', 'Data Mining', 'Data pipelines', 'Finance']",fulltime
https://boards.greenhouse.io/digit/jobs/3289203?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/fviqfy4gvp.webp,Digit,digit,hellodigit,"The ChallengeAt Digit, we are on a mission to make financial health effortless for everyone. We are building the world’s first intelligent bank account to help millions of American consumers become financially healthy. Our challenge is clear: managing personal finances is hard. As of 2019, 70% of Americans struggle with at least one aspect of financial stability and over 40% don’t have $400 in their savings account. We believe automation is our path to delivering our mission, and we are working towards it every day.We have a collaborative, diverse, and supportive culture and we look for people who are curious, ambitious, and mission-driven. If you’re passionate about building something that’s never been built before and helping real people every day we’re excited to meet you!The RoleWe are looking for a Senior Data Engineer who is passionate about all things data to come help us build Digit’s data platform. In this role you will work on our Data Engineering team to own and build our data infrastructure to make Digit more data driven as we build an intelligent bank account. While Digit is headquartered in SF, this role is open to anyone, anywhere in the US and reports to the Engineering Manager of our Data Engineering team.What You’ll Do:Build, scale and manage Digit’s data platform including but not limited to our Kafka pipelines, Redshift and Delta Lake setups, and our Airflow and DBT deployments.Collaborate with our data science and machine learning teams to power the ‘brains’ of our bank account and product teams to enable data driven product development.Implement and control data access, governance and cataloging solutions for Digit’s data.Brainstorm, plan and iterate on Digit’s data platform roadmap.Advocate for industry standard data engineering practices for Digit’s data platform and products and champion their implementation and adoption.Participate in team oncall and bug rotations.Who You Are:You have 2+ years of dedicated data engineering experience at scale.You have experience building and working with both real-time and batch data pipelines. You can design and develop scalable data solutions with a long-term and growth mindset.You have recent accomplishments working closely with relational as well as No-SQL data stores. You’re familiar with extracting data from different data stores and making it available for analytical and machine learning use cases in data lakes and warehouses.You get excited to try out new technologies. You like to produce proof-of-concepts leveraging them to demonstrate if they can improve existing processes or systems.You aren’t afraid to get deep into the weeds to manage, deploy and improve low level data infrastructure.You operate with empathy when working with your stakeholders. You listen to them, speak your mind, ask the right questions and come up with optimal solutions for them.Bonus Points If:You have familiarity with the AWS ecosystem.You are well-versed with Kafka and it’s stream processing frameworks.Who We Are:We want to eliminate the stress and anxiety people feel about their finances so they can focus on what’s most important in their lives. We first mastered saving for near-term goals, helping members automatically save over $6B in cumulative savings and prevented $170M in overdraft fees. Today, we are harnessing machine learning technology to give our members the first intelligent bank account that manages all of their personal finances.We’re committed to doing the best work of our lives together. Come see if Digit is right for you.What We Offer You:Competitive salary and RSUs100% paid medical, dental, &amp; vision benefits100% paid life &amp; disability insuranceFertility reimbursementDaily lunch stipendInternet, commuter, and wellness benefitsTake what you need PTO policy401k planFlexible, hybrid work environmentDigit is a proud equal opportunity employer and we believe that a diverse and inclusive workforce is an imperative. We welcome people of different backgrounds, genders, races, ethnicities, abilities, sexual orientations, and perspectives. We don’t discriminate based upon any protected class and we encourage candidates of all identities and backgrounds to apply. Digit considers qualified applicants regardless of criminal histories in accordance with the <a href=""http://sfgsa.org/modules/showdocument.aspx?documentid=11600"">San Francisco Fair Chance Ordinance.Digit is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at <a href=""mailto:recruiting@digit.co""><u>recruiting@digit.co</u>.",15976,USA,remote,Senior Data Engineer,2022-01-20T21:57:00Z,fviqfy4gvp-senior-data-engineer,approved,"['Airflow', 'AWS', 'Data pipelines', 'Engineering']",fulltime
https://boards.greenhouse.io/figure/jobs/5829529002?ref=datastackjobs.com&utm_source=datastackjobs.com,machinelearning,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/x2rlhlnxdn.webp,Figure,figure,Figure,"About FigureFigure is transforming the trillion dollar financial services industry using blockchain technology. In three short years, Figure has unveiled a series of fintech firsts using the Provenance blockchain for loan origination, equity management, private fund services, banking and payments sectors - bringing speed, efficiency and savings to both consumers and institutions. Today, Figure is one of less than a thousand companies considered a unicorn, globally.Our mission requires us to have a creative, team-oriented, and supportive environment where everyone can do their absolute best. The team is composed of driven, innovative, collaborative, and curious people who love architecting ground-breaking technologies. We value individuals who bring an entrepreneurial mindset to every task and will embrace our culture of innovation. Every day at Figure is a journey in continuous learning yet a daily focus on getting work done that makes a difference. Join a team of proven leaders who have already created billions of dollars in value in the FinTech space!<a href=""https://www.forbes.com/americas-best-startup-employers/#6535f31b6527"">Forbes America’s Best Startup Employers<a href=""https://www.forbes.com/sites/michaeldelcastillo/2020/02/19/blockchain-50/?sh=60e7347c7553"">Forbes Top 50 Blockchain Companies<a href=""https://www.businesswire.com/news/home/20210520005738/en/Figure-Raises-200-Million-Series-D-Co-Led-by-10T-Holdings-and-Morgan-Creek-Digital"">Figure Series D AnnouncementAbout the RoleEach member of the Data Science team plays an integral part of what we are building at Figure. We rely on advanced techniques in machine learning, cloud platforms and big data to drive decisions across the organization. If you are interested in working with an impressive team of Data pros who collaborate and challenge each other, and want to solve interesting problems to propel the company’s growth, apply now! In this role, you'll be embedded with a team of machine learning developers. You'll be expected to help conceive, code, and deploy machine learning models at scale using the latest industry tools. Important skills include machine learning workflow automation and ML Ops. What You’ll get to doSupport Figure in building a machine learning platform to serve multiple lines of business and data science personas. Work with data scientists to refine workflow automation and increase productivity. Partner with data scientists to understand, implement, refine, and design machine learning and other algorithms.Perform regular A/B tests, gather data, perform analyses, and draw conclusions about model performance. Work cross-functionally with product managers, data scientists, engineers, and communicate results to peers and leaders. Explore new technology to determine how they might connect with the customer benefits we wish to deliver. Build tools to monitor data pipeline performance, data quality, and models in production. Establish best practices with coding standards, workflows, tools, and product automation. Review and maintain existing codebase (pipelines, models, algorithms), continue to improve existing tools and create new ones.Build fundamentally sound, production-ready software and data products using modern development lifecycle methodologies: CI/CD, QA, and Agile Methodologies and deploy highly scalable softwareWork as part of a data team working with mature data science products.Integrate applications and platforms with cloud technologies (e.g., AWS and GCP)What We Look ForBS, MS, or PhD in Computer Science or a related field, or equivalent practical experience. 5+ years of experience and a passion for designing, analyzing, and deploying machine learning-based solutions.Applied experience designing, building, and optimizing data pipelines, architectures, and data sets. Good understanding of machine learning methods and statistics, including ML project lifecycle and associated challenges at each stage of development. Knowledgeable about machine learning frameworks (e.g. PyTorch, Tensorflow, XGBoost, etc) Expert-level knowledge of setup and use of data processing tools (e.g. Spark, Dask, etc) and distributed computing frameworks (e.g. Ray, Dask, etc)Computer science fundamentals: data structures, algorithms, performance complexity, and implications of computer architecture on software performance such as I/O and memory tuning.Experience with GPU acceleration (i.e. CUDA and cuDNN)Experience with tools like MLFlow, Airflow, Prefect, Docker, and Kubernetes is ideal. Benefits and PerksCompetitive salary and growth opportunities Company quarterly performance based bonusEquity stock options packageEmployer funded comprehensive health, vision, dental insurance and wellness program for employees and their dependentsEmployer funded life and disability insurance coverageCompany HSA, FSA, Dependent Care, 401k, and commuter benefitsUp to 12 weeks paid family leave In office, remote, and hybrid work location optionsHome office and technology stipend for those working outside of a traditional office more than 75% of the timeFlexible time-off plan to empower employees to take the time off that they want and needContinuing education reimbursementRoutine Team swag deliveries!Depending on your residential location certain laws might regulate the way Figure manages applicant data. California Residents, please review our <a href=""https://drive.google.com/file/d/1eDhTkvbpFETeAvGpsB8e6KzaXES4BWNB/view?usp=sharing"">California Employee and Prospective Employee Privacy Notice for further information. By submitting your application, you are agreeing and acknowledging that you have read and understand the above notice.Figure is unfortunately unable to provide sponsorship for this position. In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification form upon hire.",15934,United States,remote,Machine Learning Engineer,2022-01-19T20:05:28Z,x2rlhlnxdn-machine-learning-engineer,approved,"['Airflow', 'AWS', 'Banking', 'Big Data']",fulltime
https://apply.workable.com/j/8F40C1DD9B/apply?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/65mhjxbhkk.webp,Netguru,netguru,netguru,"Join<a href=""https://www.netguru.com/talent/marketplace""> Netguru Talent Marketplace, a proven partner for tech-minded freelancers and experts. Thanks to us, you will have access to various project-based opportunities and can collaborate with different companies and industries. As a result, you will not only gain more experience but also develop a variety of skills you didn’t even know you had. Work the way you like, on your terms, with no strings attached.Over the past ten years, Netguru has changed the way people bank, listen to music, learn languages, and rent bicycles. Some of our clients include Fortune 500 companies and startups like Shine, Countr, Petro Niche, and more. Netguru works with the largest brands in the world, such as Volkswagen, IKEA, and Keller Williams.Our team of 650+ allows us to deliver well-designed and optimized custom mobile app development solutions for both iOS and Android mobile platforms, in turn, increasing the productivity of a business enterprise. The main reason behind custom mobile apps is that they not only help business owners transform their unique ideas into reality, but also help them deliver personalized UX.Joining Netguru's project means:Working with the Data Engineering and Machine Learning team to build custom data pipelines.Working with external clients, teams, data owners, and solution architects to build data flows in a reliable way.Building transformations, scripts, and migrations to multiple specifications and standards.Data-driven mindset - our clients require PoCs, data exploration/normalization, and expertise.Monitoring data flows and making continuous improvements to data pipelines.RequirementsApply if you:Are advanced in Python programming language (understanding: iterators, generators, exceptions, OOP, popular libraries for data engineering).Have advanced SQL knowledge.Have practical knowledge of DevOps t.j. CI, CD, terraform, observability.Have experience with Apache Spark / AWS Glue, or similar solutions.Have experience with ETL (Airflow) or other data processing automation approaches.Have experience with Snowflake.Have a very good command of written and spoken English (B2+). Polish is not required.We'll be happy to see that you have:Experience with AWS Redshift or GCP BigQuery.Experience with coding in Scala.Have hands-on experience with Hadoop technologies or equivalent in the cloud environment.Experience optimizing data storage in HDFS/Parquet/Avro.Experience with cloud technologies (AWS, GCP, Azure or other).Worked with data (ideally TB+).Can debug complex data infrastructures.Benefits100-percent remote work.Work with an experienced team of developers and continuously develop your hard and soft skills.A mentor who will assist you during your first days.Dev-friendly processes such as Continuous Integration, Continuous Delivery, Code Review, and bug bashes.Collaboration on challenging products (FinTech, B2B software, E-commerce, and more).Looking for a full-time job? Check out our<a href=""https://www.netguru.com/career""> Career Page and find out more about our open recruitment processes. ",15915,Worldwide,remote,Data Engineer,2022-01-19T20:02:36Z,65mhjxbhkk-data-engineer,approved,"['Airflow', 'Avro', 'AWS', 'Azure']",fulltime
https://boards.greenhouse.io/demandbase/jobs/3830086?ref=datastackjobs.com&utm_source=datastackjobs.com,softwareengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/trz1dxqeps.webp,Demandbase,demandbase,Demandbase,"Introduction to Demandbase:The biggest and fastest-growing companies in the world rely on Demandbase to drive their account-based strategies and maximize B2B go-to-market performance. We pioneered the ABM category nearly a decade ago, and today we lead the industry as an indispensable part of the B2B tech stack. Demandbase offers the only end-to-end Account-Based Experience (ABX) solution that helps B2B companies find, engage, and close the accounts that matter most. Our success would not be possible without the driven and collaborative teams here at Demandbase. As a company, we’re as committed to growing careers as we are to building world-class technology. We invest heavily in people, our culture, and the community around us. We have offices in the Bay Area, New York, Seattle, and a team in the UK, and allow employees to work remotely from anywhere in the US. We have also continuously been recognized as one of the best places to work in the Bay Area.Our success depends on our ability to create a diverse, equitable and inclusive environment. We're committed to attracting, developing, retaining and promoting a diverse workforce. By ensuring that every Demandbase employee is able to bring a diversity of talents to work, we're increasingly capable of living out our mission and providing real insight from our products to support our customers. We encourage people from underrepresented backgrounds and all walks of life to apply. Come grow with us at Demandbase!About the Role:In this role, you will help build the next generation unified data platform that will combine datasets from across the Demandbase ecosystem. Using the latest open source tools, you'll solve complex data warehousing problems to ensure quality, discoverability and accessibility of data. You'll build batch and streaming data pipelines for ingestion, normalization and analysis; in addition, you'll develop standard design and access patterns that will allow these pipelines to stay flexible and grow over time as the needs of the business change. You'll be a leader in the unification of data from our multiple products as we come together as one Demandbase platform.What you'll be doing:Build out all aspects of the Demandbase Data ecosystem and move products from R&amp;D into production scaleDesign and build data pipelines to create the next generation of Demandbase’s Unified Data PlatformWork across the data stack to build and productionalize data pipelines for massive amounts of dataBuild DAGs in Airflow for orchestration and monitoring of data pipelinesWhat we're looking for:Four-year degree in Computer Science, or related field OR equivalent experienceProgressive experience in all of the following areas:Designing frameworks and writing efficient data pipelines, including batches and real time streamsUnderstanding of data strategies, articulate data analysis &amp; data model design and evolve data products according to business requirements.Experience with the Spark Ecosystem (YARN, Executors, Livy, etc)Experience in large scale data streaming, particularly Kafka or similar technologies (Pulsar, Kinesis, etc)Experience with data orchestration frameworks, particularly Airflow or similarExperience with columnar data stores, particularly Parquet and ClickhouseStrong SDLC principles (CI/CD, Unit Testing, git, etc)General understanding of AWS EMR, EC2, S3Even better if you have….Experience with “Lakehouse” technologies, particularly Iceberg or similar (DeltaLake, Hudi, etc)Terraform for AWSAstronomerOpen Source contribution experienceBenefits: Our benefits include options for 100% paid for Medical, Dental and Vision for you and your entire family, short-term/long-term disability, life insurance, flexible vacation policy and 401K. More About Demandbase:Demandbase is the leader in Account-Based Experience (ABX) and an indispensable part of the B2B Go-to-Market tech stack. The company offers simply the best account-based platform to find, engage, and close the accounts that matter. The biggest and fastest-growing companies in the world, such as Accenture, Adobe, DocuSign, GE, Salesforce, and others, rely on Demandbase to drive their ABX strategy and maximize their marketing performance. Demandbase has been named to the JMP Securities list “The Hot 100: The Best Privately Held Software Companies,” the Deloitte Fast 500, and named a Gartner Cool Vendor for Tech Go-To-Market.For more information, please visit www.demandbase.com or follow the company on Twitter @Demandbase. ",15914,US,remote,Senior Data Engineer,2022-01-19T20:00:52Z,trz1dxqeps-senior-data-engineer,approved,"['Data Platform', 'Airflow', 'AWS', 'Data Warehousing']",fulltime
https://angel.co/company/ydata/jobs/683530-mlops-back-end-engineer,devops,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/nzziqxbdfc.webp,YData.ai,ydata-ai,YData_ai,"Salary Range: €25k – €45k | Equity: 0.0% – 0.1%We're looking for an MLOps / Back-End Engineer who will help us shape our team, drive the company to the next level, and have the most direct influence on our success.Your ProfileExperience or interest to work with Go and/or Python languagesExperience with infrastructure technologies (Kubernetes and Docker)Experience developing distributed systems and microservies architecturesUnit, integration, and end-to-end tests are an essential part of your coding stylePassionate about learning new tools and keeping yourself up-to-dateWillingness to communicate and share your knowledge with other team membersWillingness to work in agile processes, like Scrum or KanbanFluent in EnglishYour ResponsibilitiesYou will be part of a self-organized, cross-functional team building a data platformSince our team is currently being developed from scratch, we need pragmatic engineersYou are not only our 'code', you take responsibility for the whole product your team deliversYou are curious and figure out how things work and how they should work for your productYou bring your core expertise but are open to getting your hands dirty with back-end, DevOps, QA, and customer successYou have a problem-solving attitudeOur Perks – More than just a jobHave an impact. With innovation and smart technology, we are changing the way organizations use and share data.Trust-based working. We don't punch the clock – organize your own schedule. We trust in what you do!Improve yourself. We only hire the best and make them even better.Feel at home. Literally! We are remote work enthusiasts!Feel it’s your own company. Besides salary, we offer stock options because we want you to be part of YData.",15884,"Europe, Africa, North America, South America, Central America",remote,MLOps / Back-End Engineer,2022-01-18T17:14:08Z,nzziqxbdfc-mlops-back-end-engineer,approved,"['Go', 'Python', 'Kubernetes', 'Docker']",fulltime
https://boards.greenhouse.io/affirm/jobs/4857087003?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/ecdbh7e98x.webp,Affirm,affirm,Affirm,"Affirm is reinventing credit to make it more honest and friendly, giving consumers the flexibility to buy now and pay later without any hidden fees or compounding interest. Affirm, Inc. proudly includes Affirm, PayBright, and Returnly. What you'll doHelp shape the technical direction of a domain within the Data@ organization.Build a reliable and scalable single source of truth core model data product for internal and external analytics and enable self-service.Partner with product, data analyst, engineering teams and other data engineers to translate business requirements into data models with measurable transformation quality under SLA.Develop and automate large-scale, high-performance data processing systems and visualization to ensure reliability and meet critical business requirements.Lead data engineering projects, and overall strategy for data governance, security, privacy, quality, and retention.Mentor data engineers and continue promoting data engineering and analytics tooling &amp; standards.What we look for7+ years of experience in data modeling, data architecture, and other areas directly relevant to data engineering.Technical leadership; capable of handling mentorship, cross functional project execution, and solid individual contributions.Advanced SQL, ETL pipelines, Data modeling &amp; design, SQL performance tuning in OLAP and Data Warehouse/Data Lake environmentsProficiency with programming languages (e.g. Python) and Data Warehouse technologies (NoSQL, logging, columnar, Snowflake, etc.), Big Data technologies (e.g Hadoop, Spark, etc.), analytics (Looker, Tableau, etc.)Familiar with data governance frameworks and Agile methodologyExcellent written and verbal communication and interpersonal skills; able to effectively collaborate with technical and business partners.Eager to learn new things and have a growth mindset.BS/MS degrees in Computer Science, Engineering, or a related technical field.Location - Remote U.S.Affirm is proud to be a <a href=""https://www.linkedin.com/pulse/new-ways-we-work-jude-komuves/?trackingId=b19Ndt4EShSxDp3fjaCHdw%3D%3D"">remote-first company! The majority of our roles are remote and can be located anywhere in the U.S. and Canada (with the exception of the U.S. Territories, Quebec, Yukon, Nunavut, and the Northwest Territories) unless the job indicates a different global location. We are currently building operations in Spain, Poland, and Australia.  Employees in remote roles have the option of working remotely or from an Affirm office in their country of hire, and may occasionally travel to an Affirm office or elsewhere for required meetings or team-building events. Our offices in Chicago, New York, Pittsburgh, Salt Lake City, San Francisco and Toronto will remain operational and accessible for anyone to use on a voluntary basis, subject to local COVID-19 guidelines.If you got this far, we hope you're feeling excited about this role. Even if you don't feel you meet every single requirement, we still encourage you to apply. We're eager to meet people who believe in Affirm's mission and can contribute to our team in a variety of ways—not just candidates who check all the boxes. Inclusivity:At Affirm, People Come First is one of our core values, and that’s why diversity and inclusion are vital to our priorities as an equal opportunity employer. You can read about our D&amp;I program <a href=""https://www.affirm.com/diversity-inclusion"">here and our progress thus far in our <a href=""https://assets.ctfassets.net/4rc1asww3mw7/4oAgbpVaxk6UbqRnFOkASc/1e110320731c73da9350677bd8c702cf/2020_Affirm_DEI_Report.pdf"">2020 DEI Report.We also believe It’s On Us to provide an inclusive interview experience for all, including people with disabilities. We are happy to provide reasonable accommodations to candidates in need of individualized support during the hiring process.By clicking ""Submit Application,"" you acknowledge that you have read the <a href=""https://docs.google.com/document/d/e/2PACX-1vRSrHfbqKhhxAsI84tBH5hW85xiwEF4s8MOnfgDFJ5hl4_opeivo6dKc1kbywvVEppRe37UqYYsghB2/pub?urp=gmail_link"">Affirm Employment Privacy Policy, or the <a href=""https://docs.google.com/document/d/e/2PACX-1vQrsTcZOb2_liNfehZtHSHG6apQTk372vodkmNinPGNNLKnoU_YyCeEneUzsZtTdn2uiRYvE2kM3XL9/pub"">Affirm Employment Privacy Notice (EU) for applicants applying from the European Union, and hereby freely and unambiguously give informed consent to the collection, processing, use, and storage of your personal information as described therein.",15860,US,remote,Staff Data Engineer,2022-01-18T17:15:37Z,ecdbh7e98x-staff-data-engineer,approved,"['Big Data', 'Engineering', 'ETL', 'Hadoop']",fulltime
https://boards.greenhouse.io/dataminr/jobs/3820711?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/cj2izg5kel.webp,Dataminr,dataminr,dataminr,"--COVID-19 Hiring Update--As the health and safety of our candidates and our employees come first, we're excited to provide virtual experiences for interviews and new hire on-boarding. Currently, reopening of offices is planned for January 2022.Who we are: Dataminr puts real-time AI and public data to work for our clients, generating relevant and actionable alerts for global corporations, public sector agencies, newsrooms, and NGOs. Our leading AI platform detects the earliest signals of high-impact events and emerging risks from vast amounts of publicly available information. Our real-time alerts enable tens of thousands of users at hundreds of public and private sector organizations to learn first of breaking events around the world, develop effective risk mitigation strategies, and respond with confidence as crises unfold. Dataminr is making its mark for growth and innovation, recently earning recognition on the Deloitte Technology Fast 500, Forbes AI 50 and Forbes Cloud 100 lists. We also earned accolades for ‘Most Innovative Use of AI’ from the 2020 AI &amp; Machine Learning Awards. Join our team and help the world manage risk in real time. You’ll work with 800+ talented people across eight offices, united by our passion to collaborate, make a difference, and have fun while doing it!Who you are:You are a highly motivated self-starter and problem solver interested in the intersection of business, technology, and current events. You are innovative and adaptable, with an ability to juggle multiple projects at one time. You have a high level of technical skill, but even more importantly have an analytical mindset and are excited to learn more about the programs and tools that make our Data Analytics team a diverse and capable component of Dataminr. You will work hand-in-hand with content experts, product managers, engineers, and other teams to solve challenging problems with your data analysis skills.About the Role:Conduct data exploration and build data ingests/models utilizing APIs and other methodsGuide the development of reports, dashboards, and metrics to monitor the performance of our internal productsEffectively translate statistical findings into actionable recommendations for senior leaders on operations, product, and engineering teams.Communicate complex ideas in a clear, precise, accessible way to operations, product, engineering, and data science teams.Required Skills &amp; Experience:At least 2-4 years experience in Data AnalyticsExperience in one or more object oriented programming language (Python, Java or TypeScript preferred), and ability to work on projects with minimal supportIntermediate knowledge of SQLDemonstrated experience with analytical tools (e.g., Microsoft Excel/Google Sheet)Experience with, or a willingness to explore business intelligence tools (e.g., Tableau, Looker)Leveraging data to tell a storyExcellent attention to detail, highly organized and process orientedAbility to work both independently and collaboratively within a teamSelf-motivated with an ability to handle multiple competing priorities in a fast-paced, entrepreneurial environmentExcellent verbal and written communication skills, and the ability to convey complex results to non-technical audiencesDesired Skills &amp; Experience:Familiarity with AWS services (S3, ECS, Lambda)Experience with web scraping frameworks/technologies (Selenium, Scrapy, BeautifulSoup, HTML, CSS)Familiarity in machine learning frameworks (TensorFlow/Keras) or packages (scikit-learn)Why you should work here:We recognise and reward hard work with:competitive compensation package including equitycompany paid benefits for employees and their dependents such as Health and Dental insurance as well as Income Protection and Life Insurancepersonal retirement savings account with employer matchWe want you to be your best, authentic self by supporting you with:a diverse, driven, and passionate team of coworkers who want you to succeedindividual learning and development fund and professional traininggenerous leave, including two additional volunteer daysRemote working friendly perks such as expanded telehealth options for mental and physical well-being, meditation and health and fitness app reimbursements Discounted Gym Membership…and this is just to name a few!Dataminr is an equal opportunity and affirmative action employer. Individuals seeking employment at Dataminr are considered without regards to race, sex, colour, creed, religion, national origin, age, disability, genetics, marital status, pregnancy, unemployment status, sexual orientation, citizenship status or veteran status.Dataminr will collect and process your personal data. All personal data will be processed in accordance with Dataminr’s job candidate privacy notice available here: https://www.dataminr.com/irecandidatenotice.For individuals applying for US-based roles: Dataminr is requiring that all prospective employees hired for this position present proof that they are fully vaccinated against COVID-19 prior to their first day of employment, to the extent permitted by applicable law.Dataminr is an equal opportunity employer. Candidates who are unable to be vaccinated due to a sincerely held religious belief, medical reasons, or other legally protected reasons, should contact their recruiting representative as soon as possible following any conditional offer of employment to explore what, if any, reasonable accommodations Dataminr is able to offer.",15796,"Dublin, Ireland",onsite,Senior Data Analytics Developer,2022-01-16T20:35:12Z,cj2izg5kel-senior-data-analytics-developer,approved,"['AWS', 'Business Intelligence', 'Data Analytics', 'Engineering']",fulltime
https://www.transferwise.jobs/role/3818448?gh_jid=3818448&ref=datastackjobs.com&utm_source=datastackjobs.com,datascience,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/r98pqk6xmc.webp,Wise,wise,wise,"Wise is <a href=""https://www.ft.com/content/cf0c5fce-3112-11e8-b5bf-23cb17fd1498"">one of the fastest growing companies in Europe.  Current banking systems don't let us send, spend or receive money across borders easily. Or quickly. Or cheaply. So, we’re building a new one.We’re on a mission: to make money without borders the new norm. We’ve got 11 million customers across the globe and we’re growing. Fast.We’re creating a scalable, high performing platform for our customers. And we need Data Science Interns to join us in our mission. This is a paid internship that will run throughout the summer.At Wise you’ll work on challenging technical problems across the full product life-cycle and you’ll help us gain the understanding necessary to give our customers a great experience. How you’ll contribute to our team of data scientists: You’ll work on a real data science project that matters to us, using up-to-date machine learning techniques. We can’t say what project yet, but your internship will be centred around this.You will help analysing data that will help us prioritise the most customer significant changes in the productParticipate in building the most advanced machine learning based solutions to help us scaleHelp take Wise to the next level as we scale to impact 100’s of millions more customersThis role will give you the opportunity to:Learn and develop professionally. You’ll work closely with your Wise team. You’ll learn by doing. And you’ll be guided and supported along the wayUnderstand the Wise way through lots of opportunities to learn about our business and how it worksBroaden your network. There are a LOT of experienced people here at Wise who are keen to share their experience and knowledge with you. They’ll want to learn from you and get your perspective on things tooChoose your path to impact. We believe people do great things when they can act autonomously. So, instead of being told what to do, you’ll work with your team to create a vision of your own. You can always gather feedback from smart, curious people across Wise, but you’ll have the freedom to make your own callsBe flexible in how and where you work. We understand everyone needs a little something different - so we’ll do our best to make it happenInspire teams with your ideas, knowledge and self-starting attitude What does it take? These things are a must:You are a student studying a Bachelors, Masters, or PhD degree. This might be in Computer Science, Mathematics, Engineering or any other STEM subjectYou are able to start a full time graduate job in September 2023Knowledge of computer science and machine learning fundamentals including data structures, algorithms, data analysis, linear algebra and statisticsUnderstanding principles of machine learningYou should have a good command of Python 3 and be familiar with major data analysis and ML frameworksA self-started side project(s) that you are proud to talk aboutGreat communication skills and the ability to articulate complex, technical concepts to a non-technical audienceCurious, keen to learn and proactive by natureYou are open to and value feedback in order to improveEligible to work in Tallinn or London (You can work from anywhere in the country you're hired!)And these would be great, but aren’t essential:Experience in applying causal inference and/or uplift modeling techniques, for example with DoWhy and EconMLExperience in designing and training deep neural networksExperience in applying machine learning methods to real-world problemsFamiliarity with TensorFlow 2 and/or PyTorchFamiliarity with AutoML frameworks, especially FLAMLFamiliarity with Bayesian methods in machine learningExperience in web development, from a previous internship ...Don’t worry we don’t expect you to know everything!What you get back:🚀 Experience working in <a href=""https://www.wise.jobs/2021/04/08/the-growth-of-wise-and-whats-next-for-us/"">one of the fastest growing European FinTechs🏃‍♀️ Lots of team activities📈 Solve real customer problems with data🙌Fun offices with social activities - have <a href=""https://youtu.be/-Amc0Fcu40U"">a sneak peak of life in our Singaporean office!We’re people without borders — without judgement or prejudice, too. We want to work with the best people, no matter their background. So if you’re passionate about learning new things and keen to join our mission, you’ll fit right in.And because we believe that diverse teams build better products, we’d especially love to hear from you if you’re from an under-represented demographic.",15769,Tallinn or London,onsite,Data Science Internship,2022-01-16T20:46:29Z,r98pqk6xmc-data-science-internship,approved,"['Banking', 'Engineering', 'Machine Learning', 'ML']",fulltime
https://discord.com/jobs/5664098002?ref=datastackjobs.com&utm_source=datastackjobs.com,softwareengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/eyiizrzf6l.webp,Discord,discord,discordapp,"Discord is about creating a space for everyone to find belonging in their lives. Hundreds of millions of people use Discord everyday to have meaningful interactions.The mission of the Discovery &amp; Notifications team at Discord is to help users connect and engage with the online communities to create this belonging. We are working on enabling our users’ experiences with search, recommendations, and smart notifications. We are just starting to build these ML driven user experiences and if you are someone who is passionate about building things from scratch, this could be a great opportunity for you! What you'll be doingDesign and build machine learning systems for retrieval, ranking and personalization.Collaborate with stakeholders throughout the company such as, leaders in product, data science, and engineeringBuild generalizable infrastructure for NLP, retrieval and ranking, especially using MLOps stack like TFX.What you should haveBachelor’s degree or higher in a quantitative field including Computer Science, Physics, Applied Math, Statistics or other quantitative fields.2+ years experience in one or more of the following areas: recommendation systems, search, adsML, natural language processing, knowledge graphs.Benefits And PerksComprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures)Mental health resources and quarterly wellness stipends16 paid holidays, 4 weeks of PTO, use-what-you-need sick days and volunteer time offPaid parental leave (plus fertility, adoption and other family planning benefits)Generous stipends for headphones, your remote work setup, and lunch on a daily basis (while we’re all remote)Flexible long-term work options (remote and hybrid)A diverse slate of Employee Resource GroupsPlus commuter contributions and other perks for office-based employeesAbout UsDiscord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests — from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations.In a world of polarization, social curation, and loneliness, Discord is working toward an inclusive world where no one feels like an outsider. We believe in the value of genuine human connection, which can so easily be lost online. So we’re building a space where everyone can find belonging from the inside out.If this strikes a chord with you, come build belonging with us!",15766,"San Francisco, CA or Remote",flexible,"Software Engineer, Machine Learning",2022-01-16T20:40:29Z,eyiizrzf6l-software-engineer-machine-learning,approved,"['Search', 'Recommendations', 'Notifications']",fulltime
https://jobs.lever.co/safe/266c3cff-d7bf-4b99-bd21-d41b4b0a562e?ref=datastackjobs.com&utm_source=datastackjobs.com,machinelearning,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/tbt87dznfc.webp,Safe Security,safe-security,itssafesecurity,"Our vision is to be the Champions of a Safer Digital Future and be the Champions of Change. We believe in empowering individuals and teams with freedom and responsibility to align their goals such that we all row in the same direction. We are uncomfortably transparent, autonomous &amp; accountable, we have zero tolerance for brilliant jerks, we have unlimited vacation policy and more. For us our Culture Is Our Strategy - check out our <a href=""https://jobs.safe.security/culture/"">Culture Memo for more details and surprises.At the core, we are a data science company. We take different data points from a company's cyber environment, and apply statistics / ML to give actionable insights to our customers. We are looking for a Senior ML Engineer who can take our models to the next level.Key responsibilities include:Build production level ML/ statistics code for our cyber quantification algorithms;Lay down the foundation for our future data architecture - plan the right way to collect data in the product (telemetry), prepare data for aggregate analysis in the future; ‘Preparation’ might include labeling, cleaning and streaming data.Ideal experience5+ years of experience in building scalable production level Python based models2+ years of experience in MLOps architecture and building / or working on data lakes / data warehouse – preparing infrastructure to run analytics at scaleGood understanding of different statistical and ML techniquesJoin our rocket ship if you want to learn, make your mark and work with incredible talent!",15764,Worldwide,remote,Senior ML Engineer,2022-01-16T20:37:27Z,tbt87dznfc-senior-ml-engineer,approved,"['ML', 'MLOps', 'Python']",fulltime
https://boards.greenhouse.io/andela/jobs/3805528?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/wnnyq2wi9m.webp,Andela,andela,Andela,"About Andela:Andela exists to connect brilliance and opportunity. Since 2014, we have been dedicated to breaking down global barriers and accelerating the future of work for both technologists and organizations around the world.For technologists, Andela offers competitive long term career opportunities with leading organizations, access to a global community of professionals, and education opportunities with leading technology providers.For companies, Andela provides access to a global network of fully integrated team members that unlock their business’ innovation and growth potential. At Andela, we are deeply passionate about creating long-lasting and transformative growth opportunities for all and doing it in an <a href=""andela.com/careers"">E.P.I.C. way.We are excited to continue building our team with incredible people like you!What you’ll do:Understand Andela’s platform, value proposition, and roadmap by working with Data Engineering leadership.Take ownership of sprint work to help create innovative solutions for a category-defining platformThis role is founded in data engineering technology solutions to drive efficiencies here at scale.Own the excitement of entropy! Our platform, products, and offerings are constantly changing and expanding. We encourage and enable each individual at Andela to drive a commercial idea when they identify one, which creates an ever-changing data landscape. Who you are:At home in an environment where you are responsible for delivering data solutions to drive change!1+ years experience working in data intensive environments and platforms.Ability to work in an agile team environment and collaborate effectively.Basic understanding of data structures, data in transit, and data at rest.Ability to thrive in a fast moving and challenging environment.Preferred QualificationsPython and SQL Experience working with a modern SaaS tool Experience in data modeling Kubernetes, Docker or a comparable systembasic knowledge of shell scriptingExperience with a cloud platform (GCP is a plus)Experience with Agile/ScrumBenefits:Fully Remote work cultureA fair and competitive salaryBring your own device stipend - buy your own laptop with funds from AndelaQuarterly work from home stipendsGenerous paid time offAdditional paid holidaysFlexible working hoursHealth insurance (country-specific)Equity401k (US only)Andela Affinity GroupsAnd more!At Andela, we outcompete through diversity. We know that our strengths lies in the multiplicity of talents, perspectives, backgrounds &amp; orientations resident in our community and we take pride in that. Andela is committed to a work environment in which all individuals are treated with respect and dignity. Each individual has the right to work in a professional atmosphere that promotes equal employment opportunities and prohibits discriminatory practices. Andela provides equal employment opportunities and workplace to all employees and applicants without regard to factors including but not limited to race, color, religion, gender, sexual orientation, gender identity, national origin, age, disability, pregnancy (including breastfeeding), genetic information, HIV/AIDS or any other medical status, family or parental status, marital status, amnesty or status as a covered veteran in accordance with applicable federal, state and local laws. This commitment applies to all terms and conditions of employment, including but not limited to hiring, placement, promotion, termination, layoff, recall, transfer, leaves of absence, compensation and training. Our policies expressly prohibit any form of harassment and/or discrimination as stated above.Andela is home for all, come as you are.",15620,Worldwide,remote,Data Engineer,2022-01-13T17:25:50Z,wnnyq2wi9m-data-engineer,approved,"['Engineering', 'GCP', 'Kubernetes', 'Python']",fulltime
https://boards.greenhouse.io/evenresponsiblefinance/jobs/4289815004?ref=datastackjobs.com&utm_source=datastackjobs.com,dataengineering,https://nyc3.digitaloceanspaces.com/dstv-jobs-store-prod/public/company_logos/h10gyqtkka.webp,Even,even,makethingseven,"COVID Update - Even has begun to re-open its offices. Office use is available to anyone who the CDC has cleared to gather safely indoors without masks or social distancing. Employees may continue working from home indefinitely. Even is a Remote-Equal company. The experience of working 100% remotely feels the same as working from the office in all of the ways that matter: camaraderie, engagement, and opportunity.The problemMore than half of American workers live paycheck-to-paycheck. Stuck in this cycle, they collectively lose over $120 billion each year on payday loans, bank overdrafts, and fees. We’re trying to fix that by building new financial services that make it easier to plan ahead, pay down debt, and save. And we’re doing it as a transparent, straightforward business that only profits when our members do.The roleData Engineers at Even build the data transformation pipelines &amp; reporting infrastructure that serve our members and run our company. Besides writing, reviewing, and shipping code, engineers collaborate with others across the company, from product, design, and data to sales, compliance, and customer support. Data Engineers at Even are highly technical, communicative and emotionally intelligent.What you'll do:Building and maintain Even's data infrastructureDevelop and own Even's streaming data transformation pipelineManage our reporting toolsCollaborate closely with our Data AnalystsTracking and defining metrics around performanceWhat you'll need:4+ years of related experienceSelf-motivatedLove working with new techPassion for building stable and scalable solutionsTools we use:Languages: Python, Golang, TypescriptData: DBT, Fivetran, Redshift, PostgreSQLInfra: GitHub, Bazel, DockerWhat you'll get from us:The chance to work on a serious problem that affects more than half the U.S. population.A culture that gives you the time and space required to build great things.Competitive compensation, equity, and healthcare packages.401(k) with 50% match from Even on up to 6% of your salary.A $5,000 annual educational stipend to invest in your learning and development.A $500 annual stipend to use towards personal financial advice.A $100 monthly stipend for health and wellness expenses.A 5-year exercise window on stock options after 2 years at Even.A flexible vacation policy and a team that understands building a company is a marathon, not a sprint. 3 months bonding leave for both birthing and non-birthing parents. An additional 1.5 months of fully paid leave for pregnancy disability.A culture that gives you the autonomy you need to do great work, and the transparency you need to make good decisions.Want to learn more about what we look for in a team mate? Check out this <a href=""https://www.even.com/blog/what-we-value-2"">blog post written by our cofounder, Quinten Farmer.Even is used by people of all backgrounds, and we believe the best products are built by teams that represent their users. We value unique contributions and actively welcome people of all backgrounds, experiences, and perspectives to join us at Even. We are committed to working with and providing access and reasonable accommodation to applicants with mental and/or physical disabilities. If you think you may require an accommodation for any part of the recruitment process, please send a request to: <a href=""mailto:accommodations@even.com"">accommodations@even.com. All requests for accommodations are treated discreetly and confidentially, as practical and permitted by law.",15611,USA,remote,Senior Data Engineer,2022-01-13T17:28:25Z,h10gyqtkka-senior-data-engineer,approved,"['FiveTran', 'Healthcare', 'PostgreSQL', 'Python']",fulltime
