,job_id,job_title,job_url,job_salary,company_name,company_location,company_rating,company_url,company_country_name,job_description,job_benefits,job_posted_date,job_skills
0,97ae22da20777509,data engineer,https://www.indeed.com/viewjob?jk=97ae22da20777509,$94 000 - $152 000 a yearfull-time,sia partners,palo alto  ca 94303+4 locations,3.5,https://www.indeed.com/cmp/sia%20partners,united states,company description   about sia partners  sia partners is a next-generation consulting firm focused on delivering superior value and tangible results to its clients as they navigate the digital revolution. our global footprint and expertise in more than 40 sectors and services allow us to enhance our clients’ businesses worldwide. we guide their projects and initiatives in strategy  business transformation  it & digital strategy  and data science.   why join the sia village?  excellence | entrepreneurship | innovation | teamwork | care & support | employee wellbeing  these are the six core values that guide all our actions. as an expression of our values  our sia village concept describes our commitment to fostering a sense of community within and among our offices. we believe that knowledge sharing is the key  not only to innovation  but to the growth and development of our people.     job description   sia partners is looking for a talented data engineer to support our activities within the data science business unit. you will be working alongside with our data science consultants and our clients on data engineering topics  including creating relevant data models  developing powerful data pipelines  exposing them through various mechanisms including apis  and using data visualization tools to efficiently present data.  you will also contribute to internal data science projects posted on heka  our internal accelerator for data science projects. as part of the global data science team you will contribute to the development of various solutions designed to address our clients' needs.  key responsibilities   partner with our client’s leadership teams  engineers  program managers and data analysts to understand data needs.  design  build and launch efficient and reliable data pipelines transforming data into useful report ready datasets.  communicate at scale  through multiple mediums: presentations  dashboards  client-wide datasets  bots and more.  use your data and analytics experience to ‘see what’s missing ’ identifying and addressing data gaps  build monitors to detect data quality issues and partner to establish a self-serve environment.  broad range of partners equates to a broad range of projects and deliverables  including ml models  datasets  measurements  services  tools and process.  leverage data and business principles to automate data flow  detect business exceptions  build diagnostic capabilities  and improve both business and data knowledge base.  build data expertise and own data quality for your areas.      qualifications     at least 4+ years' of advanced sql experience (including at least one sql dbms and one nosql).  4+ years' of python development experience.  3+ years' of experience with workflow management engines (i.e. airflow  luigi  prefect  dagster  digdag.io  google cloud composer  aws step functions  azure data factory  uc4  control-m).  3+ years' experience with data modeling.  experience analyzing data to discover opportunities and address gaps.  4+ years' experience in custom etl design  implementation and maintenance.  experience working with cloud or on-prem big data/mpp analytics platform (i.e. snowflake  netezza  teradata  aws redshift  google bigquery  azure data warehouse  or similar).  bsc/ba in data science  computer science  engineering.   preferred experience with:   experience with more than one coding language.  knowledge of docker  ci/cd pipelines  and kubernetes.  experience in designing and implementing real-time pipelines.  experience with data quality and validation.  experience with sql performance tuning and e2e process optimization.  experience with anomaly/outlier detection.  experience with notebook-based data science workflow.  experience querying massive datasets  using spark  presto  hive  impala  etc.    additional information   please be aware that sia partners requires all employees in this position to be fully vaccinated against covid-19 as a condition of employment. “fully vaccinated” means that the individual can provide acceptable proof that the individual has received  at least fourteen (14) days prior to the individual’s start date  either the second dose of a two-dose covid-19 vaccine  or one dose of a single-dose covid-19 vaccine. vaccines must be authorized and/or approved by the fda. individuals needing an exemption to this requirement due to medical  disability-related  or religious reasons may request an exemption during the recruiting process. the company will engage in an interactive process to determine if an exemption to this requirement as a reasonable accommodation is appropriate.  benefits:   entrepreneurial journey  career advocacy program that supports achieving professional development goals through guidance  and real-time feedback  continuous learning & development opportunities  diversity  equity  and inclusion programs with an ever-growing list of global affinity initiatives  healthcare coverage that includes medical  dental  vision and life insurance policies  college save-up plan & college loan repayment plan  generous vacation  sick  floating  and holidays  including parental leave  401(k) matching  annual seminar  an in-person value-add experience that allows you to network with colleagues throughout north and south america  compensation range is between $94 000-152 000 annually   our commitment to diversity  diversity  equity  inclusion  and belonging (deib) are part of sia partners’ dna. thanks to our expertise in several sectors and our international growth  our teams include a variety of experiences and cultures. we’re confident that promoting deib creates an environment in which everyone can reach their full potential.  our global network  deib@sia partners  brings together our people worldwide to facilitate local and global progress  focused on the following areas:   gender equality (global gender equality index score of 91/100 for fy19-20)  lgbtq+  race & ethnicity  working parents  disabilities   sia partners is an equal opportunity employer. all aspects of employment  including hiring  promotion  remuneration  or discipline  are based solely on performance  competence  conduct  or business needs.  to learn more about our mission  values  and business sectors  please visit our website.  candidates must be located within commute distance of one of our three west coast offices  san francisco  seattle and denver.    sia partners is an equal opportunity employer. all aspects of employment  including hiring  promotion  remuneration  or discipline  are based solely on performance  competence  conduct  or business needs.,"401(k), 401(k) matching, dental insurance, health insurance, life insurance, loan repayment program, ",posted 2 days ago," medical, advocacy, language, to, airflow, analytics, azure data factory, big data, bigquery, business transformation, computer science, consulting, control-m , digital, data engineering, data modeling, data quality, data science, data visualization, disabilities, docker , e , entrepreneurship, etl, google cloud, google cloud composer, innovation, insurance policies, sql, knowledge base, kubernetes, leadership, luigi , m , massive , management, netezza, nosql, or, performance tuning, presentations, process optimization, python , reach, remuneration, business, sql , scale , data warehouse, san, teamwork, transformation , engines, vaccines, visualization, workflow management, "
1,2ae01772bf00cda9,data engineer - senior,https://www.indeed.com/viewjob?jk=2ae01772bf00cda9,N/A,cummins inc.,columbus  in+2 locations,3.8,https://www.indeed.com/cmp/cummins%20inc.,united states,data engineer - senior description leads projects for design  development and maintenance of a data and analytics platform. effectively and efficiently process  store and make data available to analysts and other consumers. works with key business stakeholders  it experts and subject-matter experts to plan  design and deliver optimal analytics and data science solutions. works on one or many product teams at a time. designs and automates deployment of our distributed system for ingesting and transforming data from various types of sources (relational  event-based  unstructured). designs and implements framework to continuously monitor and troubleshoot data quality and data integrity issues. implements data governance processes and methods for managing metadata  access  retention to data for internal and external users. designs and provide guidance on building reliable  efficient  scalable and quality data pipelines with monitoring and alert mechanisms that combine a variety of sources using etl/elt tools or scripting languages. designs and implements physical data models to define the database structure. optimizing database performance through efficient indexing and table relationships. participates in optimizing  testing  and troubleshooting of data pipelines. designs  develops and operates large scale data storage and processing solutions using different distributed and cloud based platforms for storing data (e.g. data lakes  hadoop  hbase  cassandra  mongodb  accumulo  dynamodb  others). uses innovative and modern tools  techniques and architectures to partially or completely automate the most-common  repeatable and tedious data preparation and integration tasks in order to minimize manual and error-prone processes and improve productivity. assists with renovating the data management infrastructure to drive automation in data integration and management. ensures the timeliness and success of critical analytics initiatives by using agile development technologies such as devops  scrum  kanban coaches and develops less experienced team members. qualifications skills data extraction - performs data extract-transform-load (etl) activities from variety of sources and transforms them for consumption by various downstream applications and users using appropriate tools and technologies. solution documentation - documents information and solution based on knowledge gained as part of product development activities; communicates to stakeholders with the goal of enabling improved productivity and effective knowledge transfer to others who were not originally part of the initial learning. quality assurance metrics - applies the science of measurement to assess whether a solution meets its intended outcomes using the it operating model (itom)  including the sdlc standards  tools  metrics and key performance indicators  to deliver a quality product. solution validation testing - validates a configuration item change or solution using the function's defined best practices  including the systems development life cycle (sdlc) standards  tools and metrics  to ensure that it works as designed and meets customer requirements. system requirements engineering - uses appropriate methods and tools to translate stakeholder needs into verifiable requirements to which designs are developed; establishes acceptance criteria for the system of interest through analysis  allocation and negotiation; tracks the status of requirements throughout the system lifecycle; assesses the impact of changes to system requirements on project scope  schedule  and resources; creates and maintains information linkages to related artifacts. problem solving - solves problems using a systematic analysis process by leveraging industry standard methodologies to create problem traceability and protect the customer; determines the assignable cause; implements robust  data-based solutions; identifies the systemic root causes and recommended actions to prevent problem reoccurrence. data quality - identifies  understands and corrects flaws in data that supports effective information governance across operational business processes and decision making. programming - creates  writes and tests computer code  test scripts  and build scripts using algorithmic analysis and design  industry standards and tools  version control  and build and test automation to meet business  technical  security  governance and compliance requirements. customer focus - building strong customer relationships and delivering customer-centric solutions. decision quality - making good and timely decisions that keep the organization moving forward. collaborates - building partnerships and working collaboratively with others to meet shared objectives. communicates effectively - developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences. education  licenses  certifications college  university or equivalent degree preferred or equivalent work experience in relevant technical discipline. this position may require licensing for compliance with export controls or sanctions regulations. experience intermediate experience in a relevant discipline area is required. knowledge of the latest technologies and trends in data engineering are highly preferred and includes:  familiarity analyzing complex business systems  industry requirements  and/or data regulations  background in processing and managing large data sets  design and development for a big data platform using open source and third-party tools  spark  scala/java  map-reduce  hive  hbase  and kafka or equivalent college coursework  sql query language  clustered compute cloud-based implementation experience  experience developing applications requiring large file movement for a cloud-based environment and other data extraction tools and methods from a variety of sources  experience in building analytical solutions  intermediate experiences in the following are preferred:  experience with iot technology  experience in agile software development  ideal candidate would have demonstrated experience in developing production worthy data pipelines  etl/elt  streaming data  operating in multi-cloud environment  data ingestion  event hub  ability to take lead in the data engineering activities from concept to delivery and mentor/coach/monitor deliveries by vendors/ junior data engineers. job systems/information technology primary location united states-indiana-columbus-us  in  columbus  sears building job type experienced - exempt / office recruitment job type exempt - experienced job posting jul 25  2022  7:58:45 am unposting date ongoing organization corporate req id: 220005dd,,posted today," software, iot, agile software development, language, to, analytics, standard, automation, big data, business systems, java, software development, communications, compliance requirements, configuration item, project, data engineering, data extraction, data governance, data ingestion, data integration, data integrity, data lakes, data management, data quality, data science, decision making, devops, e , etl, programming, governance, framework, indexing, indicators , information governance, information technology, java , sql, key performance indicators , less, licensing, management, metadata, mongodb, multi-cloud, negotiation, or, problem solving, programming , quality assurance, requirements engineering, business, sql , scala , map, scripting, source , system lifecycle, system requirements, systems development, systems development life cycle, test automation, traceability, version control, "
2,3af44a8e46314846,sr data engineer - telecommute,https://www.indeed.com/viewjob?jk=3af44a8e46314846,$82 100 - $146 900 a yearfull-time,optum,remote in eden prairie  mn 55346+24 locations,3.4,https://www.indeed.com/cmp/optum,united states,combine two of the fastest-growing fields on the planet with a culture of performance  collaboration and opportunity and this is what you get. leading edge technology in an industry that's improving the lives of millions. here  innovation isn't about another gadget  it's about making health care data available wherever and whenever people need it  safely and reliably. there's no room for error. join us and start doing your life's best work.(sm)  you’ll enjoy the flexibility to telecommute* from anywhere within the u.s. as you take on some tough challenges.  primary responsibilities:   assemble large  complex data sets that meet functional / non-functional business requirements  identify  design  and implement internal process improvements: automating manual processes  optimizing data delivery  re-designing infrastructure for greater scalability  etc.  build the infrastructure required for optimal extraction  transformation  and loading of data from a wide variety of data sources using sql  work with stakeholders including the executive  product  data and design teams to assist with data-related technical issues and support their data infrastructure needs    you’ll be rewarded and recognized for your performance in an environment that will challenge you and give you clear direction on what it takes to succeed in your role as well as provide development for other roles you may be interested in.  required qualifications:   undergraduate degree or equivalent experience  5+ years of experience in sql server with strong knowledge in writing sqls  stored procedures  performance tuning  etc.  5+ years of experience in ssis/talend  hands-on experience with etl tools  full covid-19 vaccination is an essential job function of this role. candidates located in states that mandate covid-19 booster doses must also comply with those state requirements. unitedhealth group will adhere to all federal  state and local regulations as well as all client requirements and will obtain necessary proof of vaccination  and boosters when applicable  prior to employment to ensure compliance. candidates must be able to perform all essential job functions with or without reasonable accommodation   preferred qualifcations:   experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement  bi tools knowledge    to protect the health and safety of our workforce  patients and communities we serve  unitedhealth group and its affiliate companies require all employees to disclose covid-19 vaccination status prior to beginning employment. in addition  some roles and locations require full covid-19 vaccination  including boosters  as an essential job function. unitedhealth group adheres to all federal  state and local covid-19 vaccination regulations as well as all client covid-19 vaccination requirements and will obtain the necessary information from candidates prior to employment to ensure compliance. candidates must be able to perform all essential job functions with or without reasonable accommodation. failure to meet the vaccination requirement may result in rescission of an employment offer or termination of employment  technology careers with optum. information and technology have amazing power to transform the health care industry and improve people's lives. this is where it's happening. this is where you'll help solve the problems that have never been solved. we're freeing information so it can be used safely and securely wherever it's needed. we're creating the very best ideas that can most easily be put into action to help our clients improve the quality of care and lower costs for millions. this is where the best and the brightest work together to make positive change a reality. this is the place to do your life's best work.(sm)  colorado  connecticut or nevada residents only: the salary range for colorado residents is $82 100 to $146 900. the salary range for connecticut / nevada residents is $90 500 to $161 600. pay is based on several factors including but not limited to education  work experience  certifications  etc. in addition to your salary  unitedhealth group offers benefits such as  a comprehensive benefits package  incentive and recognition programs  equity stock purchase and 401k contribution (all benefits are subject to eligibility requirements). no matter where or when you begin a career with unitedhealth group  you’ll find a far-reaching choice of benefits and incentives.  *all telecommuters will be required to adhere to unitedhealth group’s telecommuter policy.   diversity creates a healthier atmosphere: unitedhealth group is an equal employment opportunity/affirmative action employer and all qualified applicants will receive consideration for employment without regard to race  color  religion  sex  age  national origin  protected veteran status  disability status  sexual orientation  gender identity or expression  marital status  genetic information  or any other characteristic protected by law.  unitedhealth group is a drug free workplace. candidates are required to pass a drug test before beginning employment.  #dice,"401(k), 401(k) matching, ",posted 3 days ago," to, business requirements, collaboration, data infrastructure, etl, health care industry, etl tools, innovation, sql, make , server, or, bi, performance tuning, business, root cause analysis, sql , ssis, scalability, talend, transformation , writing, "
3,11695ceae70293ee,data engineer (remote option),https://www.indeed.com/viewjob?jk=11695ceae70293ee,estimated $87.9k - $111k a year,aleut federal,remote in dhs  va 20598,N/A,https://www.indeed.com/cmp/aleut%20federal,united states,aleut federal is looking for a data engineer who excels at data integrity and validation  thrives on problem-solving  and loves explaining data-driven solutions. our team is responsible for supporting the refugee  asylum  and international operations (raio) directorate to fulfill their critical mission. come be a game changer and join our team!   job requirements:  experience with data entry  data validation  and quality assurance experience in a customer service or request ticket management role comfortable validating large volume of data against standards and policy experience with troubleshooting  prioritizing  and escalating requests experience drafting communications  reports  and training documentation hold a dhs suitability clearance or have the ability to obtain one    preferred qualifications:  like to solve problems  using excellent analytical and problem-solving skills exemplary written and spoken communication skills meticulous attention to detail proactive nature to solve issues independently  but with awareness to escalate as needed experience with servicenow experience working on an agile development team,,posted 3 days ago," to, service, communications, customer service, data entry, data integrity, data validation, management, or, operations, quality assurance, servicenow, training documentation, troubleshooting , "
4,3cddbd7060d09ae4,senior data engineer,https://www.indeed.com/viewjob?jk=3cddbd7060d09ae4,N/A,the hershey company,remote in hershey  pa,3.7,https://www.indeed.com/cmp/the%20hershey%20company,united states,job title: senior data engineer job location: hershey  pa   this position is open to 100% remote   summary:   the enterprise data organization drives value for hershey by providing high-quality  well governed data to the enterprise for analytics and decision-making.   the sr. data engineer will be part of an agile execution team  working with hershey business partners  data scientists  technical engineers  and project managers to ensure engineering standards adhere to company best practice and help to deliver rapid impactful benefits.   the sr. data engineer will act as a trusted advisor for hershey business partners by ensuring that data solutions meet expectations and requirements. you will work with a diverse team of business analysts  data scientists  technical engineers  data architects  and project managers to deliver outcomes aligned with our business partner’s strategy. in addition  you will work directly with the sr. manager of data engineering to ensure consistency and compliance of deliverables to frameworks and governance processes.   major duties/responsibilities:   data engineering solution delivery: develop and deliver high-quality data pipelines adhering to best practice  privacy  and governance principles data engineering maintenance/optimization: work existing data pipelines and solutions to enhance its performance  quality and/or functionality. resolve incidents escalated by support teams or business users data engineering domain: collaborate with it and business partners to define  manage and deliver innovative data solutions to drive growth and adoption of capabilities at hershey data engineering advocacy: evangelize future data solutions identified by enterprise data leadership  including innovations such as: metadata management; data security and governance; cloud-based systems for data storage; multi-environment integration and automation of data tasks and movement   specific job responsibilities:    executes the strategy to deliver cloud-based intelligent systems to collect  distribute  model  and analyze disparate and diverse data assets to automate insights and drive business performance using best practice frameworks and governance  evaluate  design  and analyze solution engineering for agile delivery create and develop robust and secure etl pipelines across a broad range of data-focused products  services  projects  and systems using best practice guidance from enterprise data leadership  oversee the health and evolution of agile execution team engineering technologies works closely with leaders within data engineering  data architecture  data science and domain experts  to build and maintain roadmaps against the it strategy partner to deliver a modern data engineering model that follows dev/ops principles and standards for continuous integration/ continuous delivery (ci/cd) processes ensure reliability in data and data pipelines  enforcing governance  security  and performance collaborate in developing best in class key performance indicators to measure the performance and quality of the data engineering teams and processes able to articulate the holistic benefits of data engineering from a business perspective  while maintaining the relationship with business analysts  data scientists  technical engineers  and project managers     minimum knowledge  skills and abilities required to successfully perform major duties/responsibilities:    experience designing  implementing large scale data pipelines for data curation  feature engineering and machine learning across multiple environments working knowledge of agile frameworks ability to manage multiple priorities  meet deadlines and produce quality results under pressure demonstrated leadership and managerial skills strong problem solving and analytical skills strong team player  change agent  and advocate excellent customer service skills high energy self-starter excellent verbal and written communication skills     minimum education and experience requirements:   education:  bachelor’s in a stem degree master’s degree and/or related equivalent experience preferred     experience    3-5+ years of progressive experience working with data  much of which has been focused on working with cross-functional teams and enterprise-wide data management programs 3+ years of experience in building data solutions within an enterprise environment using industry standard guiding principles and practices 3+ years of leveraging data integration tools to build data pipelines e.g.  informatica  talend  matillion 3+ years of experience with sql  python  scala and spark languages to explore  interact and build solutions 3+ years of experience with public and private cloud solutions advanced working knowledge and experience with relational/non-relational databases e.g.  teradata  snowflake  databricks  azure data solutions or hadoop experience working with machine learning and data science teams experience building data visualizations or analytics e.g.  power bi  tableau  ssrs  sap experience working in a high performing agile delivery model  aligning with scrum masters  product owners  and other execution team members to deliver rapid and impactful solutions that align to business partner strategy excellent communication and presentation skills  with the ability to articulate new ideas and concepts to technical and non-technical partners experience leading a project team or project function to deliver an enterprise data  application and/or erp solution experience with cobit/sox  as well as pii data in accordance with relevant laws     #li-mb1  the hershey company is an equal opportunity employer. the policy of the hershey company is to extend opportunities to qualified applicants and employees on an equal basis regardless of an individual's race  color  gender  age  national origin  religion  citizenship status  marital status  sexual orientation  gender identity  transgender status  physical or mental disability  protected veteran status  genetic information  pregnancy  or any other categories protected by applicable federal  state or local laws.   the hershey company is an equal opportunity employer - minority/female/disabled/protected veterans if you require a reasonable accommodation as part of the application process  please contact the hr service center (askhr@hersheys.com).,,posted 4 days ago," act, advocacy, to, analytical skills, analytics, standard, automation, service, com, continuous delivery, continuous integration, cobit, project, curation, customer service, data architecture, data curation, data engineering, data integration, data management, data science, data security, databricks, e , etl, feature engineering, governance, indicators , informatica, intelligent systems, sql, key performance indicators , leadership, erp, machine learning, management, matillion, metadata, metadata management, or, bi, perspective , power bi, presentation skills, private cloud, problem solving, application, python , relational databases, reliability, business, sql , sox, scala , scale , scrum , snowflake , solution delivery, tableau , talend, written communication, "
5,b6c99ef825b8ec10,senior data engineer (remote),https://www.indeed.com/viewjob?jk=b6c99ef825b8ec10,estimated $118k - $149k a yearfull-time,cbs,remote in new york  ny 10036+5 locations,3.9,https://www.indeed.com/cmp/cbs,united states,paramount+  a direct-to-consumer digital subscription video on-demand and live streaming service from viacomcbs  combines live sports  breaking news  and a mountain of entertainment. the premium streaming service features an expansive library of original series  hit shows and popular movies across every genre from world-renowned brands and production studios  including bet  cbs  comedy central  mtv  nickelodeon  paramount pictures and the smithsonian channel. the service is also the streaming home to unmatched sports programming  including every cbs sports event  from golf to football to basketball and more  plus exclusive streaming rights for major sports properties  including some of the world’s biggest and most popular soccer leagues. paramount+ also enables subscribers to stream local cbs stations live across the u.s. in addition to the ability to stream viacomcbs streaming’s other live channels: cbsn for 24/7 news  cbs sports hq for sports news and analysis  and et live for entertainment coverage.  data plays a central role at viacomcbs and our data technology solutions team is a crucial part of our success! it drives business  product  and operational decisions by providing rich data  strategic insights  and analytical products we are looking for a senior data engineer who is passionate about data  entertainment  news  and sports who thrive in a dynamic and fast-paced environment. you will:  design and develop highly scalable and reliable data engineering pipelines to process large volumes of data across many data sources in the cloud  identify  design and implement internal process improvements by automating manual processes and optimizing data delivery  develop and promote best practices in data engineering  be part of the on call rotation supporting our sla’s key projects:  develop data pipelines for processing data from internal and external sources  migration of on-premise etl processes to python and airflow  develop a process to capture different data points required for a reliable data quality system qualifications:    what you bring to the team:  you have –  bachelor’s degree in computer science or a related field  minimum of 4+ years of applicable engineering experience  strong proficiency in python  ability to write complex sql to perform common types of analysis and aggregations  strong knowledge of application programming interfaces  proven ability to clearly communicate complex solutions  experience working on large scale data migration projects  phenomenal plusses -  experience with cloud platforms  experience with services like google dataflow  google bigquery  pubsub  apache airflow or similar  experience with docker containerization  familiar with a nosql database such as mongodb  familiar with version control systems (git and bitbucket)  can perform statistical analysis using tools such as r  numpy/scipy with python  familiar with atlassian products jira and confluence  experience with a python web framework such as django or flask  familiar with apache beam    #li-er2  #li-remote    paramount is an equal opportunity employer (eoe) including disability/vet.    at paramount  the spirit of inclusion feeds into everything that we do  on-screen and off. from the programming and movies we create to employee benefits/programs and social impact outreach initiatives  we believe that opportunity  access  resources and rewards should be available to and for the benefit of all. paramount is proud to be an equal opportunity workplace and is an affirmative action employer. we are committed to equal employment opportunity regardless of race  color  ethnicity  ancestry  religion  creed  sex  national origin  sexual orientation  age  citizenship status  marital status  disability  gender identity  gender expression  and veteran status.    if you are a qualified individual with a disability or a disabled veteran  you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. you can request reasonable accommodations by calling  212.846.5500 or by sending an email to viacomaccommodations@viacom.com. only messages left for this purpose will be returned.,,posted today," to, airflow, web framework, apache airflow, apache beam, bigquery, bitbucket, service, com, computer science, containerization, control systems, digital, data engineering, data migration, data quality, dataflow, direct-to-consumer , docker , employee benefits, etl, programming, git, git , framework, jira, sql, library, live streaming, mongodb, nosql, numpy, or, programming , application, python , r , business, sql , scale , scipy, statistical analysis, technology solutions, version control, "
6,42561df62ecc28f1,data engineer,https://www.indeed.com/viewjob?jk=42561df62ecc28f1,estimated $122k - $155k a yearcontract,capgemini,+20 locationsremote,3.8,https://www.indeed.com/cmp/capgemini,united states,duration: 6+ months    full stack data engineer with 5+ years of exp in design  coding and full development to deployment lifecycle using python  jenkins.  aws experience is must. associate should be aws experienced at the minimum.  strong exp in planning  implementation and development of projects.  ocp experience is desirable.  associate should be well experienced in cloud based projects..    the capgemini freelancer gateway is enabled by a cutting-edge software platform that leads the contingent labor world for technology innovation. the software platform leverages machine learning and artificial intelligence to make sure the right people end up in the right job.   a global leader in consulting  technology services  and digital transformation  capgemini is at the forefront of innovation to address the entire breadth of clients’ opportunities in the evolving world of cloud  digital  and platforms. building on its strong 50 year heritage and deep industry-specific expertise  capgemini enables organizations to realize their business ambitions through an array of services from strategy to operations. capgemini is driven by the conviction that the business value of technology comes from and through people. it is a multicultural company of over 200 000 team members in more than 40 countries. the group reported 2018 global revenues of eur 13.2 billion.,,posted today," software, to, artificial intelligence, consulting, digital, digital transformation, innovation, jenkins, machine learning, operations, planning, python , business, software platform, transformation , "
7,593a64e46d479051,data engineer,https://www.indeed.com/viewjob?jk=593a64e46d479051,estimated $102k - $130k a year,luxoft,weehawken  nj+4 locations,4.4,https://www.indeed.com/cmp/luxoft,united states,project description  cloud-based reference data platform  a new finance risk and data analytics capability  that will provide data mastering and distribution capabilities for various reference data domains including instruments  ratings  book data  product taxonomy  legal entity  industries  countries  currencies  etc. as a service we provide cleansing  enriching and data quality in a centralized place and offering it to different systems  applications  or users  irrespective of where they are in the organization  or on the network. as a data engineer  you will be building big data solutions to solve some of the organization's toughest problems and delivering significant business value. this is an exciting time to join as you will be helping to shape the reference data mastering and distribution architecture and technology stack within our new cloud-based datalake-house.     responsibilities    model data landscape  obtain data extracts and define secure data exchange approaches acquire  ingest  and process data from multiple sources and systems into cloud data lake create data structures optimized for storage and various query patterns implement pipelines integrating database management systems  cleaning data and improving its data quality collaborate with others to map data fields to hypotheses and curate  wrangle  and prepare data for use in their advanced analytical models shape the portfolio of business problems to solve by building detailed knowledge of internal data sources define  develop and maintain artifacts like technical design or user documentation and look for continuous improvement in software and development process within an agile development team help architect the strategic advanced analytics technology landscape build reusable code and data assets codify best practices  methodology and share knowledge with other engineers operate in the fast-paced  iterative environment while remaining compliant with bank's information sec policies/standards technology explorations  research & development  deep investigations & trouble-shooting      skills  must have   7+ years of experience in data engineering and 5+ years of experience in cloud technologies ability to work across structured  semi-structured and unstructured data  extracting information and identifying linkages across disparate data sets expert in creating data structures optimized for storage and various query patterns for e.g. parquet and delta lake hands on experience with at least one of the following programming languages: python  scala experience of working with traditional data warehousing / etl tools experience with azure data factory  azure data bricks  azure data lake storage  azure devops  azure storage services  azure data services and equivalent technologies proficient at working with large and complex code bases (github  gitflow  fork/pull model) working experience in agile methodologies (scrum  xp  kanban)    nice to have   understanding of information security principles to ensure compliant handling and management of data relevant certifications        languages  english: b2 upper intermediate   seniority  senior   relocation package  if needed  we can help you with relocation process.     vacancy specialization   bigdata development   ref number  vr-78797,"relocation assistance, ",posted today," software, to, analytics, azure data factory, azure data lake, azure devops, big data, service, cloud technologies, project, data engineering, data exchange, data quality, data structures, data warehousing, database management, database management systems, devops, e , etl, finance, programming, github, landscape, etl tools, management, management systems, nice , or, programming , python , reference data, research, business, scala , map, scrum , taxonomy, unstructured data, warehousing, "
8,d84a8450a5b0810d,remote data engineer  analytics,https://www.indeed.com/viewjob?jk=d84a8450a5b0810d,estimated $101k - $129k a yearfull-time,paramount pictures,remote in los angeles  ca 90038,4.1,https://www.indeed.com/cmp/paramount%20pictures,united states,founded in 1912  paramount pictures works with the entertainment industry’s biggest filmmakers and brightest stars to produce and distribute entertainment around the world. the iconic paramount logo has opened some of the most successful and beloved films in cinematic history  including timeless classics such as sunset boulevard  the godfather  forrest gump and ferris bueller’s day off; and blockbuster franchises such as star trek  transformers  and mission: impossible. recent innovative break-out films such as a quiet place and rocketman have further elevated paramount’s film legacy. on the small screen  paramount television studios’ defending jacob  13 reasons why  the haunting of bly manor  the alienist: angel of darkness  made for love and tom clancy’s jack ryan have also been thrilling audiences. with a beautiful 65-acre lot in the heart of hollywood  a worldwide network of offices and a culture of engagement  paramount’s passionate employees ensure the studio continues to deliver creativity and innovation to a dynamic industry. paramount is a subsidiary of viacomcbs  which reaches 700 million global subscribers through mtv  nickelodeon  comedy central  bet and other media networks.    under the mentorship of the manager of global data architecture  this role will be responsible for growing and optimizing the studio’s data and data pipeline architecture  as well as optimizing data flow and collection. the ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing existing data systems and building new ones from the ground up! the data engineer will support the cross-functional analytics team – which is comprised of executives  data analysts  and data scientists – across multiple initiatives and will ensure efficient data delivery is standardized across the team’s data warehouse. the ideal candidate is hard-working and excited by the prospect of optimizing  owning  and growing the team’s data architecture to support the studio’s ongoing data projects and data product development! more specifically  these responsibilities include  but are not limited to:    crafting and maintaining efficient data pipeline architecture  assembling large  complex data sets that meet functional / non-functional business requirements  identifying  crafting  and implementing internal process improvements: automating manual processes  optimizing data delivery  re-designing infrastructure for greater scalability  etc.  building the infrastructure required for efficient extraction  transformation  and loading (etl) of data from a wide variety of data sources using sql and aws ‘big data’ technologies  working with technical and non-technical stakeholders to assist with data-related technical issues and support their data infrastructure needs  working with the team to strive for clean and meaningful data  and greater functionality and flexibility within the team’s data systems    basic qualifications:  2+ years of experience in a data engineering role  advanced working sql knowledge  query authoring  and experience working with relational databases  proficiency with object-oriented/object function scripting languages: python  java  etc.   experience with big data tools: snowflake  hadoop  spark  etc.   experience with data pipeline and workflow management tools: informatica  airflow  etc.  experience with aws cloud services  experience building  maintaining  and optimizing ‘big data’ data pipelines  architectures  and data sets  experience cleaning  testing  and evaluating data quality from a wide variety of ingestible data sources  design processes supporting data transformation  data structures  metadata  dependency  and workload management  experience with manipulating  processing  and extracting value from large  disconnected datasets  strong project management and organizational skills  experience supporting and working with cross-functional teams in a dynamic environment    preferred qualifications:  completed coursework  certification(s)  and/or demonstrable ability to display data engineering expertise  experience working in an agile environment.   experience with a stream-processing system: snowpipe  spark-streaming  etc.  experience working with stakeholders and analysts who use tableau    paramount is an equal opportunity employer (eoe) including disability/vet.    at paramount  the spirit of inclusion feeds into everything that we do  on-screen and off. from the programming and movies we create to employee benefits/programs and social impact outreach initiatives  we believe that opportunity  access  resources and rewards should be available to and for the benefit of all. paramount is proud to be an equal opportunity workplace and is an affirmative action employer. we are committed to equal employment opportunity regardless of race  color  ethnicity  ancestry  religion  creed  sex  national origin  sexual orientation  age  citizenship status  marital status  disability  gender identity  gender expression  and veteran status.    if you are a qualified individual with a disability or a disabled veteran  you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. you can request reasonable accommodations by calling  212.846.5500 or by sending an email to viacomaccommodations@viacom.com. only messages left for this purpose will be returned.,,posted 16 days ago," to, airflow, analytics, big data, business requirements, java, cloud services, com, project, creativity, data architecture, data engineering, data infrastructure, data pipeline, data quality, data structures, data transformation, employee benefits, etl, films, programming, informatica, innovation, java , sql, management, mentorship, metadata, project management, or, organizational skills, programming , python , relational databases, business, sql , scalability, scripting, data warehouse, tableau , transformation , transformers , workflow management, "
9,12eea4b44e3de229,data engineer (starlink),https://www.indeed.com/viewjob?jk=12eea4b44e3de229,estimated $93.5k - $118k a year,spacex,redmond  wa 98052 (se redmond area)+3 locations,3.6,https://www.indeed.com/cmp/spacex,united states,spacex was founded under the belief that a future where humanity is out exploring the stars is fundamentally more exciting than one where we are not. today spacex is actively developing the technologies to make this possible  with the ultimate goal of enabling human life on mars.  data engineer (starlink)  spacex is looking for a data engineer to drive data analysis and monitoring for the starlink network  with the goal of providing better internet access to unconnected users worldwide. you will set best practices for how to use our data to direct developer efforts  find and solve network inefficiencies  create and drive kpis for network quality  and solve the network's biggest problems. the tools you build will allow starlink to expand its user base  improve its user experience  and serve unconnected populations across the globe.  responsibilities:  define and create real-time and historical metrics  dashboards  and kpis to monitor network performance  outages  and regressions use data analytics to isolate performance bottlenecks in reliability  throughput and latency onboard other teams at starlink to be able to create their own monitoring dashes  using a common toolset bring machine learning into our toolkit: ml models to predict failures  anomaly detection  basic qualifications:  bachelor's degree in computer science  data science  physics  mathematics  or a stem discipline 1+ years of professional  or educational/intern experience in analytics  data science  data engineering  or software engineering development experience with sql  python  spark  r  or other programming languages  preferred skills and experience:  experience building predictive models and machine learning pipelines (clustering analysis  failure prediction  anomaly detection) experience working with in-stream data processing of structured and semi-structured data experience in custom etl design  implementation and maintenance experience with schema design and dimensional data modeling experience working in a linux environment  and open source tools experience handling large (tb+) datasets domain-specific experience a plus  but not required demonstrated ability to own projects from start to completion strong attention to detail  itar requirements:  to conform to u.s. government space technology export regulations  including the international traffic in arms regulations (itar) you must be a u.s. citizen  lawful permanent resident of the u.s.  protected individual as defined by 8 u.s.c. 1324b(a)(3)  or eligible to obtain the required authorizations from the u.s. department of state. learn more about the itar here.  spacex is an equal opportunity employer; employment with spacex is governed on the basis of merit  competence and qualifications and will not be influenced in any manner by race  color  religion  gender  national origin/ethnicity  veteran status  disability status  age  sexual orientation  gender identity  marital status  mental or physical disability or any other legally protected status.  applicants wishing to view a copy of spacex's affirmative action plan for veterans and individuals with disabilities  or applicants requiring reasonable accommodation to the application/interview process should notify the human resources department at (310) 363-6000.,,posted 30+ days ago," software, to, toolkit, analytics, anomaly detection, software engineering, c , computer science, data analysis, data engineering, data modeling, data processing, data science, disabilities, etl, programming, international traffic in arms regulations, sql, kpis, linux, machine learning, or, user experience, physics, programming , application, python , r , reliability, sql , semi-structured data, source , space technology, throughput, "
10,7535b9c09a9e30b6,data engineer iii - remote,https://www.indeed.com/viewjob?jk=7535b9c09a9e30b6,estimated $87.1k - $110k a yearfull-time,uw health,remote in madison  wi 53717,3.5,https://www.indeed.com/cmp/uw%20health,united states,w ork schedule :  this is a full-time  40 hours per week position scheduled monday through friday  typically between the hours of 8:00 am – 5:00 pm. applicants hired into this position can work remotely from most states. this will be discussed during the interview process.  be part of something remarkable  have a hand in building data pipelines and objects that improve the lives and care of our patients. contribute to changing the way analytics are used at the #1 hospital in wisconsin. work remotely on a highly collaborative team that comes together every day to apply their skills to work that goes far beyond just selling a widget.  we are seeking a data engineer iii to:   lead our data engineering team and data science teams into expanded  more efficient use of azure  databricks  and other cloud technologies.  leverage knowledge and skill with a variety of data engineering  dataops  and data warehousing methodologies  techniques  tools  and platforms to move and transform large quantities of data from multiple sources.  develop and maintain trusted advisor relationships with business  clinical  and operations leaders that include guidance for optimizing use of analytic capabilities and deliverables.   learn more about is at uw health  education :  minimum – bachelor’s degree in healthcare  information systems  computer science  engineering  business  data science  or related field. (four years relevant work experience may be considered in lieu of educational requirement).  preferred – master’s degree in healthcare  information systems  computer science  engineering  business  data science  or related field.  work experience :  minimum –   demonstrated success in designing  developing  implementing  testing  and operating large-scale  high-volume  high-performance data structures and other purpose-built data stores for analytics  reporting  machine learning  and data science with low technical deb.  demonstrated success building robust  scalable  reliable data pipelines of high complexity.  demonstrated success automating and/or continually improving ongoing data pipelines and reporting and analysis processes.  demonstrated success prescribing technical designs and solutions when approached with an ambiguous problem or need.  demonstrated success leading and coordinating cross-functional delivery teams to achieve desired outcomes within enterprise analytics.  demonstrated success teaching and mentoring by contributing experience and insight to the team.   preferred –   five (5) years of relevant data warehousing or etl development experience in healthcare (provider or payor.  three (3) years of experience with epic cogito technologies (e.g. epic clarity  epic caboodle) or other data warehousing and data transformation technologies (e.g. azure  databricks  informatica  etc).  project management experience  including agile methods.   licenses and certifications :  preferred –   epic certifications in cogito or any other subject area.  relevant certifications related to data warehousing concepts and technologies  etl development  or other pertinent areas of analytics.  relevant certifications to agile methodologies  itil  process improvement  lean management  or other related activities.   our commitment to diversity  equity  and inclusion  uw health is committed to being a diverse  equitable  inclusive  and anti-racist workplace and is an equal employment opportunity  affirmative action employer. our integrity shines through in patient care interactions and our daily work practices as we work to embrace the knowledge  unique perspectives  and qualities each employee and faculty member brings to work each day. applications from black  indigenous and people of color (bipoc) individuals  lgbtq+ and non-binary identities  women  persons with disabilities  military service members and veterans are strongly encouraged. eoe  including disability/veterans.    uw medical foundation benefits,,posted 30+ days ago," medical, to, analytics, service, cloud technologies, computer science, coordinating, project, data engineering, data science, data structures, data transformation, data warehousing, databricks, disabilities, e , epic clarity, etl, informatica, information systems, machine learning, management, project management, or, operations, process improvement, military, business, scale , teaching, transformation , warehousing, "
11,338f5f345a34e790,senior data engineer (remote),https://www.indeed.com/viewjob?jk=338f5f345a34e790,$100 000 - $120 000 a yearfull-time,matrix medical network,remote in scottsdale  az 85258,2.8,https://www.indeed.com/cmp/matrix%20medical%20network,united states,overview:     sr. data engineer  (remote)   matrix  in partnership with its expert clinical advisory panel  offers customizable solutions across four distinct lines of business via in-home visits  telehealth  on-site support at medical facilities and businesses  and mobile health clinics:   matrix clinical solutions helps keep workers healthy and businesses run productively by designing custom workplace health solutions and providing testing  tracing  and clinical care solutions. matrix also offers a safety verified certification program developed in collaboration with the cleveland clinic.  matrix clinical care helps seniors and other at-risk individuals enjoy a better quality of care  experience better health outcomes  and identify chronic conditions that may otherwise go undiagnosed.  matrix clinical trials provides rapid and scalable decentralized trial solutions to reach broad and diverse trial participant populations and improve the patient experience. matrix adheres to the highest standards in quality  compliance  and data collection to accelerate trial completion timelines and support trial partners.  matrix clinical labs is a clia-certified and cap-accredited laboratory that provides state-of-the-art diagnostic services and clinical testing support.      matrix medical network it delivers capabilities using cutting edge technologies to support all these lines of business  including mobile tablet  geo-spatial analysis  business intelligence and custom business solutions.    at matrix  you will have endless opportunities to positively impact the communities in which we work and to affect the lives of health plan members who we serve.   what we offer:   a chance to work with great people on exciting projects  make a difference by taking the time doing the work that saves lives that have positive and direct impact on the wellbeing of others  the opportunity to work with a progressive company  who wants to make a difference    responsibilities:    about the role:   type: full time salaried  compensation: $100 000 to $120 000 a year  location: primary location: remote or 9201 e. mountain view road  scottsdale  az 85258.  hours: full time days  benefits offered to include: medical  dental  vision  pto and holiday pay  401k with company matching  voluntary life insurance  short term disability  long term disability  health savings account  flexible spending accounts.    what to expect:   the senior data engineer is a technical leader providing oversight and delivery of technical projects. this role implements architecture-centric solutions in addition to providing guidance to the developers in delivering solutions that adhere to and meets the strategic objectives set by the architect and it leadership.    responsibilities:    participates in all phases of sdlc: from system analysis and design thru development and test to deployment and support.  provides development estimates and participates in project planning.  participates in designing and developing complex systems by writing design specifications description of framework  interfaces  services  reports  business components  and interaction between the components.  responsible for ensuring quality delivery of data solutions through static and dynamic testing techniques  is able to troubleshoot any complex issues as well as provide support to production.  keep abreast of the current technologies and technological trends. ability to learn and prototype new technologies  and recommend their use in the company products.  may lead a team of developers  possibly offshore to ensure that the project is successfully completed.  peer mentoring experience of more junior team members.  ensures adherence to standards for self as well as team    qualifications:    must haves:   bachelor's degree in computer science or related field or equivalent combination of education and experience  minimum 7 years of experience as a developer  minimum 2 years of experience as a lead or senior developer  experience in azure sql or similar cloud databases  knowledge of advanced sql programming concepts like cte  window functions  minimum 5 years of experience with transact-sql  microsoft sql reporting services and microsoft sql server (2014 or later preferred)  minimum 5 years of experience with microsoft sql server integration services (ssis). knowledge of advanced ssis concepts to handle complex tasks like importing large files  loading data in a transactional database etc.  minimum of 2 years experience in azure data factory  other azure technologies.  minimum 1 years experience in power bi.  knowledge of azure data integration tools like logicapps  eventgrid.  knowledge of ms dynamics or similar saas services.  proven ability to analyze  document  and reverse engineer any type of sql based applications and processes.  make recommendation on how to rewrite  modify  redesign sql based application and processes based on analysis.  excellent written and verbal communication skills  demonstrated experience of estimation and planning  understanding of project management concepts and techniques required  demonstrated abilities to successfully document and communicate software designs of complex systems.  has proven record of successfully motivating and leading a software development team.  proven history of developing and unit testing complex software components.  ability to be flexible  set priorities and meet deadlines in a changing environment for self as well as team.  must have decision-making skills for problem identification and solution recommendation.  ability to work independently and as part of a team while demonstrating initiative and using good business judgment  demonstrated ability to drive process improvement and improve the process efficiency  demonstrated ability to reduce and/or prevent production defects based on the continuous root cause analysis and process improvement  ability to maintain effective working relationships across teams and with a diverse workforce    nice to have:    azure experience  experience with nosql databases  experience in ms dynamics or similar sas services is a big plus.    our culture:   we have a clear vision of where we are going  and we are guided by core values that embody our organization and our culture.  we emphasizes innovation and growth  and you will be given the opportunities and tools to develop personally and professionally.  we encourage and celebrate collaboration.  we have a deep commitment to positively impact the communities in which we work and to make a difference in the lives of who we serve.  as a clinical organization  we support vaccinations because we care about the health and safety of our colleagues and those we serve. moreover  our clients are increasingly expecting us to be vaccinated due to the vulnerability of those we serve. as such  matrix medical network requires that all team members are fully vaccinated against influenza and covid-19  unless they are eligible for a specific exemption.    matrix medical network is an equal employment opportunity employer. it is the policy of matrix to provide equal employment opportunities without regard to race  color  religion  sex  gender identity or expression  pregnancy  age  national origin  age  disability  marital status  veteran status  sexual orientation  genetic information or any other protected characteristic under applicable law. it is also the policy of matrix that qualified individuals with disabilities receive equal opportunity in regard to job application procedures  hiring  and all aspects of the employment process. matrix is committed to the full inclusion of all qualified individuals. consistent with the americans with disabilities act (ada) and applicable state and local laws  it is the policy of matrix to provide reasonable accommodation when requested by a qualified applicant or employee with a disability  unless such accommodation would cause an undue hardship. if reasonable accommodation is needed to participate in the job application or interview process  pre-employment testing  to otherwise participate in the selection process  to perform essential job functions  and/or to receive other benefits and privileges of employment  please contact matrixhr@matrixhealth.net.   senior data engineer senior sql developer primary location: remote or scottsdale  az 85258. regular shift. work from home opportunity  full-time  regular  salaried,"401(k), 401(k) matching, dental insurance, disability insurance, flexible spending account, health insurance, ",posted 6 days ago," software, medical, act, ada , to, azure data factory, business intelligence, clinical trials, collaboration, software development, computer science, project, data collection, data integration, design specifications, disabilities, e , programming, go , framework, influenza, innovation, sql, leadership, management, server, project management, saas, nice , nosql, or, bi, planning, power bi, process improvement, programming , programming concepts, project planning, prototype , application, reach, business, root cause analysis, sql , ssis, spatial analysis, sas, telehealth, timelines, transact-sql, unit testing, verbal communication skills, vulnerability, writing, "
12,e25f9b533d3f046e,data engineer,https://www.indeed.com/viewjob?jk=e25f9b533d3f046e,estimated $72.7k - $92.1k a yearfull-time,cinemark usa  inc,plano  tx 75093,3.7,https://www.indeed.com/cmp/cinemark%20usa%20%20inc,united states,headquartered in plano  tx  cinemark holdings  inc. is a leader in the motion picture exhibition industry with 500+ theatres in the u.s. and latin america.    join our team!    do you enjoy working together as a team to accomplish major goals? join cinemark to utilize and expand your skills! we are dedicated to making the movie experience memorable  “one guest at a time.” our world class talent creates a warm and friendly culture through shared values.    the data engineer will be responsible for the development  implementation  testing  documentation and maintenance of bi and analytics platforms. will implement data ingestion routines using best practices in data modeling  etl/elt processes leveraging microsoft azure technologies. provide reporting and data analysis using business intelligence tools. produce comprehensive  usable dataset documentation and metadata. work with internal customers to solve  implement and lead through the deployment of technical solutions for their business needs.,,posted 6 days ago," to, analytics, business intelligence, business intelligence tools, data analysis, data ingestion, data modeling, dataset, etl, latin, metadata, microsoft azure, bi, business, "
13,c8a309340af4f867,sr data engineer,https://www.indeed.com/viewjob?jk=c8a309340af4f867,estimated $116k - $147k a year,the walt disney company (corporate),lake buena vista  fl+9 locations,4.1,https://www.indeed.com/cmp/the%20walt%20disney%20company%20(corporate),united states,the disney decision science and integration (ddsi) analytics consulting team is responsible for supporting clients across the walt disney company including direct-to-consumer & international  media networks (e.g.  abc  espn)  studio entertainment (e.g.  the walt disney studios  disney theatrical group) and parks  experiences & consumer products. ddsi leverages technology  data analytics  optimization  statistical and econometric modeling to explore opportunities  shape business decisions and drive business value.  the ddsi data engineering (de) team is seeking a senior data engineer to work on a food and beverage revenue management project. this position will work with the decision science products and science teams to design and implement a new system in the food and beverage space. the work will involve various data engineering activities such as data acquisition and validation  designing and implementing etl/elt data pipelines  and designing and implementing databases.  responsibilities of the role:  work assignments may cover activities such as data requirements gathering  source-to-target mapping  data validation scripting and review  developing and monitoring etl/elt data pipelines  designing and implementing database schema/tables/views  and producing datasets as input to science models and visualizations.  technologies generally leveraged to fulfill the work include  but not limited to  sql  python  docker  gitlab  airflow  lambda  snowflake  and postgresql.  basic qualifications:   3-5 years of experience with elt/etl data pipeline development and maintenance  proven experience and expertise using python  sql  and cloud storage (such as aws s3)  experience with developing in a multi environment (dev  qa  prod  etc.) and devops procedures for code deployment/promotion.  strong understanding of relational database design and proficiency utilizing a database such as postgresql  or snowflake   desired qualifications:   master’s degree (computer science  mathematics  engineering or related field preferred)  experience working with large datasets and big data technologies  preferably cloud-based  such as snowflake  databricks  or similar  knowledgeable on cloud architecture and product offerings  preferably aws  experience managing and deploying code using a source control product such as gitlab/github  experience leveraging containerization technologies such as docker or kubernetes  hands-on knowledge of job scheduling software like apache airflow  amazon mwaa  or uc4,,posted 2 days ago," software, to, airflow, analytics, apache airflow, big data, cloud storage, computer science, consulting, containerization, project, food, data acquisition, data engineering, data pipeline, data validation, database design, database schema, databricks, devops, direct-to-consumer , e , econometric modeling, etl, github, gitlab, sql, job scheduling , kubernetes, management, or, postgresql, python , relational database design, business, revenue management, sql , scheduling, scripting, snowflake , source , "
14,8c5373b9f8b44765,data engineer newsroom products,https://www.indeed.com/viewjob?jk=8c5373b9f8b44765,N/A,dow jones,princeton  nj 08544+5 locations,3.9,https://www.indeed.com/cmp/dow%20jones,united states,"job description: as a member of the newsroom data platform team  this role will work closely in collaboration with our data scientists  editors  and strategy leads as we build internal data products for the newsroom. day-to-day collaboration will happen with other data engineers within the team and dow jones’ broader data organization. importantly  this role will work directly with other engineers  product managers  and program managers who collectively work on our internal data products. required experience  knowledge  and skills:  strong familiarity and experience with ingestion  streaming and batch processing  data infrastructure design  and data analytics. excellent written and verbal communication skills  as well as top organizational  time management  and documentation skills. top-notch understanding of basic statistics and issues surrounding data quality experience in building infrastructure required for optimal extraction  transformation and loading of data from diverse data resources experience running and supporting production of enterprise data platforms. understanding and experience with relational and non-relational databases. experience building data pipelines in aws (preferred) or gcp. proficiency in scala  python  bash  git  spark  and sql. 2 or more years of data engineering experience is preferred  but candidates with less experience in data engineering may be successful depending on their general engineering background and/or relevant work in academic research.  dow jones   making careers newsworthy all qualified applicants will receive consideration for employment without regard to race  color  religion  sex  national origin  protected veteran status  or disability status. eeo/aa/m/f/disabled/vets . dow jones is committed to providing reasonable accommodation for qualified individuals with disabilities  in our job application and/or interview process. if you need assistance or accommodation in completing your application  due to a disability  please reach out to us at talentresourceteam@dowjones.com. please put “reasonable accommodation"" in the subject line. business area: technology - data set/ad tech job category: it development group union status: union / no clear and likely internal candidate (employee only) has been identified req id: 32941",,posted 30+ days ago," to, analytics, bash , batch processing, collaboration, com, data engineering, data infrastructure, data quality, disabilities, git, git , gcp, sql, less, m , management, or, application, python , reach, relational databases, research, business, sql , statistics, scala , time management, transformation , verbal communication skills, "
